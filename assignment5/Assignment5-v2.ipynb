{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "\n",
    "**Submission deadline: last lab session before or on Tuesday, 09.5.17**\n",
    "\n",
    "**Points: 9 + 10 bonus points**\n",
    "\n",
    "\n",
    "## Downloading this notebook\n",
    "\n",
    "This assignment is an Jupyter notebook. Download it by cloning https://github.com/janchorowski/nn_assignments. Follow the instructions in its README for instructions.\n",
    "\n",
    "For programming exerciese add your solutions to the notebook. For math exercies please provide us with answers on paper or type them in the notebook (it supports Latex-like equations).\n",
    "\n",
    "Please do not hesitate to use GitHubâ€™s pull requests to send us corrections!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modular network implementation\n",
    "\n",
    "This assignment builds on code from Assignment 4, Problem 7. \n",
    "For your convenience, we have copied the code below. Please copy your solution from the old list, or fill in the blanks below to get a working network.\n",
    "\n",
    "In the following cells, I implement in a modular way a feedforward neural network. Please study the code - many network implementations follow a similar pattern.\n",
    "\n",
    "Please make sure that the network trains to nearly 100% accuracy on Iris.\n",
    "\n",
    "## Task\n",
    "\n",
    "Your job is to implement SGD training on MNIST with the following elements:\n",
    "1. SGD + momentum\n",
    "2. weight decay\n",
    "3. early stopping\n",
    "\n",
    "In overall, you should get below **2% testing errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "# \n",
    "\n",
    "class Constant():\n",
    "    \"\"\"Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype=np.float32)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    \"\"\"Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    \"\"\"\n",
    "    def __init__(self, std=1, mean=0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size=shape)\n",
    "        #print(np.sum(m > 0.))\n",
    "        #print(np.sum(m == 0.))\n",
    "        #print(np.sum(m < 0.))\n",
    "        return m.astype(np.float32)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    \"\"\"Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., width=None, std=None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1/12 * width^2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size=shape)\n",
    "        return m.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class Layer(object):\n",
    "#     def __init__(self, rng=None):\n",
    "#         if rng is None:\n",
    "#             rng = numpy.random\n",
    "#         self.rng = rng\n",
    "    \n",
    "#     @property\n",
    "#     def parameters(self):\n",
    "#         return []\n",
    "    \n",
    "#     @property\n",
    "#     def parameter_names(self):\n",
    "#         return []\n",
    "    \n",
    "#     def get_gradients(self, dLdY, fprop_context):\n",
    "#         return [] \n",
    "\n",
    "# class AffineLayer(Layer):\n",
    "#     def __init__(self, num_in, num_out, weight_init=None, bias_init=None, **kwargs):\n",
    "#         super(AffineLayer, self).__init__(**kwargs)\n",
    "#         if weight_init is None:\n",
    "#             weight_init = IsotropicGaussian(std=0.2, mean=0.0)\n",
    "#         if bias_init is None:\n",
    "#             bias_init = Constant(0.0)\n",
    "\n",
    "#         self.W = weight_init.generate(self.rng, (num_out, num_in))\n",
    "#         self.b = bias_init.generate(self.rng, (num_out, 1))\n",
    "    \n",
    "#     @property\n",
    "#     def parameters(self):\n",
    "#         return [self.W, self.b]\n",
    "    \n",
    "#     @property\n",
    "#     def parameter_names(self):\n",
    "#         return ['W','b']\n",
    "    \n",
    "#     def fprop(self, X):\n",
    "#         fprop_context = dict(X=X)\n",
    "#         Y = np.dot(self.W, X) + self.b\n",
    "#         return Y, fprop_context\n",
    "    \n",
    "#     def bprop(self, dLdY, fprop_context):\n",
    "#         return self.W.T.dot(dLdY)\n",
    "    \n",
    "#     def get_gradients(self, dLdY, fprop_context):\n",
    "#         X = fprop_context['X']\n",
    "#         dLdW = np.dot(dLdY, X.T)\n",
    "#         dLdb = dLdY.sum(1, keepdims=True)\n",
    "#         return [dLdW, dLdb]\n",
    "    \n",
    "# class TanhLayer(Layer):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super(TanhLayer, self).__init__(**kwargs)\n",
    "    \n",
    "#     def fprop(self, X):\n",
    "#         Y = np.tanh(X)\n",
    "#         fprop_context = dict(Y=Y)\n",
    "#         return Y, fprop_context\n",
    "    \n",
    "#     def bprop(self, dLdY, fprop_context):\n",
    "#         Y = fprop_context['Y']\n",
    "#         return dLdY * (1.0 - Y**2)\n",
    "\n",
    "    \n",
    "# class ReLULayer(Layer):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super(ReLULayer, self).__init__(**kwargs)\n",
    "    \n",
    "#     def fprop(self, X):\n",
    "#         Y = np.maximum(X, 0.0)\n",
    "#         fprop_context = dict(Y=Y)\n",
    "#         return Y, fprop_context\n",
    "    \n",
    "#     def bprop(self, dLdY, fprop_context):\n",
    "#         Y = fprop_context['Y']\n",
    "#         return dLdY * (Y>0)\n",
    "\n",
    "    \n",
    "# class SoftMaxLayer(Layer):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super(SoftMaxLayer, self).__init__(**kwargs)\n",
    "    \n",
    "#     def compute_probabilities(self, X):\n",
    "#         O = X - X.max(axis=0, keepdims=True)\n",
    "#         O = np.exp(O)\n",
    "#         O /= O.sum(axis=0, keepdims=True)\n",
    "#         return O\n",
    "    \n",
    "#     def fprop_cost(self, X, Y):\n",
    "#         NS = X.shape[1]\n",
    "#         O = self.compute_probabilities(X)\n",
    "#         Cost = -1.0/NS * np.log(O[Y.ravel(), range(NS)]).sum()\n",
    "#         return Cost, O, dict(O=O, X=X, Y=Y)\n",
    "    \n",
    "#     def bprop_cost(self, fprop_context):\n",
    "#         X = fprop_context['X']\n",
    "#         Y = fprop_context['Y']\n",
    "#         O = fprop_context['O']\n",
    "#         NS = X.shape[1]\n",
    "#         dLdX = O.copy()\n",
    "#         dLdX[Y, range(NS)] -= 1.0\n",
    "#         dLdX /= NS\n",
    "#         return dLdX\n",
    "    \n",
    "# class FeedForwardNet(object):\n",
    "#     def __init__(self, layers=None):\n",
    "#         if layers is None:\n",
    "#             layers = []\n",
    "#         self.layers = layers\n",
    "    \n",
    "#     def add(self, layer):\n",
    "#         self.layers.append(layer)\n",
    "    \n",
    "#     @property\n",
    "#     def parameters(self):\n",
    "#         params = []\n",
    "#         for layer in self.layers:\n",
    "#             params += layer.parameters\n",
    "#         return params\n",
    "    \n",
    "#     @parameters.setter\n",
    "#     def parameters(self, values):\n",
    "#         for ownP, newP in zip(self.parameters, values):\n",
    "#             ownP[...] = newP\n",
    "    \n",
    "#     @property\n",
    "#     def parameter_names(self):\n",
    "#         param_names = []\n",
    "#         for layer in self.layers:\n",
    "#             param_names += layer.parameter_names\n",
    "#         return param_names\n",
    "    \n",
    "#     def fprop(self, X):\n",
    "#         for layer in self.layers[:-1]:\n",
    "#             X, fp_context = layer.fprop(X)\n",
    "#         return self.layers[-1].compute_probabilities(X)\n",
    "    \n",
    "#     def get_cost_and_gradient(self, X, Y):\n",
    "#         fp_contexts = []\n",
    "#         for layer in self.layers[:-1]:\n",
    "#             X, fp_context = layer.fprop(X)\n",
    "#             fp_contexts.append(fp_context)\n",
    "        \n",
    "#         L, O, fp_context = self.layers[-1].fprop_cost(X, Y)\n",
    "#         dLdX = self.layers[-1].bprop_cost(fp_context)\n",
    "        \n",
    "#         dLdP = [] #gradient with respect to parameters\n",
    "#         for i in xrange(len(self.layers)-1):\n",
    "#             layer = self.layers[len(self.layers)-2-i]\n",
    "#             fp_context = fp_contexts[len(self.layers)-2-i]\n",
    "#             dLdP = layer.get_gradients(dLdX, fp_context) + dLdP\n",
    "#             dLdX = layer.bprop(dLdX, fp_context)\n",
    "            \n",
    "#         return L, O, dLdP\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, rng=None):\n",
    "        if rng is None:\n",
    "            rng = numpy.random\n",
    "        self.rng = rng\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        return []\n",
    "    \n",
    "    def get_gradients(self, dLdY, fprop_context):\n",
    "        return [] \n",
    "\n",
    "class AffineLayer(Layer):\n",
    "    def __init__(self, num_in, num_out, weight_init=None, bias_init=None, dropout = None, **kwargs):\n",
    "        super(AffineLayer, self).__init__(**kwargs)\n",
    "        if weight_init is None:\n",
    "            weight_init = IsotropicGaussian(std=0.2, mean=0.0)\n",
    "        if bias_init is None:\n",
    "            bias_init = Constant(0.0)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.W = weight_init.generate(self.rng, (num_out, num_in))\n",
    "        self.b = bias_init.generate(self.rng, (num_out, 1))\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.W, self.b]\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        return ['W','b']\n",
    "    \n",
    "    def fprop(self, X, with_dropout = False):\n",
    "        fprop_context = dict(X=X)\n",
    "        if with_dropout or (not self.dropout):\n",
    "            Y = np.dot(self.W, X) + self.b\n",
    "        else:\n",
    "            Y = np.dot(self.W * self.dropout, X) + self.b\n",
    "        return Y, fprop_context\n",
    "    \n",
    "    def bprop(self, dLdY, fprop_context):\n",
    "        return self.W.T.dot(dLdY)\n",
    "    \n",
    "    def get_gradients(self, dLdY, fprop_context):\n",
    "        X = fprop_context['X']\n",
    "        dLdW = np.dot(dLdY, X.T)\n",
    "        dLdb = dLdY.sum(1, keepdims=True)\n",
    "        return [dLdW, dLdb]\n",
    "\n",
    "class InputDropoutLayer(Layer):\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(InputDropoutLayer, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def fprop(self, X, with_dropout = False):\n",
    "        if with_dropout:\n",
    "            choice = np.random.binomial(1, self.dropout, X.shape[0]).reshape(X.shape[0], 1)\n",
    "            Y = X * choice\n",
    "        else:\n",
    "            Y = X\n",
    "        return Y, dict()\n",
    "    \n",
    "    def bprop(self, dLdY, fprop_context):\n",
    "        return dLdY\n",
    "        \n",
    "class TanhLayer(Layer):\n",
    "    def __init__(self, dropout = None, **kwargs):\n",
    "        super(TanhLayer, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def fprop(self, X, with_dropout = False):\n",
    "        Y = np.tanh(X)\n",
    "        fprop_context = dict(Y=Y)\n",
    "        return Y, fprop_context\n",
    "    \n",
    "    def bprop(self, dLdY, fprop_context):\n",
    "        Y = fprop_context['Y']\n",
    "        return dLdY * (1.0 - Y**2)\n",
    "\n",
    "    \n",
    "class ReLULayer(Layer):\n",
    "    def __init__(self, dropout = None, **kwargs):\n",
    "        super(ReLULayer, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def fprop(self, X, with_dropout = False):\n",
    "        Y = np.maximum(X, 0.0)\n",
    "        if self.dropout and with_dropout:\n",
    "            choice = np.random.binomial(1, self.dropout, Y.shape[0]).reshape(Y.shape[0], 1)\n",
    "            Y *= choice\n",
    "            fprop_context = dict(Y=Y, choice=choice)\n",
    "        else:\n",
    "            fprop_context = dict(Y=Y)\n",
    "        return Y, fprop_context\n",
    "    \n",
    "    def bprop(self, dLdY, fprop_context):\n",
    "        Y = fprop_context['Y']\n",
    "        dLdX = dLdY * (Y > 0)\n",
    "        if self.dropout:\n",
    "            choice = fprop_context['choice']\n",
    "            dLdX *= choice\n",
    "        return dLdX\n",
    "\n",
    "    \n",
    "class SoftMaxLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SoftMaxLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def compute_probabilities(self, X):\n",
    "        O = X - X.max(axis=0, keepdims=True)\n",
    "        O = np.exp(O)\n",
    "        O /= O.sum(axis=0, keepdims=True)\n",
    "        return O\n",
    "    \n",
    "    def fprop_cost(self, X, Y):\n",
    "        NS = X.shape[1]\n",
    "        O = self.compute_probabilities(X)\n",
    "        Cost = -1.0/NS * np.log(O[Y.ravel(), range(NS)]).sum()\n",
    "        return Cost, O, dict(O=O, X=X, Y=Y)\n",
    "    \n",
    "    def bprop_cost(self, fprop_context):\n",
    "        X = fprop_context['X']\n",
    "        Y = fprop_context['Y']\n",
    "        O = fprop_context['O']\n",
    "        NS = X.shape[1]\n",
    "        dLdX = O.copy()\n",
    "        dLdX[Y, range(NS)] -= 1.0\n",
    "        dLdX /= NS\n",
    "        return dLdX\n",
    "    \n",
    "class FeedForwardNet(object):\n",
    "    def __init__(self, layers=None):\n",
    "        if layers is None:\n",
    "            layers = []\n",
    "        self.layers = layers\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.parameters\n",
    "        return params\n",
    "    \n",
    "    @parameters.setter\n",
    "    def parameters(self, values):\n",
    "        for ownP, newP in zip(self.parameters, values):\n",
    "            ownP[...] = newP\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        param_names = []\n",
    "        for layer in self.layers:\n",
    "            param_names += layer.parameter_names\n",
    "        return param_names\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        for layer in self.layers[:-1]:\n",
    "            X, fp_context = layer.fprop(X)\n",
    "        return self.layers[-1].compute_probabilities(X)\n",
    "    \n",
    "    def get_cost_and_gradient(self, X, Y):\n",
    "        fp_contexts = []\n",
    "        for layer in self.layers[:-1]:\n",
    "            X, fp_context = layer.fprop(X, with_dropout = True)\n",
    "            fp_contexts.append(fp_context)\n",
    "        \n",
    "        L, O, fp_context = self.layers[-1].fprop_cost(X, Y)\n",
    "        dLdX = self.layers[-1].bprop_cost(fp_context)\n",
    "        \n",
    "        dLdP = [] #gradient with respect to parameters\n",
    "        for i in xrange(len(self.layers)-1):\n",
    "            layer = self.layers[len(self.layers)-2-i]\n",
    "            fp_context = fp_contexts[len(self.layers)-2-i]\n",
    "            dLdP = layer.get_gradients(dLdX, fp_context) + dLdP\n",
    "            dLdX = layer.bprop(dLdX, fp_context)\n",
    "            \n",
    "        return L, O, dLdP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training algorithms. They change the network!\n",
    "def GD(net, X, Y, alpha=1e-4, max_iters=1000000, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Simple batch gradient descent\n",
    "    \"\"\"\n",
    "    old_L = np.inf\n",
    "    for i in xrange(max_iters):\n",
    "        L, O, gradients = net.get_cost_and_gradient(X, Y)\n",
    "        if old_L < L:\n",
    "            print \"Iter: %d, loss increased!!\" % (i,)\n",
    "        if (old_L - L)<tolerance:\n",
    "            print \"Tolerance level reached exiting\"\n",
    "            break\n",
    "        if i % 1000 == 0:\n",
    "            err_rate = (O.argmax(0) != Y).mean()\n",
    "            print \"At iteration %d, loss %f, train error rate %f%%\" % (i, L, err_rate*100)\n",
    "        for P,G in zip(net.parameters, gradients):\n",
    "            P -= alpha * G\n",
    "        old_L = L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "IrisX = iris.data.T\n",
    "IrisX = (IrisX - IrisX.mean(axis=1, keepdims=True)) / IrisX.std(axis=1, keepdims=True)\n",
    "IrisY = iris.target.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 0, loss 1.020450, train error rate 30.000000%\n",
      "At iteration 1000, loss 0.052523, train error rate 2.000000%\n",
      "At iteration 2000, loss 0.044054, train error rate 1.333333%\n",
      "At iteration 3000, loss 0.041678, train error rate 1.333333%\n",
      "At iteration 4000, loss 0.040556, train error rate 1.333333%\n",
      "At iteration 5000, loss 0.039779, train error rate 1.333333%\n",
      "At iteration 6000, loss 0.039111, train error rate 1.333333%\n",
      "At iteration 7000, loss 0.038519, train error rate 1.333333%\n",
      "At iteration 8000, loss 0.038005, train error rate 1.333333%\n",
      "At iteration 9000, loss 0.037565, train error rate 1.333333%\n",
      "At iteration 10000, loss 0.037189, train error rate 1.333333%\n",
      "At iteration 11000, loss 0.036861, train error rate 1.333333%\n",
      "At iteration 12000, loss 0.036565, train error rate 1.333333%\n",
      "At iteration 13000, loss 0.036284, train error rate 1.333333%\n",
      "At iteration 14000, loss 0.036006, train error rate 1.333333%\n",
      "At iteration 15000, loss 0.035722, train error rate 1.333333%\n",
      "At iteration 16000, loss 0.035422, train error rate 1.333333%\n",
      "At iteration 17000, loss 0.035102, train error rate 1.333333%\n",
      "At iteration 18000, loss 0.034756, train error rate 1.333333%\n",
      "At iteration 19000, loss 0.034382, train error rate 1.333333%\n",
      "At iteration 20000, loss 0.033981, train error rate 1.333333%\n",
      "At iteration 21000, loss 0.033556, train error rate 1.333333%\n",
      "At iteration 22000, loss 0.033113, train error rate 1.333333%\n",
      "At iteration 23000, loss 0.032655, train error rate 1.333333%\n",
      "At iteration 24000, loss 0.032181, train error rate 1.333333%\n",
      "At iteration 25000, loss 0.031691, train error rate 1.333333%\n",
      "At iteration 26000, loss 0.031185, train error rate 1.333333%\n",
      "At iteration 27000, loss 0.030660, train error rate 1.333333%\n",
      "At iteration 28000, loss 0.030109, train error rate 1.333333%\n",
      "At iteration 29000, loss 0.029518, train error rate 1.333333%\n",
      "At iteration 30000, loss 0.028857, train error rate 1.333333%\n",
      "At iteration 31000, loss 0.028097, train error rate 1.333333%\n",
      "At iteration 32000, loss 0.027230, train error rate 1.333333%\n",
      "At iteration 33000, loss 0.026267, train error rate 1.333333%\n",
      "At iteration 34000, loss 0.025221, train error rate 1.333333%\n",
      "At iteration 35000, loss 0.024100, train error rate 1.333333%\n",
      "At iteration 36000, loss 0.022914, train error rate 1.333333%\n",
      "At iteration 37000, loss 0.021668, train error rate 1.333333%\n",
      "At iteration 38000, loss 0.020367, train error rate 1.333333%\n",
      "At iteration 39000, loss 0.019021, train error rate 0.666667%\n",
      "At iteration 40000, loss 0.017654, train error rate 0.666667%\n",
      "At iteration 41000, loss 0.016293, train error rate 0.666667%\n",
      "At iteration 42000, loss 0.014971, train error rate 0.666667%\n",
      "At iteration 43000, loss 0.013714, train error rate 0.000000%\n",
      "At iteration 44000, loss 0.012539, train error rate 0.000000%\n",
      "At iteration 45000, loss 0.011457, train error rate 0.000000%\n",
      "At iteration 46000, loss 0.010470, train error rate 0.000000%\n",
      "At iteration 47000, loss 0.009576, train error rate 0.000000%\n",
      "At iteration 48000, loss 0.008771, train error rate 0.000000%\n",
      "At iteration 49000, loss 0.008050, train error rate 0.000000%\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here we verify that the network can be trained on Irises.\n",
    "# Most runs should result in 100% accurracy\n",
    "#\n",
    "\n",
    "net = FeedForwardNet([\n",
    "        AffineLayer(4,10),\n",
    "        TanhLayer(),\n",
    "        AffineLayer(10,3),\n",
    "        SoftMaxLayer()\n",
    "        ])\n",
    "GD(net, IrisX,IrisY, 1e-1, tolerance=1e-7, max_iters=50000)\n",
    "#GD(net, IrisX,IrisY, 1e-1, tolerance=1e-7, max_iters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from Fuel\n",
    "\n",
    "The following cell prepares the data pipeline in fuel. please see SGD template for usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuel.datasets.mnist import MNIST\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "\n",
    "MNIST.default_transformers = (\n",
    "    (ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "    (Cast, [np.float32], {'which_sources': 'features'}), \n",
    "    (Flatten, [], {'which_sources': 'features'}),\n",
    "    (Mapping, [lambda batch: (b.T for b in batch)], {}) )\n",
    "\n",
    "mnist_train = MNIST((\"train\",), subset=slice(None,50000))\n",
    "#this stream will shuffle the MNIST set and return us batches of 100 examples\n",
    "mnist_train_stream = DataStream.default_stream(\n",
    "    mnist_train,\n",
    "    iteration_scheme=ShuffledScheme(mnist_train.num_examples, 100))\n",
    "                                               \n",
    "mnist_validation = MNIST((\"train\",), subset=slice(50000, None))\n",
    "\n",
    "# We will use larger portions for testing and validation\n",
    "# as these dont do a backward pass and reauire less RAM.\n",
    "mnist_validation_stream = DataStream.default_stream(\n",
    "    mnist_validation, iteration_scheme=SequentialScheme(mnist_validation.num_examples, 250))\n",
    "mnist_test = MNIST((\"test\",))\n",
    "mnist_test_stream = DataStream.default_stream(\n",
    "    mnist_test, iteration_scheme=SequentialScheme(mnist_test.num_examples, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The streams return batches containing (u'features', u'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (784, 100) containing float32\n",
      " - an array of size (1, 100) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (784, 250) containing float32\n",
      " - an array of size (1, 250) containing uint8\n"
     ]
    }
   ],
   "source": [
    "print \"The streams return batches containing %s\" % (mnist_train_stream.sources,)\n",
    "\n",
    "print \"Each trainin batch consits of a tuple containing:\"\n",
    "for element in next(mnist_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "    \n",
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(mnist_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 [4p]\n",
    "\n",
    "Implement the following additions to the SGD code below:\n",
    "1. Momentum [2p]\n",
    "2. Learning rate schedule [1p]\n",
    "3. Weight decay [1p]. One way to implement it is to use the functions `net.params` and `net.param_names` to get all parameters whose names are \"W\" and not \"b\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Please note, the code blow is able to train a SoftMax regression model on mnist to poor results (ca 8%test error), \n",
    "# you must improve it\n",
    "#\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy.linalg\n",
    "\n",
    "def compute_error_rate(net, stream):\n",
    "    num_errs = 0.0\n",
    "    num_examples = 0\n",
    "            \n",
    "    for X, Y in stream.get_epoch_iterator():\n",
    "        O = net.fprop(X)\n",
    "        num_errs += (O.argmax(0) != Y).sum()\n",
    "        num_examples += X.shape[1]\n",
    "            \n",
    "    return num_errs/num_examples\n",
    "\n",
    "def print_stats(train_loss, train_errors, validation_errors):\n",
    "    subplot(2,1,1)\n",
    "    train_loss = np.array(train_loss)\n",
    "    semilogy(train_loss[:,0], train_loss[:,1], label='batch train loss')\n",
    "    legend()\n",
    "\n",
    "    subplot(2,1,2)\n",
    "    train_errors = np.array(train_errors)\n",
    "    plot(train_errors[:,0], train_errors[:,1], label='batch train error rate')\n",
    "    validation_errors = np.array(validation_errors)\n",
    "    plot(validation_errors[:,0], validation_errors[:,1], label='validation error rate', color='r')\n",
    "    ylim(0,0.2)\n",
    "    legend()\n",
    "\n",
    "class AlphaAlgExp:\n",
    "    def __init__(self, initial = 5e-2, rate = 0.998):\n",
    "        self.initial = initial\n",
    "        self.rate = rate\n",
    "    \n",
    "    def __call__(self, i, e):\n",
    "        return (self.initial * np.power(self.rate, e))\n",
    "    \n",
    "class AlphaAlgBct:\n",
    "    def __init__(self, b = 1e3, c = 2e4):\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "    \n",
    "    def __call__(self, i, e):\n",
    "        return (self.b / (self.c + i))\n",
    "    \n",
    "class AlphaAlgConst:\n",
    "    def __init__(self, constant = 1e-2):\n",
    "        self.constant = constant\n",
    "        \n",
    "    def __call__(self, i, e):\n",
    "        return self.constant\n",
    "    \n",
    "    \n",
    "class MomentumAlgConst:\n",
    "    def __init__(self, constant = 0.5):\n",
    "        self.constant = constant\n",
    "        \n",
    "    def __call__(self, i):\n",
    "        return self.constant\n",
    "    \n",
    "class MomentumAlg1:\n",
    "    def __call__(self, i, e):\n",
    "        return (1. - 3. / (5. + i))\n",
    "\n",
    "class MomentumAlg2:\n",
    "    def __call__(self, i, e, limit = 0.9):\n",
    "        v = (1. - 3. / (5. + i))\n",
    "        return (v if v < limit else limit)\n",
    "    \n",
    "class MomentumAlg3:\n",
    "    def __init__(self, start = 0.5, stop = 0.9, epochs = 500):\n",
    "        self.start = start\n",
    "        self.stop = stop\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def __call__(self, i, e):\n",
    "        if e >= self.epochs:\n",
    "            return self.stop\n",
    "        else:\n",
    "            c = e / self.epochs\n",
    "            return c * self.start + (1. - c) * self.stop\n",
    "\n",
    "def SGD(net, train_stream, validation_stream, test_stream,\n",
    "        print_debug = True,\n",
    "        epochs = 3,\n",
    "        patience = 1.5,\n",
    "        alpha_alg = AlphaAlgExp(),\n",
    "        momentum_alg = MomentumAlg1(),\n",
    "        regularization_rate = 1e-3,\n",
    "        norm_limiting = None,\n",
    "        dropout = None):\n",
    "    \n",
    "    print \"Network configuration: \"\n",
    "    print \", \".join([ \"%s%s\" %(N, P.shape) for P, N in zip(net.parameters, net.parameter_names) ])\n",
    "    \n",
    "    i=0\n",
    "    e=0\n",
    "    \n",
    "    velocities = [np.zeros(P.shape) for P in net.parameters]\n",
    "    \n",
    "    best_valid_error_rate = np.inf\n",
    "    best_params = deepcopy(net.parameters)\n",
    "    best_params_epoch = 0\n",
    "    \n",
    "    alpha = None\n",
    "    \n",
    "    train_errors = []\n",
    "    train_loss = []\n",
    "    validation_errors = []\n",
    "    \n",
    "    number_of_epochs = epochs\n",
    "    patience_expansion = patience\n",
    "    \n",
    "    try:\n",
    "        while e<number_of_epochs: #This loop goes over epochs\n",
    "            e += 1\n",
    "            #First train on all data from this batch\n",
    "            for X,Y in train_stream.get_epoch_iterator(): \n",
    "                i += 1\n",
    "                L, O, gradients = net.get_cost_and_gradient(X, Y)\n",
    "                err_rate = (O.argmax(0) != Y).mean()\n",
    "                train_loss.append((i,L))\n",
    "                train_errors.append((i,err_rate))\n",
    "                if i % 100 == 0 and print_debug:\n",
    "                    print \"At minibatch %d, batch loss %f, batch error rate %f%%\" % (i, L, err_rate*100)\n",
    "                for P, V, G, N in zip(net.parameters, velocities, gradients, net.parameter_names):\n",
    "                    if N=='W' and regularization_rate:\n",
    "                        G += regularization_rate * P\n",
    "                        \n",
    "                    \n",
    "                    alpha = alpha_alg(i, e)\n",
    "                    \n",
    "                    epsilon = momentum_alg(i, e)\n",
    "                    \n",
    "                    #V = epsilon * V - (1. - epsilon) * alpha * G\n",
    "                    V = epsilon * V - alpha * G\n",
    "                    \n",
    "                    P += V\n",
    "                    \n",
    "                    if N=='W' and norm_limiting:\n",
    "                        nrm = np.linalg.norm(P, axis = 1)\n",
    "                        P[nrm > norm_limiting] = P[nrm > norm_limiting] / (nrm[nrm > norm_limiting].reshape(-1, 1) * norm_limiting)\n",
    "                            \n",
    "                    \n",
    "            # After an epoch compute validation error\n",
    "            val_error_rate = compute_error_rate(net, validation_stream)\n",
    "\n",
    "            if val_error_rate < best_valid_error_rate:\n",
    "                number_of_epochs = np.maximum(number_of_epochs, e * patience_expansion+1)\n",
    "                best_valid_error_rate = val_error_rate\n",
    "                best_params = deepcopy(net.parameters)\n",
    "                best_params_epoch = e\n",
    "                validation_errors.append((i,val_error_rate))\n",
    "            if print_debug or (e % 20 == 1):\n",
    "                print \"After epoch %d: valid_err_rate: %f%% currently going ot do %d epochs [best: %f%%]\" %(\n",
    "                    e, val_error_rate, number_of_epochs, best_valid_error_rate)\n",
    "        print \"Finished with %d epochs (minibatch %d), with best valid error rate %f\" % (e, i, best_valid_error_rate)\n",
    "        print_stats(train_loss, train_errors, validation_errors)\n",
    "    except KeyboardInterrupt:\n",
    "        print \"Setting network parameters from after epoch %d\" %(best_params_epoch)\n",
    "        net.parameters = best_params\n",
    "        print_stats(train_loss, train_errors, validation_errors)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 [5p]\n",
    "\n",
    "Tune the following network to reach below 1.9% error rate on\n",
    "the validation set. This should result in a test error below 2%. To\n",
    "tune the network you will need to:\n",
    "1. choose the number of layers (more than 1, less than 5),\n",
    "2. choose the number of neurons in each layer (more than 100,\n",
    "    less than 5000),\n",
    "3. pick proper weight initialization,\n",
    "4. pick proper learning rate schedule (need to decay over time,\n",
    "    good range to check on MNIST is about 1e-2 ... 1e-1 at the beginning and\n",
    "    half of that after 10000 batches),\n",
    "5. pick a momentum constant (probably a constant one will be OK).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network configuration: \n",
      "W(800, 784), b(800, 1), W(800, 800), b(800, 1), W(10, 800), b(10, 1)\n",
      "At minibatch 100, batch loss 0.417986, batch error rate 10.000000%\n",
      "At minibatch 200, batch loss 0.427327, batch error rate 11.000000%\n",
      "At minibatch 300, batch loss 0.262817, batch error rate 11.000000%\n",
      "At minibatch 400, batch loss 0.488589, batch error rate 12.000000%\n",
      "At minibatch 500, batch loss 0.382394, batch error rate 12.000000%\n",
      "After epoch 1: valid_err_rate: 0.068500% currently going ot do 3 epochs [best: 0.068500%]\n",
      "At minibatch 600, batch loss 0.181788, batch error rate 5.000000%\n",
      "At minibatch 700, batch loss 0.222348, batch error rate 7.000000%\n",
      "At minibatch 800, batch loss 0.260655, batch error rate 8.000000%\n",
      "At minibatch 900, batch loss 0.205376, batch error rate 6.000000%\n",
      "At minibatch 1000, batch loss 0.229170, batch error rate 5.000000%\n",
      "After epoch 2: valid_err_rate: 0.050900% currently going ot do 4 epochs [best: 0.050900%]\n",
      "At minibatch 1100, batch loss 0.172597, batch error rate 4.000000%\n",
      "At minibatch 1200, batch loss 0.149599, batch error rate 4.000000%\n",
      "At minibatch 1300, batch loss 0.186692, batch error rate 6.000000%\n",
      "At minibatch 1400, batch loss 0.174771, batch error rate 6.000000%\n",
      "At minibatch 1500, batch loss 0.122935, batch error rate 4.000000%\n",
      "After epoch 3: valid_err_rate: 0.043000% currently going ot do 5 epochs [best: 0.043000%]\n",
      "At minibatch 1600, batch loss 0.237922, batch error rate 8.000000%\n",
      "At minibatch 1700, batch loss 0.129161, batch error rate 5.000000%\n",
      "At minibatch 1800, batch loss 0.190453, batch error rate 5.000000%\n",
      "At minibatch 1900, batch loss 0.195714, batch error rate 5.000000%\n",
      "At minibatch 2000, batch loss 0.134309, batch error rate 3.000000%\n",
      "After epoch 4: valid_err_rate: 0.038800% currently going ot do 7 epochs [best: 0.038800%]\n",
      "At minibatch 2100, batch loss 0.309411, batch error rate 11.000000%\n",
      "At minibatch 2200, batch loss 0.134621, batch error rate 3.000000%\n",
      "At minibatch 2300, batch loss 0.200403, batch error rate 4.000000%\n",
      "At minibatch 2400, batch loss 0.259687, batch error rate 9.000000%\n",
      "At minibatch 2500, batch loss 0.103394, batch error rate 4.000000%\n",
      "After epoch 5: valid_err_rate: 0.031900% currently going ot do 8 epochs [best: 0.031900%]\n",
      "At minibatch 2600, batch loss 0.096136, batch error rate 3.000000%\n",
      "At minibatch 2700, batch loss 0.089427, batch error rate 3.000000%\n",
      "At minibatch 2800, batch loss 0.142253, batch error rate 4.000000%\n",
      "At minibatch 2900, batch loss 0.109618, batch error rate 4.000000%\n",
      "At minibatch 3000, batch loss 0.119443, batch error rate 2.000000%\n",
      "After epoch 6: valid_err_rate: 0.034300% currently going ot do 8 epochs [best: 0.031900%]\n",
      "At minibatch 3100, batch loss 0.075378, batch error rate 2.000000%\n",
      "At minibatch 3200, batch loss 0.104489, batch error rate 4.000000%\n",
      "At minibatch 3300, batch loss 0.128839, batch error rate 4.000000%\n",
      "At minibatch 3400, batch loss 0.083537, batch error rate 3.000000%\n",
      "At minibatch 3500, batch loss 0.108984, batch error rate 5.000000%\n",
      "After epoch 7: valid_err_rate: 0.031900% currently going ot do 8 epochs [best: 0.031900%]\n",
      "At minibatch 3600, batch loss 0.058499, batch error rate 1.000000%\n",
      "At minibatch 3700, batch loss 0.074944, batch error rate 2.000000%\n",
      "At minibatch 3800, batch loss 0.074663, batch error rate 1.000000%\n",
      "At minibatch 3900, batch loss 0.059663, batch error rate 2.000000%\n",
      "At minibatch 4000, batch loss 0.209681, batch error rate 7.000000%\n",
      "After epoch 8: valid_err_rate: 0.028000% currently going ot do 13 epochs [best: 0.028000%]\n",
      "At minibatch 4100, batch loss 0.127746, batch error rate 3.000000%\n",
      "At minibatch 4200, batch loss 0.093484, batch error rate 3.000000%\n",
      "At minibatch 4300, batch loss 0.078075, batch error rate 1.000000%\n",
      "At minibatch 4400, batch loss 0.066245, batch error rate 1.000000%\n",
      "At minibatch 4500, batch loss 0.143469, batch error rate 7.000000%\n",
      "After epoch 9: valid_err_rate: 0.031100% currently going ot do 13 epochs [best: 0.028000%]\n",
      "At minibatch 4600, batch loss 0.062598, batch error rate 2.000000%\n",
      "At minibatch 4700, batch loss 0.116331, batch error rate 4.000000%\n",
      "At minibatch 4800, batch loss 0.058727, batch error rate 1.000000%\n",
      "At minibatch 4900, batch loss 0.140078, batch error rate 1.000000%\n",
      "At minibatch 5000, batch loss 0.035475, batch error rate 0.000000%\n",
      "After epoch 10: valid_err_rate: 0.026300% currently going ot do 16 epochs [best: 0.026300%]\n",
      "At minibatch 5100, batch loss 0.052649, batch error rate 1.000000%\n",
      "At minibatch 5200, batch loss 0.085547, batch error rate 2.000000%\n",
      "At minibatch 5300, batch loss 0.094464, batch error rate 2.000000%\n",
      "At minibatch 5400, batch loss 0.042279, batch error rate 0.000000%\n",
      "At minibatch 5500, batch loss 0.099626, batch error rate 3.000000%\n",
      "After epoch 11: valid_err_rate: 0.026000% currently going ot do 17 epochs [best: 0.026000%]\n",
      "At minibatch 5600, batch loss 0.112177, batch error rate 2.000000%\n",
      "At minibatch 5700, batch loss 0.128881, batch error rate 4.000000%\n",
      "At minibatch 5800, batch loss 0.047106, batch error rate 0.000000%\n",
      "At minibatch 5900, batch loss 0.079798, batch error rate 2.000000%\n",
      "At minibatch 6000, batch loss 0.056914, batch error rate 1.000000%\n",
      "After epoch 12: valid_err_rate: 0.026000% currently going ot do 17 epochs [best: 0.026000%]\n",
      "At minibatch 6100, batch loss 0.066793, batch error rate 2.000000%\n",
      "At minibatch 6200, batch loss 0.093765, batch error rate 2.000000%\n",
      "At minibatch 6300, batch loss 0.094547, batch error rate 4.000000%\n",
      "At minibatch 6400, batch loss 0.069239, batch error rate 2.000000%\n",
      "At minibatch 6500, batch loss 0.039838, batch error rate 1.000000%\n",
      "After epoch 13: valid_err_rate: 0.025800% currently going ot do 20 epochs [best: 0.025800%]\n",
      "At minibatch 6600, batch loss 0.065708, batch error rate 1.000000%\n",
      "At minibatch 6700, batch loss 0.056837, batch error rate 2.000000%\n",
      "At minibatch 6800, batch loss 0.033565, batch error rate 0.000000%\n",
      "At minibatch 6900, batch loss 0.037309, batch error rate 1.000000%\n",
      "At minibatch 7000, batch loss 0.077398, batch error rate 2.000000%\n",
      "After epoch 14: valid_err_rate: 0.024600% currently going ot do 22 epochs [best: 0.024600%]\n",
      "At minibatch 7100, batch loss 0.072781, batch error rate 2.000000%\n",
      "At minibatch 7200, batch loss 0.031714, batch error rate 0.000000%\n",
      "At minibatch 7300, batch loss 0.070401, batch error rate 3.000000%\n",
      "At minibatch 7400, batch loss 0.091795, batch error rate 3.000000%\n",
      "At minibatch 7500, batch loss 0.055031, batch error rate 1.000000%\n",
      "After epoch 15: valid_err_rate: 0.023700% currently going ot do 23 epochs [best: 0.023700%]\n",
      "At minibatch 7600, batch loss 0.012801, batch error rate 0.000000%\n",
      "At minibatch 7700, batch loss 0.050084, batch error rate 2.000000%\n",
      "At minibatch 7800, batch loss 0.065295, batch error rate 1.000000%\n",
      "At minibatch 7900, batch loss 0.028225, batch error rate 1.000000%\n",
      "At minibatch 8000, batch loss 0.049550, batch error rate 1.000000%\n",
      "After epoch 16: valid_err_rate: 0.025100% currently going ot do 23 epochs [best: 0.023700%]\n",
      "At minibatch 8100, batch loss 0.104171, batch error rate 2.000000%\n",
      "At minibatch 8200, batch loss 0.023960, batch error rate 0.000000%\n",
      "At minibatch 8300, batch loss 0.063516, batch error rate 2.000000%\n",
      "At minibatch 8400, batch loss 0.038184, batch error rate 1.000000%\n",
      "At minibatch 8500, batch loss 0.041720, batch error rate 2.000000%\n",
      "After epoch 17: valid_err_rate: 0.022400% currently going ot do 26 epochs [best: 0.022400%]\n",
      "At minibatch 8600, batch loss 0.073852, batch error rate 1.000000%\n",
      "At minibatch 8700, batch loss 0.016963, batch error rate 0.000000%\n",
      "At minibatch 8800, batch loss 0.033930, batch error rate 0.000000%\n",
      "At minibatch 8900, batch loss 0.051254, batch error rate 1.000000%\n",
      "At minibatch 9000, batch loss 0.036388, batch error rate 0.000000%\n",
      "After epoch 18: valid_err_rate: 0.023000% currently going ot do 26 epochs [best: 0.022400%]\n",
      "At minibatch 9100, batch loss 0.078840, batch error rate 4.000000%\n",
      "At minibatch 9200, batch loss 0.043832, batch error rate 2.000000%\n",
      "At minibatch 9300, batch loss 0.030912, batch error rate 0.000000%\n",
      "At minibatch 9400, batch loss 0.071220, batch error rate 2.000000%\n",
      "At minibatch 9500, batch loss 0.061335, batch error rate 2.000000%\n",
      "After epoch 19: valid_err_rate: 0.022600% currently going ot do 26 epochs [best: 0.022400%]\n",
      "At minibatch 9600, batch loss 0.095030, batch error rate 3.000000%\n",
      "At minibatch 9700, batch loss 0.029181, batch error rate 0.000000%\n",
      "At minibatch 9800, batch loss 0.029067, batch error rate 0.000000%\n",
      "At minibatch 9900, batch loss 0.033142, batch error rate 1.000000%\n",
      "At minibatch 10000, batch loss 0.053650, batch error rate 1.000000%\n",
      "After epoch 20: valid_err_rate: 0.022500% currently going ot do 26 epochs [best: 0.022400%]\n",
      "At minibatch 10100, batch loss 0.033358, batch error rate 0.000000%\n",
      "At minibatch 10200, batch loss 0.022750, batch error rate 0.000000%\n",
      "At minibatch 10300, batch loss 0.047834, batch error rate 1.000000%\n",
      "At minibatch 10400, batch loss 0.066249, batch error rate 2.000000%\n",
      "At minibatch 10500, batch loss 0.088213, batch error rate 2.000000%\n",
      "After epoch 21: valid_err_rate: 0.023700% currently going ot do 26 epochs [best: 0.022400%]\n",
      "At minibatch 10600, batch loss 0.049547, batch error rate 1.000000%\n",
      "At minibatch 10700, batch loss 0.019940, batch error rate 0.000000%\n",
      "At minibatch 10800, batch loss 0.052610, batch error rate 0.000000%\n",
      "At minibatch 10900, batch loss 0.028231, batch error rate 0.000000%\n",
      "At minibatch 11000, batch loss 0.029507, batch error rate 1.000000%\n",
      "After epoch 22: valid_err_rate: 0.025500% currently going ot do 26 epochs [best: 0.022400%]\n",
      "At minibatch 11100, batch loss 0.066112, batch error rate 3.000000%\n",
      "At minibatch 11200, batch loss 0.047617, batch error rate 2.000000%\n",
      "At minibatch 11300, batch loss 0.045563, batch error rate 1.000000%\n",
      "At minibatch 11400, batch loss 0.066201, batch error rate 2.000000%\n",
      "At minibatch 11500, batch loss 0.049983, batch error rate 2.000000%\n",
      "After epoch 23: valid_err_rate: 0.021900% currently going ot do 35 epochs [best: 0.021900%]\n",
      "At minibatch 11600, batch loss 0.030132, batch error rate 1.000000%\n",
      "At minibatch 11700, batch loss 0.022175, batch error rate 0.000000%\n",
      "At minibatch 11800, batch loss 0.022429, batch error rate 0.000000%\n",
      "At minibatch 11900, batch loss 0.027522, batch error rate 1.000000%\n",
      "At minibatch 12000, batch loss 0.083677, batch error rate 4.000000%\n",
      "After epoch 24: valid_err_rate: 0.023100% currently going ot do 35 epochs [best: 0.021900%]\n",
      "At minibatch 12100, batch loss 0.071543, batch error rate 2.000000%\n",
      "At minibatch 12200, batch loss 0.043897, batch error rate 1.000000%\n",
      "At minibatch 12300, batch loss 0.034321, batch error rate 1.000000%\n",
      "At minibatch 12400, batch loss 0.016325, batch error rate 0.000000%\n",
      "At minibatch 12500, batch loss 0.029153, batch error rate 1.000000%\n",
      "After epoch 25: valid_err_rate: 0.022000% currently going ot do 35 epochs [best: 0.021900%]\n",
      "At minibatch 12600, batch loss 0.029559, batch error rate 0.000000%\n",
      "At minibatch 12700, batch loss 0.016616, batch error rate 0.000000%\n",
      "At minibatch 12800, batch loss 0.046045, batch error rate 1.000000%\n",
      "At minibatch 12900, batch loss 0.059772, batch error rate 2.000000%\n",
      "At minibatch 13000, batch loss 0.055600, batch error rate 0.000000%\n",
      "After epoch 26: valid_err_rate: 0.022200% currently going ot do 35 epochs [best: 0.021900%]\n",
      "At minibatch 13100, batch loss 0.024721, batch error rate 0.000000%\n",
      "At minibatch 13200, batch loss 0.065602, batch error rate 2.000000%\n",
      "At minibatch 13300, batch loss 0.042516, batch error rate 1.000000%\n",
      "At minibatch 13400, batch loss 0.047511, batch error rate 1.000000%\n",
      "At minibatch 13500, batch loss 0.021591, batch error rate 0.000000%\n",
      "After epoch 27: valid_err_rate: 0.020700% currently going ot do 41 epochs [best: 0.020700%]\n",
      "At minibatch 13600, batch loss 0.040367, batch error rate 1.000000%\n",
      "At minibatch 13700, batch loss 0.045182, batch error rate 2.000000%\n",
      "At minibatch 13800, batch loss 0.021054, batch error rate 1.000000%\n",
      "At minibatch 13900, batch loss 0.031059, batch error rate 0.000000%\n",
      "At minibatch 14000, batch loss 0.018837, batch error rate 0.000000%\n",
      "After epoch 28: valid_err_rate: 0.021000% currently going ot do 41 epochs [best: 0.020700%]\n",
      "At minibatch 14100, batch loss 0.029656, batch error rate 1.000000%\n",
      "At minibatch 14200, batch loss 0.031718, batch error rate 0.000000%\n",
      "At minibatch 14300, batch loss 0.069875, batch error rate 2.000000%\n",
      "At minibatch 14400, batch loss 0.057638, batch error rate 1.000000%\n",
      "At minibatch 14500, batch loss 0.086869, batch error rate 4.000000%\n",
      "After epoch 29: valid_err_rate: 0.023200% currently going ot do 41 epochs [best: 0.020700%]\n",
      "At minibatch 14600, batch loss 0.013683, batch error rate 0.000000%\n",
      "At minibatch 14700, batch loss 0.051817, batch error rate 0.000000%\n",
      "At minibatch 14800, batch loss 0.030607, batch error rate 0.000000%\n",
      "At minibatch 14900, batch loss 0.052241, batch error rate 2.000000%\n",
      "At minibatch 15000, batch loss 0.049573, batch error rate 1.000000%\n",
      "After epoch 30: valid_err_rate: 0.022300% currently going ot do 41 epochs [best: 0.020700%]\n",
      "At minibatch 15100, batch loss 0.045861, batch error rate 1.000000%\n",
      "At minibatch 15200, batch loss 0.029858, batch error rate 0.000000%\n",
      "At minibatch 15300, batch loss 0.023483, batch error rate 0.000000%\n",
      "At minibatch 15400, batch loss 0.027306, batch error rate 0.000000%\n",
      "At minibatch 15500, batch loss 0.021248, batch error rate 0.000000%\n",
      "After epoch 31: valid_err_rate: 0.020300% currently going ot do 47 epochs [best: 0.020300%]\n",
      "At minibatch 15600, batch loss 0.051264, batch error rate 2.000000%\n",
      "At minibatch 15700, batch loss 0.020880, batch error rate 0.000000%\n",
      "At minibatch 15800, batch loss 0.037074, batch error rate 1.000000%\n",
      "At minibatch 15900, batch loss 0.017933, batch error rate 0.000000%\n",
      "At minibatch 16000, batch loss 0.030651, batch error rate 0.000000%\n",
      "After epoch 32: valid_err_rate: 0.020900% currently going ot do 47 epochs [best: 0.020300%]\n",
      "At minibatch 16100, batch loss 0.032504, batch error rate 1.000000%\n",
      "At minibatch 16200, batch loss 0.026106, batch error rate 1.000000%\n",
      "At minibatch 16300, batch loss 0.071734, batch error rate 2.000000%\n",
      "At minibatch 16400, batch loss 0.055699, batch error rate 1.000000%\n",
      "At minibatch 16500, batch loss 0.027779, batch error rate 1.000000%\n",
      "After epoch 33: valid_err_rate: 0.021300% currently going ot do 47 epochs [best: 0.020300%]\n",
      "At minibatch 16600, batch loss 0.028146, batch error rate 0.000000%\n",
      "At minibatch 16700, batch loss 0.055644, batch error rate 1.000000%\n",
      "At minibatch 16800, batch loss 0.013240, batch error rate 0.000000%\n",
      "At minibatch 16900, batch loss 0.016924, batch error rate 0.000000%\n",
      "At minibatch 17000, batch loss 0.051614, batch error rate 2.000000%\n",
      "After epoch 34: valid_err_rate: 0.021700% currently going ot do 47 epochs [best: 0.020300%]\n",
      "At minibatch 17100, batch loss 0.015178, batch error rate 0.000000%\n",
      "At minibatch 17200, batch loss 0.033319, batch error rate 0.000000%\n",
      "At minibatch 17300, batch loss 0.042784, batch error rate 1.000000%\n",
      "At minibatch 17400, batch loss 0.037866, batch error rate 1.000000%\n",
      "At minibatch 17500, batch loss 0.062577, batch error rate 2.000000%\n",
      "After epoch 35: valid_err_rate: 0.020800% currently going ot do 47 epochs [best: 0.020300%]\n",
      "At minibatch 17600, batch loss 0.070076, batch error rate 2.000000%\n",
      "At minibatch 17700, batch loss 0.021942, batch error rate 0.000000%\n",
      "At minibatch 17800, batch loss 0.028038, batch error rate 0.000000%\n",
      "At minibatch 17900, batch loss 0.011166, batch error rate 0.000000%\n",
      "At minibatch 18000, batch loss 0.036558, batch error rate 0.000000%\n",
      "After epoch 36: valid_err_rate: 0.019900% currently going ot do 55 epochs [best: 0.019900%]\n",
      "At minibatch 18100, batch loss 0.014507, batch error rate 0.000000%\n",
      "At minibatch 18200, batch loss 0.033883, batch error rate 0.000000%\n",
      "At minibatch 18300, batch loss 0.023962, batch error rate 1.000000%\n",
      "At minibatch 18400, batch loss 0.022473, batch error rate 0.000000%\n",
      "At minibatch 18500, batch loss 0.020274, batch error rate 0.000000%\n",
      "After epoch 37: valid_err_rate: 0.020000% currently going ot do 55 epochs [best: 0.019900%]\n",
      "At minibatch 18600, batch loss 0.044461, batch error rate 1.000000%\n",
      "At minibatch 18700, batch loss 0.046504, batch error rate 1.000000%\n",
      "At minibatch 18800, batch loss 0.028889, batch error rate 1.000000%\n",
      "At minibatch 18900, batch loss 0.032840, batch error rate 1.000000%\n",
      "At minibatch 19000, batch loss 0.082889, batch error rate 3.000000%\n",
      "After epoch 38: valid_err_rate: 0.020300% currently going ot do 55 epochs [best: 0.019900%]\n",
      "At minibatch 19100, batch loss 0.121764, batch error rate 5.000000%\n",
      "At minibatch 19200, batch loss 0.060392, batch error rate 1.000000%\n",
      "At minibatch 19300, batch loss 0.018728, batch error rate 0.000000%\n",
      "At minibatch 19400, batch loss 0.043951, batch error rate 1.000000%\n",
      "At minibatch 19500, batch loss 0.047265, batch error rate 1.000000%\n",
      "After epoch 39: valid_err_rate: 0.020900% currently going ot do 55 epochs [best: 0.019900%]\n",
      "At minibatch 19600, batch loss 0.035973, batch error rate 1.000000%\n",
      "At minibatch 19700, batch loss 0.034996, batch error rate 0.000000%\n",
      "At minibatch 19800, batch loss 0.018481, batch error rate 0.000000%\n",
      "At minibatch 19900, batch loss 0.017245, batch error rate 0.000000%\n",
      "At minibatch 20000, batch loss 0.021271, batch error rate 0.000000%\n",
      "After epoch 40: valid_err_rate: 0.019200% currently going ot do 61 epochs [best: 0.019200%]\n",
      "At minibatch 20100, batch loss 0.021487, batch error rate 0.000000%\n",
      "At minibatch 20200, batch loss 0.046346, batch error rate 1.000000%\n",
      "At minibatch 20300, batch loss 0.025990, batch error rate 1.000000%\n",
      "At minibatch 20400, batch loss 0.038103, batch error rate 0.000000%\n",
      "At minibatch 20500, batch loss 0.014388, batch error rate 0.000000%\n",
      "After epoch 41: valid_err_rate: 0.020200% currently going ot do 61 epochs [best: 0.019200%]\n",
      "At minibatch 20600, batch loss 0.039185, batch error rate 1.000000%\n",
      "At minibatch 20700, batch loss 0.052272, batch error rate 1.000000%\n",
      "At minibatch 20800, batch loss 0.032811, batch error rate 1.000000%\n",
      "At minibatch 20900, batch loss 0.022298, batch error rate 1.000000%\n",
      "At minibatch 21000, batch loss 0.027502, batch error rate 0.000000%\n",
      "After epoch 42: valid_err_rate: 0.020200% currently going ot do 61 epochs [best: 0.019200%]\n",
      "At minibatch 21100, batch loss 0.046083, batch error rate 0.000000%\n",
      "At minibatch 21200, batch loss 0.025985, batch error rate 0.000000%\n",
      "At minibatch 21300, batch loss 0.028990, batch error rate 0.000000%\n",
      "At minibatch 21400, batch loss 0.052150, batch error rate 1.000000%\n",
      "At minibatch 21500, batch loss 0.029470, batch error rate 0.000000%\n",
      "After epoch 43: valid_err_rate: 0.021100% currently going ot do 61 epochs [best: 0.019200%]\n",
      "At minibatch 21600, batch loss 0.025602, batch error rate 0.000000%\n",
      "At minibatch 21700, batch loss 0.038401, batch error rate 1.000000%\n",
      "At minibatch 21800, batch loss 0.040246, batch error rate 1.000000%\n",
      "At minibatch 21900, batch loss 0.021048, batch error rate 0.000000%\n",
      "At minibatch 22000, batch loss 0.013295, batch error rate 0.000000%\n",
      "After epoch 44: valid_err_rate: 0.019000% currently going ot do 67 epochs [best: 0.019000%]\n",
      "At minibatch 22100, batch loss 0.051856, batch error rate 1.000000%\n",
      "At minibatch 22200, batch loss 0.020093, batch error rate 0.000000%\n",
      "At minibatch 22300, batch loss 0.026081, batch error rate 1.000000%\n",
      "At minibatch 22400, batch loss 0.033985, batch error rate 1.000000%\n",
      "At minibatch 22500, batch loss 0.029265, batch error rate 0.000000%\n",
      "After epoch 45: valid_err_rate: 0.020900% currently going ot do 67 epochs [best: 0.019000%]\n",
      "At minibatch 22600, batch loss 0.013124, batch error rate 0.000000%\n",
      "At minibatch 22700, batch loss 0.021814, batch error rate 0.000000%\n",
      "At minibatch 22800, batch loss 0.035012, batch error rate 0.000000%\n",
      "At minibatch 22900, batch loss 0.037123, batch error rate 1.000000%\n",
      "At minibatch 23000, batch loss 0.031616, batch error rate 1.000000%\n",
      "After epoch 46: valid_err_rate: 0.020600% currently going ot do 67 epochs [best: 0.019000%]\n",
      "At minibatch 23100, batch loss 0.026385, batch error rate 0.000000%\n",
      "At minibatch 23200, batch loss 0.015396, batch error rate 0.000000%\n",
      "At minibatch 23300, batch loss 0.026721, batch error rate 1.000000%\n",
      "At minibatch 23400, batch loss 0.031821, batch error rate 1.000000%\n",
      "At minibatch 23500, batch loss 0.074290, batch error rate 4.000000%\n",
      "After epoch 47: valid_err_rate: 0.020100% currently going ot do 67 epochs [best: 0.019000%]\n",
      "At minibatch 23600, batch loss 0.012234, batch error rate 0.000000%\n",
      "At minibatch 23700, batch loss 0.030911, batch error rate 2.000000%\n",
      "At minibatch 23800, batch loss 0.053142, batch error rate 1.000000%\n",
      "At minibatch 23900, batch loss 0.024935, batch error rate 0.000000%\n",
      "At minibatch 24000, batch loss 0.014828, batch error rate 0.000000%\n",
      "After epoch 48: valid_err_rate: 0.019600% currently going ot do 67 epochs [best: 0.019000%]\n",
      "At minibatch 24100, batch loss 0.021569, batch error rate 0.000000%\n",
      "At minibatch 24200, batch loss 0.019544, batch error rate 0.000000%\n",
      "At minibatch 24300, batch loss 0.054676, batch error rate 1.000000%\n",
      "At minibatch 24400, batch loss 0.028709, batch error rate 1.000000%\n",
      "At minibatch 24500, batch loss 0.021383, batch error rate 0.000000%\n",
      "After epoch 49: valid_err_rate: 0.020100% currently going ot do 67 epochs [best: 0.019000%]\n",
      "At minibatch 24600, batch loss 0.055861, batch error rate 1.000000%\n",
      "At minibatch 24700, batch loss 0.031602, batch error rate 0.000000%\n",
      "At minibatch 24800, batch loss 0.035659, batch error rate 0.000000%\n",
      "At minibatch 24900, batch loss 0.014135, batch error rate 0.000000%\n",
      "At minibatch 25000, batch loss 0.021046, batch error rate 0.000000%\n",
      "After epoch 50: valid_err_rate: 0.019200% currently going ot do 67 epochs [best: 0.019000%]\n",
      "At minibatch 25100, batch loss 0.011319, batch error rate 0.000000%\n",
      "At minibatch 25200, batch loss 0.032996, batch error rate 0.000000%\n",
      "At minibatch 25300, batch loss 0.049212, batch error rate 1.000000%\n",
      "At minibatch 25400, batch loss 0.033661, batch error rate 0.000000%\n",
      "At minibatch 25500, batch loss 0.024132, batch error rate 1.000000%\n",
      "After epoch 51: valid_err_rate: 0.018800% currently going ot do 77 epochs [best: 0.018800%]\n",
      "At minibatch 25600, batch loss 0.017768, batch error rate 0.000000%\n",
      "At minibatch 25700, batch loss 0.015567, batch error rate 0.000000%\n",
      "At minibatch 25800, batch loss 0.023592, batch error rate 0.000000%\n",
      "At minibatch 25900, batch loss 0.070429, batch error rate 1.000000%\n",
      "At minibatch 26000, batch loss 0.028708, batch error rate 0.000000%\n",
      "After epoch 52: valid_err_rate: 0.019300% currently going ot do 77 epochs [best: 0.018800%]\n",
      "At minibatch 26100, batch loss 0.060610, batch error rate 2.000000%\n",
      "At minibatch 26200, batch loss 0.019409, batch error rate 0.000000%\n",
      "At minibatch 26300, batch loss 0.052366, batch error rate 1.000000%\n",
      "At minibatch 26400, batch loss 0.038733, batch error rate 0.000000%\n",
      "At minibatch 26500, batch loss 0.062440, batch error rate 2.000000%\n",
      "After epoch 53: valid_err_rate: 0.020000% currently going ot do 77 epochs [best: 0.018800%]\n",
      "At minibatch 26600, batch loss 0.010192, batch error rate 0.000000%\n",
      "At minibatch 26700, batch loss 0.042363, batch error rate 1.000000%\n",
      "At minibatch 26800, batch loss 0.057158, batch error rate 2.000000%\n",
      "At minibatch 26900, batch loss 0.024389, batch error rate 0.000000%\n",
      "At minibatch 27000, batch loss 0.030892, batch error rate 0.000000%\n",
      "After epoch 54: valid_err_rate: 0.018900% currently going ot do 77 epochs [best: 0.018800%]\n",
      "At minibatch 27100, batch loss 0.021562, batch error rate 0.000000%\n",
      "At minibatch 27200, batch loss 0.013591, batch error rate 0.000000%\n",
      "At minibatch 27300, batch loss 0.020988, batch error rate 0.000000%\n",
      "At minibatch 27400, batch loss 0.012072, batch error rate 0.000000%\n",
      "At minibatch 27500, batch loss 0.029657, batch error rate 1.000000%\n",
      "After epoch 55: valid_err_rate: 0.019900% currently going ot do 77 epochs [best: 0.018800%]\n",
      "At minibatch 27600, batch loss 0.020364, batch error rate 0.000000%\n",
      "At minibatch 27700, batch loss 0.041449, batch error rate 0.000000%\n",
      "At minibatch 27800, batch loss 0.044958, batch error rate 1.000000%\n",
      "At minibatch 27900, batch loss 0.011736, batch error rate 0.000000%\n",
      "At minibatch 28000, batch loss 0.034456, batch error rate 1.000000%\n",
      "After epoch 56: valid_err_rate: 0.020100% currently going ot do 77 epochs [best: 0.018800%]\n",
      "At minibatch 28100, batch loss 0.035417, batch error rate 1.000000%\n",
      "At minibatch 28200, batch loss 0.020128, batch error rate 0.000000%\n",
      "At minibatch 28300, batch loss 0.014849, batch error rate 0.000000%\n",
      "At minibatch 28400, batch loss 0.020677, batch error rate 0.000000%\n",
      "At minibatch 28500, batch loss 0.025644, batch error rate 0.000000%\n",
      "After epoch 57: valid_err_rate: 0.019000% currently going ot do 77 epochs [best: 0.018800%]\n",
      "At minibatch 28600, batch loss 0.027188, batch error rate 0.000000%\n",
      "At minibatch 28700, batch loss 0.037838, batch error rate 1.000000%\n",
      "At minibatch 28800, batch loss 0.038837, batch error rate 1.000000%\n",
      "At minibatch 28900, batch loss 0.034069, batch error rate 1.000000%\n",
      "At minibatch 29000, batch loss 0.022688, batch error rate 1.000000%\n",
      "After epoch 58: valid_err_rate: 0.020300% currently going ot do 77 epochs [best: 0.018800%]\n",
      "At minibatch 29100, batch loss 0.025048, batch error rate 0.000000%\n",
      "At minibatch 29200, batch loss 0.049955, batch error rate 1.000000%\n",
      "At minibatch 29300, batch loss 0.036413, batch error rate 1.000000%\n",
      "At minibatch 29400, batch loss 0.022510, batch error rate 0.000000%\n",
      "At minibatch 29500, batch loss 0.034876, batch error rate 1.000000%\n",
      "After epoch 59: valid_err_rate: 0.019700% currently going ot do 77 epochs [best: 0.018800%]\n",
      "At minibatch 29600, batch loss 0.031533, batch error rate 1.000000%\n",
      "At minibatch 29700, batch loss 0.071591, batch error rate 3.000000%\n",
      "At minibatch 29800, batch loss 0.013887, batch error rate 0.000000%\n",
      "At minibatch 29900, batch loss 0.042900, batch error rate 0.000000%\n",
      "At minibatch 30000, batch loss 0.018649, batch error rate 0.000000%\n",
      "After epoch 60: valid_err_rate: 0.018800% currently going ot do 77 epochs [best: 0.018800%]\n",
      "At minibatch 30100, batch loss 0.016766, batch error rate 0.000000%\n",
      "At minibatch 30200, batch loss 0.029340, batch error rate 0.000000%\n",
      "At minibatch 30300, batch loss 0.020982, batch error rate 0.000000%\n",
      "At minibatch 30400, batch loss 0.022419, batch error rate 0.000000%\n",
      "At minibatch 30500, batch loss 0.041448, batch error rate 1.000000%\n",
      "After epoch 61: valid_err_rate: 0.018700% currently going ot do 92 epochs [best: 0.018700%]\n",
      "At minibatch 30600, batch loss 0.036593, batch error rate 2.000000%\n",
      "At minibatch 30700, batch loss 0.020906, batch error rate 0.000000%\n",
      "At minibatch 30800, batch loss 0.017693, batch error rate 0.000000%\n",
      "At minibatch 30900, batch loss 0.030431, batch error rate 0.000000%\n",
      "At minibatch 31000, batch loss 0.063003, batch error rate 1.000000%\n",
      "After epoch 62: valid_err_rate: 0.021100% currently going ot do 92 epochs [best: 0.018700%]\n",
      "At minibatch 31100, batch loss 0.024404, batch error rate 0.000000%\n",
      "At minibatch 31200, batch loss 0.021702, batch error rate 0.000000%\n",
      "At minibatch 31300, batch loss 0.021340, batch error rate 0.000000%\n",
      "At minibatch 31400, batch loss 0.031032, batch error rate 0.000000%\n",
      "At minibatch 31500, batch loss 0.018575, batch error rate 0.000000%\n",
      "After epoch 63: valid_err_rate: 0.018600% currently going ot do 95 epochs [best: 0.018600%]\n",
      "At minibatch 31600, batch loss 0.023137, batch error rate 0.000000%\n",
      "At minibatch 31700, batch loss 0.013451, batch error rate 0.000000%\n",
      "At minibatch 31800, batch loss 0.018001, batch error rate 0.000000%\n",
      "At minibatch 31900, batch loss 0.013102, batch error rate 0.000000%\n",
      "At minibatch 32000, batch loss 0.020978, batch error rate 0.000000%\n",
      "After epoch 64: valid_err_rate: 0.019900% currently going ot do 95 epochs [best: 0.018600%]\n",
      "At minibatch 32100, batch loss 0.030165, batch error rate 1.000000%\n",
      "At minibatch 32200, batch loss 0.021319, batch error rate 0.000000%\n",
      "At minibatch 32300, batch loss 0.023093, batch error rate 0.000000%\n",
      "At minibatch 32400, batch loss 0.032167, batch error rate 0.000000%\n",
      "At minibatch 32500, batch loss 0.010767, batch error rate 0.000000%\n",
      "After epoch 65: valid_err_rate: 0.017900% currently going ot do 98 epochs [best: 0.017900%]\n",
      "At minibatch 32600, batch loss 0.017922, batch error rate 1.000000%\n",
      "At minibatch 32700, batch loss 0.021568, batch error rate 0.000000%\n",
      "At minibatch 32800, batch loss 0.015530, batch error rate 0.000000%\n",
      "At minibatch 32900, batch loss 0.061826, batch error rate 1.000000%\n",
      "At minibatch 33000, batch loss 0.045409, batch error rate 2.000000%\n",
      "After epoch 66: valid_err_rate: 0.018700% currently going ot do 98 epochs [best: 0.017900%]\n",
      "At minibatch 33100, batch loss 0.015009, batch error rate 0.000000%\n",
      "At minibatch 33200, batch loss 0.020353, batch error rate 0.000000%\n",
      "At minibatch 33300, batch loss 0.025139, batch error rate 0.000000%\n",
      "At minibatch 33400, batch loss 0.019063, batch error rate 0.000000%\n",
      "At minibatch 33500, batch loss 0.013588, batch error rate 0.000000%\n",
      "After epoch 67: valid_err_rate: 0.018400% currently going ot do 98 epochs [best: 0.017900%]\n",
      "At minibatch 33600, batch loss 0.025048, batch error rate 0.000000%\n",
      "At minibatch 33700, batch loss 0.025208, batch error rate 0.000000%\n",
      "At minibatch 33800, batch loss 0.033018, batch error rate 1.000000%\n",
      "At minibatch 33900, batch loss 0.019551, batch error rate 0.000000%\n",
      "At minibatch 34000, batch loss 0.030998, batch error rate 0.000000%\n",
      "After epoch 68: valid_err_rate: 0.019200% currently going ot do 98 epochs [best: 0.017900%]\n",
      "At minibatch 34100, batch loss 0.028679, batch error rate 0.000000%\n",
      "At minibatch 34200, batch loss 0.016832, batch error rate 0.000000%\n",
      "At minibatch 34300, batch loss 0.033945, batch error rate 1.000000%\n",
      "At minibatch 34400, batch loss 0.046585, batch error rate 1.000000%\n",
      "At minibatch 34500, batch loss 0.021154, batch error rate 0.000000%\n",
      "After epoch 69: valid_err_rate: 0.020500% currently going ot do 98 epochs [best: 0.017900%]\n",
      "At minibatch 34600, batch loss 0.040801, batch error rate 1.000000%\n",
      "At minibatch 34700, batch loss 0.029593, batch error rate 0.000000%\n",
      "At minibatch 34800, batch loss 0.030232, batch error rate 0.000000%\n",
      "At minibatch 34900, batch loss 0.051090, batch error rate 2.000000%\n",
      "At minibatch 35000, batch loss 0.023302, batch error rate 0.000000%\n",
      "After epoch 70: valid_err_rate: 0.017500% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 35100, batch loss 0.031064, batch error rate 1.000000%\n",
      "At minibatch 35200, batch loss 0.070474, batch error rate 1.000000%\n",
      "At minibatch 35300, batch loss 0.013578, batch error rate 0.000000%\n",
      "At minibatch 35400, batch loss 0.021854, batch error rate 1.000000%\n",
      "At minibatch 35500, batch loss 0.028052, batch error rate 1.000000%\n",
      "After epoch 71: valid_err_rate: 0.018500% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 35600, batch loss 0.023065, batch error rate 0.000000%\n",
      "At minibatch 35700, batch loss 0.025021, batch error rate 1.000000%\n",
      "At minibatch 35800, batch loss 0.020560, batch error rate 0.000000%\n",
      "At minibatch 35900, batch loss 0.039405, batch error rate 2.000000%\n",
      "At minibatch 36000, batch loss 0.023707, batch error rate 0.000000%\n",
      "After epoch 72: valid_err_rate: 0.018500% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 36100, batch loss 0.016959, batch error rate 0.000000%\n",
      "At minibatch 36200, batch loss 0.021707, batch error rate 0.000000%\n",
      "At minibatch 36300, batch loss 0.025046, batch error rate 0.000000%\n",
      "At minibatch 36400, batch loss 0.024840, batch error rate 0.000000%\n",
      "At minibatch 36500, batch loss 0.021257, batch error rate 0.000000%\n",
      "After epoch 73: valid_err_rate: 0.020800% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 36600, batch loss 0.025808, batch error rate 0.000000%\n",
      "At minibatch 36700, batch loss 0.033722, batch error rate 0.000000%\n",
      "At minibatch 36800, batch loss 0.032355, batch error rate 1.000000%\n",
      "At minibatch 36900, batch loss 0.034788, batch error rate 1.000000%\n",
      "At minibatch 37000, batch loss 0.023788, batch error rate 0.000000%\n",
      "After epoch 74: valid_err_rate: 0.017600% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 37100, batch loss 0.018044, batch error rate 0.000000%\n",
      "At minibatch 37200, batch loss 0.042214, batch error rate 1.000000%\n",
      "At minibatch 37300, batch loss 0.019641, batch error rate 0.000000%\n",
      "At minibatch 37400, batch loss 0.010636, batch error rate 0.000000%\n",
      "At minibatch 37500, batch loss 0.027955, batch error rate 1.000000%\n",
      "After epoch 75: valid_err_rate: 0.019000% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 37600, batch loss 0.013517, batch error rate 0.000000%\n",
      "At minibatch 37700, batch loss 0.020084, batch error rate 0.000000%\n",
      "At minibatch 37800, batch loss 0.031039, batch error rate 1.000000%\n",
      "At minibatch 37900, batch loss 0.026732, batch error rate 1.000000%\n",
      "At minibatch 38000, batch loss 0.022159, batch error rate 0.000000%\n",
      "After epoch 76: valid_err_rate: 0.018700% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 38100, batch loss 0.035582, batch error rate 2.000000%\n",
      "At minibatch 38200, batch loss 0.035532, batch error rate 1.000000%\n",
      "At minibatch 38300, batch loss 0.020788, batch error rate 1.000000%\n",
      "At minibatch 38400, batch loss 0.016711, batch error rate 0.000000%\n",
      "At minibatch 38500, batch loss 0.027571, batch error rate 0.000000%\n",
      "After epoch 77: valid_err_rate: 0.018900% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 38600, batch loss 0.016475, batch error rate 0.000000%\n",
      "At minibatch 38700, batch loss 0.032358, batch error rate 1.000000%\n",
      "At minibatch 38800, batch loss 0.019610, batch error rate 0.000000%\n",
      "At minibatch 38900, batch loss 0.009632, batch error rate 0.000000%\n",
      "At minibatch 39000, batch loss 0.010821, batch error rate 0.000000%\n",
      "After epoch 78: valid_err_rate: 0.018800% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 39100, batch loss 0.013903, batch error rate 0.000000%\n",
      "At minibatch 39200, batch loss 0.022980, batch error rate 0.000000%\n",
      "At minibatch 39300, batch loss 0.019297, batch error rate 0.000000%\n",
      "At minibatch 39400, batch loss 0.023623, batch error rate 1.000000%\n",
      "At minibatch 39500, batch loss 0.036857, batch error rate 0.000000%\n",
      "After epoch 79: valid_err_rate: 0.020100% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 39600, batch loss 0.018924, batch error rate 0.000000%\n",
      "At minibatch 39700, batch loss 0.018616, batch error rate 0.000000%\n",
      "At minibatch 39800, batch loss 0.044632, batch error rate 2.000000%\n",
      "At minibatch 39900, batch loss 0.017447, batch error rate 0.000000%\n",
      "At minibatch 40000, batch loss 0.019163, batch error rate 0.000000%\n",
      "After epoch 80: valid_err_rate: 0.018300% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 40100, batch loss 0.016120, batch error rate 0.000000%\n",
      "At minibatch 40200, batch loss 0.022613, batch error rate 0.000000%\n",
      "At minibatch 40300, batch loss 0.017141, batch error rate 0.000000%\n",
      "At minibatch 40400, batch loss 0.021641, batch error rate 0.000000%\n",
      "At minibatch 40500, batch loss 0.039796, batch error rate 1.000000%\n",
      "After epoch 81: valid_err_rate: 0.019300% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 40600, batch loss 0.015254, batch error rate 0.000000%\n",
      "At minibatch 40700, batch loss 0.021515, batch error rate 0.000000%\n",
      "At minibatch 40800, batch loss 0.024625, batch error rate 0.000000%\n",
      "At minibatch 40900, batch loss 0.026015, batch error rate 1.000000%\n",
      "At minibatch 41000, batch loss 0.017461, batch error rate 0.000000%\n",
      "After epoch 82: valid_err_rate: 0.019000% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 41100, batch loss 0.041795, batch error rate 1.000000%\n",
      "At minibatch 41200, batch loss 0.018266, batch error rate 0.000000%\n",
      "At minibatch 41300, batch loss 0.016692, batch error rate 0.000000%\n",
      "At minibatch 41400, batch loss 0.031773, batch error rate 0.000000%\n",
      "At minibatch 41500, batch loss 0.021804, batch error rate 0.000000%\n",
      "After epoch 83: valid_err_rate: 0.018300% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 41600, batch loss 0.034855, batch error rate 0.000000%\n",
      "At minibatch 41700, batch loss 0.025165, batch error rate 0.000000%\n",
      "At minibatch 41800, batch loss 0.019954, batch error rate 0.000000%\n",
      "At minibatch 41900, batch loss 0.016812, batch error rate 0.000000%\n",
      "At minibatch 42000, batch loss 0.009144, batch error rate 0.000000%\n",
      "After epoch 84: valid_err_rate: 0.019000% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 42100, batch loss 0.037351, batch error rate 1.000000%\n",
      "At minibatch 42200, batch loss 0.036188, batch error rate 1.000000%\n",
      "At minibatch 42300, batch loss 0.012455, batch error rate 0.000000%\n",
      "At minibatch 42400, batch loss 0.022895, batch error rate 1.000000%\n",
      "At minibatch 42500, batch loss 0.016362, batch error rate 0.000000%\n",
      "After epoch 85: valid_err_rate: 0.017900% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 42600, batch loss 0.012130, batch error rate 0.000000%\n",
      "At minibatch 42700, batch loss 0.013398, batch error rate 0.000000%\n",
      "At minibatch 42800, batch loss 0.017317, batch error rate 0.000000%\n",
      "At minibatch 42900, batch loss 0.044017, batch error rate 1.000000%\n",
      "At minibatch 43000, batch loss 0.021305, batch error rate 0.000000%\n",
      "After epoch 86: valid_err_rate: 0.018200% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 43100, batch loss 0.026312, batch error rate 0.000000%\n",
      "At minibatch 43200, batch loss 0.026903, batch error rate 0.000000%\n",
      "At minibatch 43300, batch loss 0.032866, batch error rate 0.000000%\n",
      "At minibatch 43400, batch loss 0.015157, batch error rate 0.000000%\n",
      "At minibatch 43500, batch loss 0.016214, batch error rate 0.000000%\n",
      "After epoch 87: valid_err_rate: 0.019000% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 43600, batch loss 0.027301, batch error rate 0.000000%\n",
      "At minibatch 43700, batch loss 0.027500, batch error rate 0.000000%\n",
      "At minibatch 43800, batch loss 0.016701, batch error rate 0.000000%\n",
      "At minibatch 43900, batch loss 0.019927, batch error rate 0.000000%\n",
      "At minibatch 44000, batch loss 0.026969, batch error rate 1.000000%\n",
      "After epoch 88: valid_err_rate: 0.019100% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 44100, batch loss 0.033816, batch error rate 1.000000%\n",
      "At minibatch 44200, batch loss 0.043615, batch error rate 1.000000%\n",
      "At minibatch 44300, batch loss 0.018983, batch error rate 0.000000%\n",
      "At minibatch 44400, batch loss 0.023981, batch error rate 0.000000%\n",
      "At minibatch 44500, batch loss 0.042713, batch error rate 0.000000%\n",
      "After epoch 89: valid_err_rate: 0.017900% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 44600, batch loss 0.017980, batch error rate 0.000000%\n",
      "At minibatch 44700, batch loss 0.024782, batch error rate 0.000000%\n",
      "At minibatch 44800, batch loss 0.017465, batch error rate 0.000000%\n",
      "At minibatch 44900, batch loss 0.059437, batch error rate 1.000000%\n",
      "At minibatch 45000, batch loss 0.045701, batch error rate 1.000000%\n",
      "After epoch 90: valid_err_rate: 0.018000% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 45100, batch loss 0.053024, batch error rate 1.000000%\n",
      "At minibatch 45200, batch loss 0.021129, batch error rate 1.000000%\n",
      "At minibatch 45300, batch loss 0.022563, batch error rate 0.000000%\n",
      "At minibatch 45400, batch loss 0.033248, batch error rate 0.000000%\n",
      "At minibatch 45500, batch loss 0.010538, batch error rate 0.000000%\n",
      "After epoch 91: valid_err_rate: 0.017900% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 45600, batch loss 0.026417, batch error rate 0.000000%\n",
      "At minibatch 45700, batch loss 0.034419, batch error rate 1.000000%\n",
      "At minibatch 45800, batch loss 0.030512, batch error rate 0.000000%\n",
      "At minibatch 45900, batch loss 0.020731, batch error rate 0.000000%\n",
      "At minibatch 46000, batch loss 0.036797, batch error rate 0.000000%\n",
      "After epoch 92: valid_err_rate: 0.018600% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 46100, batch loss 0.026397, batch error rate 0.000000%\n",
      "At minibatch 46200, batch loss 0.020775, batch error rate 0.000000%\n",
      "At minibatch 46300, batch loss 0.023021, batch error rate 0.000000%\n",
      "At minibatch 46400, batch loss 0.027231, batch error rate 0.000000%\n",
      "At minibatch 46500, batch loss 0.013474, batch error rate 0.000000%\n",
      "After epoch 93: valid_err_rate: 0.018700% currently going ot do 106 epochs [best: 0.017500%]\n",
      "At minibatch 46600, batch loss 0.022381, batch error rate 0.000000%\n",
      "At minibatch 46700, batch loss 0.015786, batch error rate 0.000000%\n",
      "At minibatch 46800, batch loss 0.025762, batch error rate 0.000000%\n",
      "At minibatch 46900, batch loss 0.057406, batch error rate 1.000000%\n",
      "At minibatch 47000, batch loss 0.015072, batch error rate 0.000000%\n",
      "After epoch 94: valid_err_rate: 0.017400% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 47100, batch loss 0.012972, batch error rate 0.000000%\n",
      "At minibatch 47200, batch loss 0.054985, batch error rate 1.000000%\n",
      "At minibatch 47300, batch loss 0.056884, batch error rate 1.000000%\n",
      "At minibatch 47400, batch loss 0.032056, batch error rate 0.000000%\n",
      "At minibatch 47500, batch loss 0.017194, batch error rate 0.000000%\n",
      "After epoch 95: valid_err_rate: 0.017900% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 47600, batch loss 0.030813, batch error rate 1.000000%\n",
      "At minibatch 47700, batch loss 0.019121, batch error rate 0.000000%\n",
      "At minibatch 47800, batch loss 0.020068, batch error rate 0.000000%\n",
      "At minibatch 47900, batch loss 0.022744, batch error rate 1.000000%\n",
      "At minibatch 48000, batch loss 0.023176, batch error rate 0.000000%\n",
      "After epoch 96: valid_err_rate: 0.018300% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 48100, batch loss 0.040654, batch error rate 0.000000%\n",
      "At minibatch 48200, batch loss 0.025127, batch error rate 0.000000%\n",
      "At minibatch 48300, batch loss 0.022260, batch error rate 0.000000%\n",
      "At minibatch 48400, batch loss 0.013789, batch error rate 0.000000%\n",
      "At minibatch 48500, batch loss 0.020380, batch error rate 0.000000%\n",
      "After epoch 97: valid_err_rate: 0.018200% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 48600, batch loss 0.038318, batch error rate 0.000000%\n",
      "At minibatch 48700, batch loss 0.043334, batch error rate 1.000000%\n",
      "At minibatch 48800, batch loss 0.018260, batch error rate 0.000000%\n",
      "At minibatch 48900, batch loss 0.012945, batch error rate 0.000000%\n",
      "At minibatch 49000, batch loss 0.016868, batch error rate 0.000000%\n",
      "After epoch 98: valid_err_rate: 0.018200% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 49100, batch loss 0.023435, batch error rate 0.000000%\n",
      "At minibatch 49200, batch loss 0.016777, batch error rate 0.000000%\n",
      "At minibatch 49300, batch loss 0.019861, batch error rate 0.000000%\n",
      "At minibatch 49400, batch loss 0.012482, batch error rate 0.000000%\n",
      "At minibatch 49500, batch loss 0.022402, batch error rate 0.000000%\n",
      "After epoch 99: valid_err_rate: 0.019000% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 49600, batch loss 0.024602, batch error rate 1.000000%\n",
      "At minibatch 49700, batch loss 0.065005, batch error rate 1.000000%\n",
      "At minibatch 49800, batch loss 0.011814, batch error rate 0.000000%\n",
      "At minibatch 49900, batch loss 0.015663, batch error rate 0.000000%\n",
      "At minibatch 50000, batch loss 0.036894, batch error rate 1.000000%\n",
      "After epoch 100: valid_err_rate: 0.018400% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 50100, batch loss 0.018755, batch error rate 0.000000%\n",
      "At minibatch 50200, batch loss 0.035471, batch error rate 1.000000%\n",
      "At minibatch 50300, batch loss 0.021827, batch error rate 0.000000%\n",
      "At minibatch 50400, batch loss 0.023998, batch error rate 1.000000%\n",
      "At minibatch 50500, batch loss 0.029000, batch error rate 0.000000%\n",
      "After epoch 101: valid_err_rate: 0.018400% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 50600, batch loss 0.016309, batch error rate 0.000000%\n",
      "At minibatch 50700, batch loss 0.014622, batch error rate 0.000000%\n",
      "At minibatch 50800, batch loss 0.015779, batch error rate 0.000000%\n",
      "At minibatch 50900, batch loss 0.025707, batch error rate 0.000000%\n",
      "At minibatch 51000, batch loss 0.035888, batch error rate 1.000000%\n",
      "After epoch 102: valid_err_rate: 0.018400% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 51100, batch loss 0.035591, batch error rate 1.000000%\n",
      "At minibatch 51200, batch loss 0.017635, batch error rate 0.000000%\n",
      "At minibatch 51300, batch loss 0.034858, batch error rate 0.000000%\n",
      "At minibatch 51400, batch loss 0.032732, batch error rate 1.000000%\n",
      "At minibatch 51500, batch loss 0.032480, batch error rate 1.000000%\n",
      "After epoch 103: valid_err_rate: 0.018200% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 51600, batch loss 0.012931, batch error rate 0.000000%\n",
      "At minibatch 51700, batch loss 0.013787, batch error rate 0.000000%\n",
      "At minibatch 51800, batch loss 0.031398, batch error rate 0.000000%\n",
      "At minibatch 51900, batch loss 0.016718, batch error rate 0.000000%\n",
      "At minibatch 52000, batch loss 0.021009, batch error rate 1.000000%\n",
      "After epoch 104: valid_err_rate: 0.019000% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 52100, batch loss 0.023797, batch error rate 1.000000%\n",
      "At minibatch 52200, batch loss 0.031354, batch error rate 0.000000%\n",
      "At minibatch 52300, batch loss 0.014146, batch error rate 0.000000%\n",
      "At minibatch 52400, batch loss 0.018895, batch error rate 0.000000%\n",
      "At minibatch 52500, batch loss 0.013542, batch error rate 0.000000%\n",
      "After epoch 105: valid_err_rate: 0.018400% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 52600, batch loss 0.017828, batch error rate 0.000000%\n",
      "At minibatch 52700, batch loss 0.045457, batch error rate 1.000000%\n",
      "At minibatch 52800, batch loss 0.034248, batch error rate 0.000000%\n",
      "At minibatch 52900, batch loss 0.010939, batch error rate 0.000000%\n",
      "At minibatch 53000, batch loss 0.037460, batch error rate 1.000000%\n",
      "After epoch 106: valid_err_rate: 0.019000% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 53100, batch loss 0.012616, batch error rate 0.000000%\n",
      "At minibatch 53200, batch loss 0.013363, batch error rate 0.000000%\n",
      "At minibatch 53300, batch loss 0.018360, batch error rate 0.000000%\n",
      "At minibatch 53400, batch loss 0.025194, batch error rate 0.000000%\n",
      "At minibatch 53500, batch loss 0.057433, batch error rate 2.000000%\n",
      "After epoch 107: valid_err_rate: 0.018800% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 53600, batch loss 0.023108, batch error rate 0.000000%\n",
      "At minibatch 53700, batch loss 0.012802, batch error rate 0.000000%\n",
      "At minibatch 53800, batch loss 0.016655, batch error rate 0.000000%\n",
      "At minibatch 53900, batch loss 0.028013, batch error rate 0.000000%\n",
      "At minibatch 54000, batch loss 0.013508, batch error rate 0.000000%\n",
      "After epoch 108: valid_err_rate: 0.018600% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 54100, batch loss 0.009988, batch error rate 0.000000%\n",
      "At minibatch 54200, batch loss 0.024190, batch error rate 0.000000%\n",
      "At minibatch 54300, batch loss 0.022300, batch error rate 0.000000%\n",
      "At minibatch 54400, batch loss 0.036551, batch error rate 1.000000%\n",
      "At minibatch 54500, batch loss 0.030847, batch error rate 0.000000%\n",
      "After epoch 109: valid_err_rate: 0.017800% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 54600, batch loss 0.024597, batch error rate 0.000000%\n",
      "At minibatch 54700, batch loss 0.026220, batch error rate 0.000000%\n",
      "At minibatch 54800, batch loss 0.024048, batch error rate 0.000000%\n",
      "At minibatch 54900, batch loss 0.019257, batch error rate 0.000000%\n",
      "At minibatch 55000, batch loss 0.024801, batch error rate 0.000000%\n",
      "After epoch 110: valid_err_rate: 0.018500% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 55100, batch loss 0.024504, batch error rate 0.000000%\n",
      "At minibatch 55200, batch loss 0.011232, batch error rate 0.000000%\n",
      "At minibatch 55300, batch loss 0.019057, batch error rate 0.000000%\n",
      "At minibatch 55400, batch loss 0.026781, batch error rate 0.000000%\n",
      "At minibatch 55500, batch loss 0.020489, batch error rate 0.000000%\n",
      "After epoch 111: valid_err_rate: 0.017600% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 55600, batch loss 0.016283, batch error rate 0.000000%\n",
      "At minibatch 55700, batch loss 0.016269, batch error rate 0.000000%\n",
      "At minibatch 55800, batch loss 0.029014, batch error rate 0.000000%\n",
      "At minibatch 55900, batch loss 0.019896, batch error rate 0.000000%\n",
      "At minibatch 56000, batch loss 0.016736, batch error rate 0.000000%\n",
      "After epoch 112: valid_err_rate: 0.018300% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 56100, batch loss 0.013725, batch error rate 0.000000%\n",
      "At minibatch 56200, batch loss 0.017913, batch error rate 0.000000%\n",
      "At minibatch 56300, batch loss 0.028151, batch error rate 1.000000%\n",
      "At minibatch 56400, batch loss 0.041300, batch error rate 1.000000%\n",
      "At minibatch 56500, batch loss 0.025419, batch error rate 0.000000%\n",
      "After epoch 113: valid_err_rate: 0.017500% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 56600, batch loss 0.011243, batch error rate 0.000000%\n",
      "At minibatch 56700, batch loss 0.032788, batch error rate 1.000000%\n",
      "At minibatch 56800, batch loss 0.017520, batch error rate 0.000000%\n",
      "At minibatch 56900, batch loss 0.011439, batch error rate 0.000000%\n",
      "At minibatch 57000, batch loss 0.016705, batch error rate 0.000000%\n",
      "After epoch 114: valid_err_rate: 0.018800% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 57100, batch loss 0.021449, batch error rate 0.000000%\n",
      "At minibatch 57200, batch loss 0.028898, batch error rate 0.000000%\n",
      "At minibatch 57300, batch loss 0.020539, batch error rate 0.000000%\n",
      "At minibatch 57400, batch loss 0.009885, batch error rate 0.000000%\n",
      "At minibatch 57500, batch loss 0.025764, batch error rate 0.000000%\n",
      "After epoch 115: valid_err_rate: 0.018600% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 57600, batch loss 0.029309, batch error rate 0.000000%\n",
      "At minibatch 57700, batch loss 0.008013, batch error rate 0.000000%\n",
      "At minibatch 57800, batch loss 0.015922, batch error rate 0.000000%\n",
      "At minibatch 57900, batch loss 0.018864, batch error rate 0.000000%\n",
      "At minibatch 58000, batch loss 0.020634, batch error rate 0.000000%\n",
      "After epoch 116: valid_err_rate: 0.017900% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 58100, batch loss 0.055607, batch error rate 2.000000%\n",
      "At minibatch 58200, batch loss 0.022250, batch error rate 0.000000%\n",
      "At minibatch 58300, batch loss 0.043072, batch error rate 1.000000%\n",
      "At minibatch 58400, batch loss 0.009996, batch error rate 0.000000%\n",
      "At minibatch 58500, batch loss 0.022198, batch error rate 0.000000%\n",
      "After epoch 117: valid_err_rate: 0.018700% currently going ot do 142 epochs [best: 0.017400%]\n",
      "At minibatch 58600, batch loss 0.019730, batch error rate 0.000000%\n",
      "At minibatch 58700, batch loss 0.054868, batch error rate 3.000000%\n",
      "At minibatch 58800, batch loss 0.020830, batch error rate 0.000000%\n",
      "At minibatch 58900, batch loss 0.031318, batch error rate 0.000000%\n",
      "At minibatch 59000, batch loss 0.019472, batch error rate 0.000000%\n",
      "After epoch 118: valid_err_rate: 0.017300% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 59100, batch loss 0.027466, batch error rate 0.000000%\n",
      "At minibatch 59200, batch loss 0.017470, batch error rate 0.000000%\n",
      "At minibatch 59300, batch loss 0.023556, batch error rate 0.000000%\n",
      "At minibatch 59400, batch loss 0.027898, batch error rate 1.000000%\n",
      "At minibatch 59500, batch loss 0.049603, batch error rate 1.000000%\n",
      "After epoch 119: valid_err_rate: 0.019000% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 59600, batch loss 0.024230, batch error rate 0.000000%\n",
      "At minibatch 59700, batch loss 0.024378, batch error rate 0.000000%\n",
      "At minibatch 59800, batch loss 0.019011, batch error rate 0.000000%\n",
      "At minibatch 59900, batch loss 0.030011, batch error rate 0.000000%\n",
      "At minibatch 60000, batch loss 0.012442, batch error rate 0.000000%\n",
      "After epoch 120: valid_err_rate: 0.018200% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 60100, batch loss 0.029309, batch error rate 0.000000%\n",
      "At minibatch 60200, batch loss 0.025339, batch error rate 0.000000%\n",
      "At minibatch 60300, batch loss 0.028696, batch error rate 1.000000%\n",
      "At minibatch 60400, batch loss 0.015513, batch error rate 0.000000%\n",
      "At minibatch 60500, batch loss 0.022838, batch error rate 0.000000%\n",
      "After epoch 121: valid_err_rate: 0.018800% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 60600, batch loss 0.034356, batch error rate 0.000000%\n",
      "At minibatch 60700, batch loss 0.010942, batch error rate 0.000000%\n",
      "At minibatch 60800, batch loss 0.012258, batch error rate 0.000000%\n",
      "At minibatch 60900, batch loss 0.044317, batch error rate 0.000000%\n",
      "At minibatch 61000, batch loss 0.028851, batch error rate 1.000000%\n",
      "After epoch 122: valid_err_rate: 0.018200% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 61100, batch loss 0.016462, batch error rate 0.000000%\n",
      "At minibatch 61200, batch loss 0.060014, batch error rate 1.000000%\n",
      "At minibatch 61300, batch loss 0.021892, batch error rate 0.000000%\n",
      "At minibatch 61400, batch loss 0.013327, batch error rate 0.000000%\n",
      "At minibatch 61500, batch loss 0.035901, batch error rate 0.000000%\n",
      "After epoch 123: valid_err_rate: 0.018600% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 61600, batch loss 0.020442, batch error rate 0.000000%\n",
      "At minibatch 61700, batch loss 0.017655, batch error rate 0.000000%\n",
      "At minibatch 61800, batch loss 0.011140, batch error rate 0.000000%\n",
      "At minibatch 61900, batch loss 0.017165, batch error rate 0.000000%\n",
      "At minibatch 62000, batch loss 0.017424, batch error rate 0.000000%\n",
      "After epoch 124: valid_err_rate: 0.017700% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 62100, batch loss 0.048119, batch error rate 1.000000%\n",
      "At minibatch 62200, batch loss 0.035853, batch error rate 1.000000%\n",
      "At minibatch 62300, batch loss 0.024033, batch error rate 0.000000%\n",
      "At minibatch 62400, batch loss 0.020388, batch error rate 1.000000%\n",
      "At minibatch 62500, batch loss 0.024830, batch error rate 0.000000%\n",
      "After epoch 125: valid_err_rate: 0.017800% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 62600, batch loss 0.011820, batch error rate 0.000000%\n",
      "At minibatch 62700, batch loss 0.021292, batch error rate 0.000000%\n",
      "At minibatch 62800, batch loss 0.015076, batch error rate 0.000000%\n",
      "At minibatch 62900, batch loss 0.010498, batch error rate 0.000000%\n",
      "At minibatch 63000, batch loss 0.025731, batch error rate 0.000000%\n",
      "After epoch 126: valid_err_rate: 0.017900% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 63100, batch loss 0.014922, batch error rate 0.000000%\n",
      "At minibatch 63200, batch loss 0.030287, batch error rate 0.000000%\n",
      "At minibatch 63300, batch loss 0.026000, batch error rate 1.000000%\n",
      "At minibatch 63400, batch loss 0.017663, batch error rate 0.000000%\n",
      "At minibatch 63500, batch loss 0.055834, batch error rate 1.000000%\n",
      "After epoch 127: valid_err_rate: 0.018600% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 63600, batch loss 0.029368, batch error rate 1.000000%\n",
      "At minibatch 63700, batch loss 0.025268, batch error rate 0.000000%\n",
      "At minibatch 63800, batch loss 0.010296, batch error rate 0.000000%\n",
      "At minibatch 63900, batch loss 0.026940, batch error rate 0.000000%\n",
      "At minibatch 64000, batch loss 0.013042, batch error rate 0.000000%\n",
      "After epoch 128: valid_err_rate: 0.018500% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 64100, batch loss 0.012741, batch error rate 0.000000%\n",
      "At minibatch 64200, batch loss 0.015404, batch error rate 0.000000%\n",
      "At minibatch 64300, batch loss 0.011831, batch error rate 0.000000%\n",
      "At minibatch 64400, batch loss 0.016330, batch error rate 1.000000%\n",
      "At minibatch 64500, batch loss 0.022074, batch error rate 0.000000%\n",
      "After epoch 129: valid_err_rate: 0.017300% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 64600, batch loss 0.017505, batch error rate 0.000000%\n",
      "At minibatch 64700, batch loss 0.024138, batch error rate 1.000000%\n",
      "At minibatch 64800, batch loss 0.023527, batch error rate 0.000000%\n",
      "At minibatch 64900, batch loss 0.038114, batch error rate 1.000000%\n",
      "At minibatch 65000, batch loss 0.023349, batch error rate 0.000000%\n",
      "After epoch 130: valid_err_rate: 0.017700% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 65100, batch loss 0.034369, batch error rate 0.000000%\n",
      "At minibatch 65200, batch loss 0.022647, batch error rate 0.000000%\n",
      "At minibatch 65300, batch loss 0.022976, batch error rate 0.000000%\n",
      "At minibatch 65400, batch loss 0.020533, batch error rate 0.000000%\n",
      "At minibatch 65500, batch loss 0.048325, batch error rate 0.000000%\n",
      "After epoch 131: valid_err_rate: 0.018400% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 65600, batch loss 0.022811, batch error rate 0.000000%\n",
      "At minibatch 65700, batch loss 0.012791, batch error rate 0.000000%\n",
      "At minibatch 65800, batch loss 0.038203, batch error rate 0.000000%\n",
      "At minibatch 65900, batch loss 0.024322, batch error rate 0.000000%\n",
      "At minibatch 66000, batch loss 0.029942, batch error rate 1.000000%\n",
      "After epoch 132: valid_err_rate: 0.018400% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 66100, batch loss 0.016542, batch error rate 0.000000%\n",
      "At minibatch 66200, batch loss 0.013018, batch error rate 0.000000%\n",
      "At minibatch 66300, batch loss 0.040407, batch error rate 0.000000%\n",
      "At minibatch 66400, batch loss 0.045224, batch error rate 1.000000%\n",
      "At minibatch 66500, batch loss 0.039987, batch error rate 1.000000%\n",
      "After epoch 133: valid_err_rate: 0.018300% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 66600, batch loss 0.023615, batch error rate 0.000000%\n",
      "At minibatch 66700, batch loss 0.009596, batch error rate 0.000000%\n",
      "At minibatch 66800, batch loss 0.024321, batch error rate 0.000000%\n",
      "At minibatch 66900, batch loss 0.025232, batch error rate 0.000000%\n",
      "At minibatch 67000, batch loss 0.023614, batch error rate 1.000000%\n",
      "After epoch 134: valid_err_rate: 0.018800% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 67100, batch loss 0.014180, batch error rate 0.000000%\n",
      "At minibatch 67200, batch loss 0.033652, batch error rate 0.000000%\n",
      "At minibatch 67300, batch loss 0.025062, batch error rate 0.000000%\n",
      "At minibatch 67400, batch loss 0.025366, batch error rate 0.000000%\n",
      "At minibatch 67500, batch loss 0.022912, batch error rate 0.000000%\n",
      "After epoch 135: valid_err_rate: 0.018200% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 67600, batch loss 0.024460, batch error rate 0.000000%\n",
      "At minibatch 67700, batch loss 0.014156, batch error rate 0.000000%\n",
      "At minibatch 67800, batch loss 0.010689, batch error rate 0.000000%\n",
      "At minibatch 67900, batch loss 0.030092, batch error rate 0.000000%\n",
      "At minibatch 68000, batch loss 0.019177, batch error rate 0.000000%\n",
      "After epoch 136: valid_err_rate: 0.019000% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 68100, batch loss 0.013562, batch error rate 0.000000%\n",
      "At minibatch 68200, batch loss 0.030109, batch error rate 1.000000%\n",
      "At minibatch 68300, batch loss 0.019877, batch error rate 0.000000%\n",
      "At minibatch 68400, batch loss 0.018332, batch error rate 0.000000%\n",
      "At minibatch 68500, batch loss 0.033655, batch error rate 1.000000%\n",
      "After epoch 137: valid_err_rate: 0.018700% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 68600, batch loss 0.049228, batch error rate 3.000000%\n",
      "At minibatch 68700, batch loss 0.037417, batch error rate 0.000000%\n",
      "At minibatch 68800, batch loss 0.017882, batch error rate 0.000000%\n",
      "At minibatch 68900, batch loss 0.032002, batch error rate 0.000000%\n",
      "At minibatch 69000, batch loss 0.010960, batch error rate 0.000000%\n",
      "After epoch 138: valid_err_rate: 0.018800% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 69100, batch loss 0.011566, batch error rate 0.000000%\n",
      "At minibatch 69200, batch loss 0.027326, batch error rate 0.000000%\n",
      "At minibatch 69300, batch loss 0.016070, batch error rate 0.000000%\n",
      "At minibatch 69400, batch loss 0.023331, batch error rate 0.000000%\n",
      "At minibatch 69500, batch loss 0.006632, batch error rate 0.000000%\n",
      "After epoch 139: valid_err_rate: 0.018600% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 69600, batch loss 0.027722, batch error rate 0.000000%\n",
      "At minibatch 69700, batch loss 0.009422, batch error rate 0.000000%\n",
      "At minibatch 69800, batch loss 0.025439, batch error rate 0.000000%\n",
      "At minibatch 69900, batch loss 0.022301, batch error rate 0.000000%\n",
      "At minibatch 70000, batch loss 0.020695, batch error rate 0.000000%\n",
      "After epoch 140: valid_err_rate: 0.018100% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 70100, batch loss 0.025893, batch error rate 0.000000%\n",
      "At minibatch 70200, batch loss 0.012383, batch error rate 0.000000%\n",
      "At minibatch 70300, batch loss 0.019946, batch error rate 1.000000%\n",
      "At minibatch 70400, batch loss 0.016848, batch error rate 0.000000%\n",
      "At minibatch 70500, batch loss 0.023521, batch error rate 0.000000%\n",
      "After epoch 141: valid_err_rate: 0.018300% currently going ot do 178 epochs [best: 0.017300%]\n",
      "At minibatch 70600, batch loss 0.026523, batch error rate 0.000000%\n",
      "At minibatch 70700, batch loss 0.025614, batch error rate 0.000000%\n",
      "At minibatch 70800, batch loss 0.065693, batch error rate 2.000000%\n",
      "At minibatch 70900, batch loss 0.027941, batch error rate 1.000000%\n",
      "At minibatch 71000, batch loss 0.045289, batch error rate 1.000000%\n",
      "After epoch 142: valid_err_rate: 0.017000% currently going ot do 214 epochs [best: 0.017000%]\n",
      "At minibatch 71100, batch loss 0.023203, batch error rate 0.000000%\n",
      "At minibatch 71200, batch loss 0.016068, batch error rate 0.000000%\n",
      "At minibatch 71300, batch loss 0.034904, batch error rate 0.000000%\n",
      "At minibatch 71400, batch loss 0.015023, batch error rate 0.000000%\n",
      "At minibatch 71500, batch loss 0.022229, batch error rate 0.000000%\n",
      "After epoch 143: valid_err_rate: 0.017800% currently going ot do 214 epochs [best: 0.017000%]\n",
      "At minibatch 71600, batch loss 0.021070, batch error rate 0.000000%\n",
      "At minibatch 71700, batch loss 0.016882, batch error rate 0.000000%\n",
      "At minibatch 71800, batch loss 0.021211, batch error rate 0.000000%\n",
      "At minibatch 71900, batch loss 0.018928, batch error rate 0.000000%\n",
      "At minibatch 72000, batch loss 0.009230, batch error rate 0.000000%\n",
      "After epoch 144: valid_err_rate: 0.017200% currently going ot do 214 epochs [best: 0.017000%]\n",
      "At minibatch 72100, batch loss 0.014796, batch error rate 0.000000%\n",
      "At minibatch 72200, batch loss 0.018060, batch error rate 0.000000%\n",
      "At minibatch 72300, batch loss 0.019840, batch error rate 0.000000%\n",
      "At minibatch 72400, batch loss 0.028613, batch error rate 1.000000%\n",
      "At minibatch 72500, batch loss 0.028009, batch error rate 0.000000%\n",
      "After epoch 145: valid_err_rate: 0.016900% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 72600, batch loss 0.014561, batch error rate 0.000000%\n",
      "At minibatch 72700, batch loss 0.028124, batch error rate 0.000000%\n",
      "At minibatch 72800, batch loss 0.007986, batch error rate 0.000000%\n",
      "At minibatch 72900, batch loss 0.016336, batch error rate 0.000000%\n",
      "At minibatch 73000, batch loss 0.041130, batch error rate 1.000000%\n",
      "After epoch 146: valid_err_rate: 0.018700% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 73100, batch loss 0.017919, batch error rate 0.000000%\n",
      "At minibatch 73200, batch loss 0.022214, batch error rate 0.000000%\n",
      "At minibatch 73300, batch loss 0.016751, batch error rate 0.000000%\n",
      "At minibatch 73400, batch loss 0.022517, batch error rate 0.000000%\n",
      "At minibatch 73500, batch loss 0.019790, batch error rate 0.000000%\n",
      "After epoch 147: valid_err_rate: 0.017800% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 73600, batch loss 0.013396, batch error rate 0.000000%\n",
      "At minibatch 73700, batch loss 0.042651, batch error rate 2.000000%\n",
      "At minibatch 73800, batch loss 0.026194, batch error rate 1.000000%\n",
      "At minibatch 73900, batch loss 0.019049, batch error rate 0.000000%\n",
      "At minibatch 74000, batch loss 0.010573, batch error rate 0.000000%\n",
      "After epoch 148: valid_err_rate: 0.018200% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 74100, batch loss 0.021041, batch error rate 0.000000%\n",
      "At minibatch 74200, batch loss 0.017273, batch error rate 0.000000%\n",
      "At minibatch 74300, batch loss 0.016102, batch error rate 0.000000%\n",
      "At minibatch 74400, batch loss 0.014507, batch error rate 0.000000%\n",
      "At minibatch 74500, batch loss 0.024232, batch error rate 0.000000%\n",
      "After epoch 149: valid_err_rate: 0.018200% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 74600, batch loss 0.034882, batch error rate 1.000000%\n",
      "At minibatch 74700, batch loss 0.014848, batch error rate 0.000000%\n",
      "At minibatch 74800, batch loss 0.016911, batch error rate 0.000000%\n",
      "At minibatch 74900, batch loss 0.021251, batch error rate 0.000000%\n",
      "At minibatch 75000, batch loss 0.023012, batch error rate 0.000000%\n",
      "After epoch 150: valid_err_rate: 0.018100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 75100, batch loss 0.027338, batch error rate 0.000000%\n",
      "At minibatch 75200, batch loss 0.017707, batch error rate 0.000000%\n",
      "At minibatch 75300, batch loss 0.021897, batch error rate 1.000000%\n",
      "At minibatch 75400, batch loss 0.017067, batch error rate 0.000000%\n",
      "At minibatch 75500, batch loss 0.015920, batch error rate 0.000000%\n",
      "After epoch 151: valid_err_rate: 0.018600% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 75600, batch loss 0.019026, batch error rate 0.000000%\n",
      "At minibatch 75700, batch loss 0.036136, batch error rate 2.000000%\n",
      "At minibatch 75800, batch loss 0.022285, batch error rate 1.000000%\n",
      "At minibatch 75900, batch loss 0.030753, batch error rate 1.000000%\n",
      "At minibatch 76000, batch loss 0.022492, batch error rate 0.000000%\n",
      "After epoch 152: valid_err_rate: 0.018400% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 76100, batch loss 0.033482, batch error rate 2.000000%\n",
      "At minibatch 76200, batch loss 0.025176, batch error rate 0.000000%\n",
      "At minibatch 76300, batch loss 0.031074, batch error rate 0.000000%\n",
      "At minibatch 76400, batch loss 0.019997, batch error rate 0.000000%\n",
      "At minibatch 76500, batch loss 0.026801, batch error rate 1.000000%\n",
      "After epoch 153: valid_err_rate: 0.019600% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 76600, batch loss 0.025559, batch error rate 0.000000%\n",
      "At minibatch 76700, batch loss 0.051247, batch error rate 1.000000%\n",
      "At minibatch 76800, batch loss 0.024968, batch error rate 0.000000%\n",
      "At minibatch 76900, batch loss 0.018711, batch error rate 0.000000%\n",
      "At minibatch 77000, batch loss 0.026776, batch error rate 0.000000%\n",
      "After epoch 154: valid_err_rate: 0.017500% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 77100, batch loss 0.012553, batch error rate 0.000000%\n",
      "At minibatch 77200, batch loss 0.019046, batch error rate 0.000000%\n",
      "At minibatch 77300, batch loss 0.031474, batch error rate 1.000000%\n",
      "At minibatch 77400, batch loss 0.013193, batch error rate 0.000000%\n",
      "At minibatch 77500, batch loss 0.026604, batch error rate 0.000000%\n",
      "After epoch 155: valid_err_rate: 0.017300% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 77600, batch loss 0.011073, batch error rate 0.000000%\n",
      "At minibatch 77700, batch loss 0.021476, batch error rate 0.000000%\n",
      "At minibatch 77800, batch loss 0.014156, batch error rate 0.000000%\n",
      "At minibatch 77900, batch loss 0.015975, batch error rate 0.000000%\n",
      "At minibatch 78000, batch loss 0.019974, batch error rate 0.000000%\n",
      "After epoch 156: valid_err_rate: 0.018600% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 78100, batch loss 0.009032, batch error rate 0.000000%\n",
      "At minibatch 78200, batch loss 0.032484, batch error rate 0.000000%\n",
      "At minibatch 78300, batch loss 0.016087, batch error rate 0.000000%\n",
      "At minibatch 78400, batch loss 0.021782, batch error rate 0.000000%\n",
      "At minibatch 78500, batch loss 0.021765, batch error rate 0.000000%\n",
      "After epoch 157: valid_err_rate: 0.017600% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 78600, batch loss 0.017843, batch error rate 0.000000%\n",
      "At minibatch 78700, batch loss 0.042277, batch error rate 0.000000%\n",
      "At minibatch 78800, batch loss 0.017736, batch error rate 0.000000%\n",
      "At minibatch 78900, batch loss 0.054875, batch error rate 2.000000%\n",
      "At minibatch 79000, batch loss 0.024659, batch error rate 0.000000%\n",
      "After epoch 158: valid_err_rate: 0.017800% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 79100, batch loss 0.037570, batch error rate 1.000000%\n",
      "At minibatch 79200, batch loss 0.020781, batch error rate 0.000000%\n",
      "At minibatch 79300, batch loss 0.025163, batch error rate 0.000000%\n",
      "At minibatch 79400, batch loss 0.017711, batch error rate 0.000000%\n",
      "At minibatch 79500, batch loss 0.015779, batch error rate 0.000000%\n",
      "After epoch 159: valid_err_rate: 0.017900% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 79600, batch loss 0.021751, batch error rate 0.000000%\n",
      "At minibatch 79700, batch loss 0.018542, batch error rate 0.000000%\n",
      "At minibatch 79800, batch loss 0.021022, batch error rate 0.000000%\n",
      "At minibatch 79900, batch loss 0.013499, batch error rate 0.000000%\n",
      "At minibatch 80000, batch loss 0.020482, batch error rate 0.000000%\n",
      "After epoch 160: valid_err_rate: 0.017800% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 80100, batch loss 0.010943, batch error rate 0.000000%\n",
      "At minibatch 80200, batch loss 0.014240, batch error rate 0.000000%\n",
      "At minibatch 80300, batch loss 0.010116, batch error rate 0.000000%\n",
      "At minibatch 80400, batch loss 0.023836, batch error rate 0.000000%\n",
      "At minibatch 80500, batch loss 0.016691, batch error rate 0.000000%\n",
      "After epoch 161: valid_err_rate: 0.018000% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 80600, batch loss 0.013836, batch error rate 0.000000%\n",
      "At minibatch 80700, batch loss 0.024328, batch error rate 0.000000%\n",
      "At minibatch 80800, batch loss 0.012700, batch error rate 0.000000%\n",
      "At minibatch 80900, batch loss 0.013804, batch error rate 0.000000%\n",
      "At minibatch 81000, batch loss 0.021325, batch error rate 0.000000%\n",
      "After epoch 162: valid_err_rate: 0.018200% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 81100, batch loss 0.018071, batch error rate 0.000000%\n",
      "At minibatch 81200, batch loss 0.016889, batch error rate 0.000000%\n",
      "At minibatch 81300, batch loss 0.044336, batch error rate 0.000000%\n",
      "At minibatch 81400, batch loss 0.011889, batch error rate 0.000000%\n",
      "At minibatch 81500, batch loss 0.091333, batch error rate 4.000000%\n",
      "After epoch 163: valid_err_rate: 0.017500% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 81600, batch loss 0.013817, batch error rate 0.000000%\n",
      "At minibatch 81700, batch loss 0.013118, batch error rate 0.000000%\n",
      "At minibatch 81800, batch loss 0.019812, batch error rate 0.000000%\n",
      "At minibatch 81900, batch loss 0.024861, batch error rate 0.000000%\n",
      "At minibatch 82000, batch loss 0.023535, batch error rate 0.000000%\n",
      "After epoch 164: valid_err_rate: 0.018200% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 82100, batch loss 0.017419, batch error rate 0.000000%\n",
      "At minibatch 82200, batch loss 0.024030, batch error rate 0.000000%\n",
      "At minibatch 82300, batch loss 0.020395, batch error rate 0.000000%\n",
      "At minibatch 82400, batch loss 0.026241, batch error rate 0.000000%\n",
      "At minibatch 82500, batch loss 0.017674, batch error rate 0.000000%\n",
      "After epoch 165: valid_err_rate: 0.017700% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 82600, batch loss 0.009169, batch error rate 0.000000%\n",
      "At minibatch 82700, batch loss 0.023243, batch error rate 1.000000%\n",
      "At minibatch 82800, batch loss 0.016420, batch error rate 0.000000%\n",
      "At minibatch 82900, batch loss 0.023770, batch error rate 0.000000%\n",
      "At minibatch 83000, batch loss 0.014782, batch error rate 0.000000%\n",
      "After epoch 166: valid_err_rate: 0.017700% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 83100, batch loss 0.015889, batch error rate 0.000000%\n",
      "At minibatch 83200, batch loss 0.015183, batch error rate 0.000000%\n",
      "At minibatch 83300, batch loss 0.010756, batch error rate 0.000000%\n",
      "At minibatch 83400, batch loss 0.025246, batch error rate 0.000000%\n",
      "At minibatch 83500, batch loss 0.019944, batch error rate 0.000000%\n",
      "After epoch 167: valid_err_rate: 0.017900% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 83600, batch loss 0.040730, batch error rate 1.000000%\n",
      "At minibatch 83700, batch loss 0.024029, batch error rate 0.000000%\n",
      "At minibatch 83800, batch loss 0.020841, batch error rate 0.000000%\n",
      "At minibatch 83900, batch loss 0.018705, batch error rate 0.000000%\n",
      "At minibatch 84000, batch loss 0.018989, batch error rate 0.000000%\n",
      "After epoch 168: valid_err_rate: 0.017300% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 84100, batch loss 0.016795, batch error rate 0.000000%\n",
      "At minibatch 84200, batch loss 0.016558, batch error rate 0.000000%\n",
      "At minibatch 84300, batch loss 0.014843, batch error rate 0.000000%\n",
      "At minibatch 84400, batch loss 0.026714, batch error rate 0.000000%\n",
      "At minibatch 84500, batch loss 0.021746, batch error rate 0.000000%\n",
      "After epoch 169: valid_err_rate: 0.017600% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 84600, batch loss 0.024439, batch error rate 1.000000%\n",
      "At minibatch 84700, batch loss 0.018611, batch error rate 0.000000%\n",
      "At minibatch 84800, batch loss 0.019377, batch error rate 0.000000%\n",
      "At minibatch 84900, batch loss 0.011302, batch error rate 0.000000%\n",
      "At minibatch 85000, batch loss 0.008148, batch error rate 0.000000%\n",
      "After epoch 170: valid_err_rate: 0.017900% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 85100, batch loss 0.006572, batch error rate 0.000000%\n",
      "At minibatch 85200, batch loss 0.013406, batch error rate 0.000000%\n",
      "At minibatch 85300, batch loss 0.028094, batch error rate 1.000000%\n",
      "At minibatch 85400, batch loss 0.015864, batch error rate 0.000000%\n",
      "At minibatch 85500, batch loss 0.017967, batch error rate 0.000000%\n",
      "After epoch 171: valid_err_rate: 0.018300% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 85600, batch loss 0.031695, batch error rate 1.000000%\n",
      "At minibatch 85700, batch loss 0.013123, batch error rate 0.000000%\n",
      "At minibatch 85800, batch loss 0.015696, batch error rate 0.000000%\n",
      "At minibatch 85900, batch loss 0.021038, batch error rate 0.000000%\n",
      "At minibatch 86000, batch loss 0.007792, batch error rate 0.000000%\n",
      "After epoch 172: valid_err_rate: 0.018300% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 86100, batch loss 0.018639, batch error rate 0.000000%\n",
      "At minibatch 86200, batch loss 0.017696, batch error rate 0.000000%\n",
      "At minibatch 86300, batch loss 0.012707, batch error rate 0.000000%\n",
      "At minibatch 86400, batch loss 0.015499, batch error rate 0.000000%\n",
      "At minibatch 86500, batch loss 0.016505, batch error rate 0.000000%\n",
      "After epoch 173: valid_err_rate: 0.017100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 86600, batch loss 0.016930, batch error rate 0.000000%\n",
      "At minibatch 86700, batch loss 0.017680, batch error rate 0.000000%\n",
      "At minibatch 86800, batch loss 0.023371, batch error rate 0.000000%\n",
      "At minibatch 86900, batch loss 0.016304, batch error rate 0.000000%\n",
      "At minibatch 87000, batch loss 0.012715, batch error rate 0.000000%\n",
      "After epoch 174: valid_err_rate: 0.018000% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 87100, batch loss 0.022068, batch error rate 1.000000%\n",
      "At minibatch 87200, batch loss 0.008020, batch error rate 0.000000%\n",
      "At minibatch 87300, batch loss 0.016197, batch error rate 0.000000%\n",
      "At minibatch 87400, batch loss 0.009515, batch error rate 0.000000%\n",
      "At minibatch 87500, batch loss 0.026582, batch error rate 0.000000%\n",
      "After epoch 175: valid_err_rate: 0.017500% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 87600, batch loss 0.016058, batch error rate 0.000000%\n",
      "At minibatch 87700, batch loss 0.022539, batch error rate 0.000000%\n",
      "At minibatch 87800, batch loss 0.022626, batch error rate 0.000000%\n",
      "At minibatch 87900, batch loss 0.019509, batch error rate 0.000000%\n",
      "At minibatch 88000, batch loss 0.042720, batch error rate 1.000000%\n",
      "After epoch 176: valid_err_rate: 0.018300% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 88100, batch loss 0.029796, batch error rate 1.000000%\n",
      "At minibatch 88200, batch loss 0.032325, batch error rate 0.000000%\n",
      "At minibatch 88300, batch loss 0.015697, batch error rate 0.000000%\n",
      "At minibatch 88400, batch loss 0.010217, batch error rate 0.000000%\n",
      "At minibatch 88500, batch loss 0.028261, batch error rate 0.000000%\n",
      "After epoch 177: valid_err_rate: 0.018200% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 88600, batch loss 0.024443, batch error rate 0.000000%\n",
      "At minibatch 88700, batch loss 0.022368, batch error rate 0.000000%\n",
      "At minibatch 88800, batch loss 0.019507, batch error rate 0.000000%\n",
      "At minibatch 88900, batch loss 0.016576, batch error rate 0.000000%\n",
      "At minibatch 89000, batch loss 0.016447, batch error rate 0.000000%\n",
      "After epoch 178: valid_err_rate: 0.017700% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 89100, batch loss 0.023412, batch error rate 1.000000%\n",
      "At minibatch 89200, batch loss 0.045785, batch error rate 1.000000%\n",
      "At minibatch 89300, batch loss 0.024739, batch error rate 0.000000%\n",
      "At minibatch 89400, batch loss 0.035051, batch error rate 1.000000%\n",
      "At minibatch 89500, batch loss 0.040415, batch error rate 0.000000%\n",
      "After epoch 179: valid_err_rate: 0.019400% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 89600, batch loss 0.020904, batch error rate 0.000000%\n",
      "At minibatch 89700, batch loss 0.019744, batch error rate 0.000000%\n",
      "At minibatch 89800, batch loss 0.023120, batch error rate 0.000000%\n",
      "At minibatch 89900, batch loss 0.021063, batch error rate 0.000000%\n",
      "At minibatch 90000, batch loss 0.032486, batch error rate 0.000000%\n",
      "After epoch 180: valid_err_rate: 0.017300% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 90100, batch loss 0.027822, batch error rate 1.000000%\n",
      "At minibatch 90200, batch loss 0.023605, batch error rate 0.000000%\n",
      "At minibatch 90300, batch loss 0.015953, batch error rate 0.000000%\n",
      "At minibatch 90400, batch loss 0.029740, batch error rate 0.000000%\n",
      "At minibatch 90500, batch loss 0.019040, batch error rate 1.000000%\n",
      "After epoch 181: valid_err_rate: 0.017300% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 90600, batch loss 0.029815, batch error rate 0.000000%\n",
      "At minibatch 90700, batch loss 0.038782, batch error rate 2.000000%\n",
      "At minibatch 90800, batch loss 0.024016, batch error rate 0.000000%\n",
      "At minibatch 90900, batch loss 0.030949, batch error rate 1.000000%\n",
      "At minibatch 91000, batch loss 0.016421, batch error rate 0.000000%\n",
      "After epoch 182: valid_err_rate: 0.017400% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 91100, batch loss 0.033951, batch error rate 1.000000%\n",
      "At minibatch 91200, batch loss 0.031613, batch error rate 0.000000%\n",
      "At minibatch 91300, batch loss 0.020040, batch error rate 0.000000%\n",
      "At minibatch 91400, batch loss 0.014357, batch error rate 0.000000%\n",
      "At minibatch 91500, batch loss 0.035471, batch error rate 1.000000%\n",
      "After epoch 183: valid_err_rate: 0.018100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 91600, batch loss 0.018279, batch error rate 0.000000%\n",
      "At minibatch 91700, batch loss 0.036994, batch error rate 1.000000%\n",
      "At minibatch 91800, batch loss 0.054373, batch error rate 1.000000%\n",
      "At minibatch 91900, batch loss 0.032251, batch error rate 1.000000%\n",
      "At minibatch 92000, batch loss 0.025775, batch error rate 0.000000%\n",
      "After epoch 184: valid_err_rate: 0.018600% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 92100, batch loss 0.020567, batch error rate 0.000000%\n",
      "At minibatch 92200, batch loss 0.018368, batch error rate 0.000000%\n",
      "At minibatch 92300, batch loss 0.017611, batch error rate 0.000000%\n",
      "At minibatch 92400, batch loss 0.014358, batch error rate 0.000000%\n",
      "At minibatch 92500, batch loss 0.018707, batch error rate 0.000000%\n",
      "After epoch 185: valid_err_rate: 0.018100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 92600, batch loss 0.020045, batch error rate 0.000000%\n",
      "At minibatch 92700, batch loss 0.022606, batch error rate 0.000000%\n",
      "At minibatch 92800, batch loss 0.036841, batch error rate 1.000000%\n",
      "At minibatch 92900, batch loss 0.036416, batch error rate 0.000000%\n",
      "At minibatch 93000, batch loss 0.029589, batch error rate 0.000000%\n",
      "After epoch 186: valid_err_rate: 0.017100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 93100, batch loss 0.010570, batch error rate 0.000000%\n",
      "At minibatch 93200, batch loss 0.041080, batch error rate 1.000000%\n",
      "At minibatch 93300, batch loss 0.018918, batch error rate 0.000000%\n",
      "At minibatch 93400, batch loss 0.023714, batch error rate 0.000000%\n",
      "At minibatch 93500, batch loss 0.024213, batch error rate 0.000000%\n",
      "After epoch 187: valid_err_rate: 0.017100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 93600, batch loss 0.016648, batch error rate 0.000000%\n",
      "At minibatch 93700, batch loss 0.033299, batch error rate 0.000000%\n",
      "At minibatch 93800, batch loss 0.016755, batch error rate 0.000000%\n",
      "At minibatch 93900, batch loss 0.014898, batch error rate 0.000000%\n",
      "At minibatch 94000, batch loss 0.026095, batch error rate 0.000000%\n",
      "After epoch 188: valid_err_rate: 0.017500% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 94100, batch loss 0.014654, batch error rate 0.000000%\n",
      "At minibatch 94200, batch loss 0.032483, batch error rate 1.000000%\n",
      "At minibatch 94300, batch loss 0.017102, batch error rate 0.000000%\n",
      "At minibatch 94400, batch loss 0.012661, batch error rate 0.000000%\n",
      "At minibatch 94500, batch loss 0.031507, batch error rate 1.000000%\n",
      "After epoch 189: valid_err_rate: 0.018700% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 94600, batch loss 0.018997, batch error rate 0.000000%\n",
      "At minibatch 94700, batch loss 0.025220, batch error rate 1.000000%\n",
      "At minibatch 94800, batch loss 0.022912, batch error rate 0.000000%\n",
      "At minibatch 94900, batch loss 0.028358, batch error rate 0.000000%\n",
      "At minibatch 95000, batch loss 0.038867, batch error rate 0.000000%\n",
      "After epoch 190: valid_err_rate: 0.018100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 95100, batch loss 0.019699, batch error rate 1.000000%\n",
      "At minibatch 95200, batch loss 0.016016, batch error rate 0.000000%\n",
      "At minibatch 95300, batch loss 0.018717, batch error rate 0.000000%\n",
      "At minibatch 95400, batch loss 0.024423, batch error rate 0.000000%\n",
      "At minibatch 95500, batch loss 0.015864, batch error rate 0.000000%\n",
      "After epoch 191: valid_err_rate: 0.017100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 95600, batch loss 0.015657, batch error rate 0.000000%\n",
      "At minibatch 95700, batch loss 0.053252, batch error rate 2.000000%\n",
      "At minibatch 95800, batch loss 0.020851, batch error rate 0.000000%\n",
      "At minibatch 95900, batch loss 0.023208, batch error rate 0.000000%\n",
      "At minibatch 96000, batch loss 0.044588, batch error rate 1.000000%\n",
      "After epoch 192: valid_err_rate: 0.018100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 96100, batch loss 0.040412, batch error rate 1.000000%\n",
      "At minibatch 96200, batch loss 0.014380, batch error rate 0.000000%\n",
      "At minibatch 96300, batch loss 0.023226, batch error rate 0.000000%\n",
      "At minibatch 96400, batch loss 0.010498, batch error rate 0.000000%\n",
      "At minibatch 96500, batch loss 0.025610, batch error rate 0.000000%\n",
      "After epoch 193: valid_err_rate: 0.017200% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 96600, batch loss 0.018824, batch error rate 0.000000%\n",
      "At minibatch 96700, batch loss 0.015915, batch error rate 0.000000%\n",
      "At minibatch 96800, batch loss 0.014933, batch error rate 0.000000%\n",
      "At minibatch 96900, batch loss 0.016823, batch error rate 0.000000%\n",
      "At minibatch 97000, batch loss 0.022729, batch error rate 0.000000%\n",
      "After epoch 194: valid_err_rate: 0.017000% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 97100, batch loss 0.030164, batch error rate 1.000000%\n",
      "At minibatch 97200, batch loss 0.027881, batch error rate 0.000000%\n",
      "At minibatch 97300, batch loss 0.027592, batch error rate 0.000000%\n",
      "At minibatch 97400, batch loss 0.011298, batch error rate 0.000000%\n",
      "At minibatch 97500, batch loss 0.009900, batch error rate 0.000000%\n",
      "After epoch 195: valid_err_rate: 0.017900% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 97600, batch loss 0.017805, batch error rate 0.000000%\n",
      "At minibatch 97700, batch loss 0.016694, batch error rate 0.000000%\n",
      "At minibatch 97800, batch loss 0.021517, batch error rate 0.000000%\n",
      "At minibatch 97900, batch loss 0.017879, batch error rate 0.000000%\n",
      "At minibatch 98000, batch loss 0.015353, batch error rate 0.000000%\n",
      "After epoch 196: valid_err_rate: 0.017500% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 98100, batch loss 0.048495, batch error rate 1.000000%\n",
      "At minibatch 98200, batch loss 0.019176, batch error rate 0.000000%\n",
      "At minibatch 98300, batch loss 0.021498, batch error rate 0.000000%\n",
      "At minibatch 98400, batch loss 0.015304, batch error rate 0.000000%\n",
      "At minibatch 98500, batch loss 0.012717, batch error rate 0.000000%\n",
      "After epoch 197: valid_err_rate: 0.017100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 98600, batch loss 0.021331, batch error rate 0.000000%\n",
      "At minibatch 98700, batch loss 0.020364, batch error rate 0.000000%\n",
      "At minibatch 98800, batch loss 0.034697, batch error rate 0.000000%\n",
      "At minibatch 98900, batch loss 0.021746, batch error rate 0.000000%\n",
      "At minibatch 99000, batch loss 0.012092, batch error rate 0.000000%\n",
      "After epoch 198: valid_err_rate: 0.017100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 99100, batch loss 0.009924, batch error rate 0.000000%\n",
      "At minibatch 99200, batch loss 0.032086, batch error rate 0.000000%\n",
      "At minibatch 99300, batch loss 0.034498, batch error rate 1.000000%\n",
      "At minibatch 99400, batch loss 0.021866, batch error rate 0.000000%\n",
      "At minibatch 99500, batch loss 0.023511, batch error rate 0.000000%\n",
      "After epoch 199: valid_err_rate: 0.017800% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 99600, batch loss 0.026926, batch error rate 0.000000%\n",
      "At minibatch 99700, batch loss 0.013653, batch error rate 0.000000%\n",
      "At minibatch 99800, batch loss 0.016781, batch error rate 0.000000%\n",
      "At minibatch 99900, batch loss 0.023860, batch error rate 0.000000%\n",
      "At minibatch 100000, batch loss 0.008773, batch error rate 0.000000%\n",
      "After epoch 200: valid_err_rate: 0.018100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 100100, batch loss 0.019481, batch error rate 0.000000%\n",
      "At minibatch 100200, batch loss 0.016719, batch error rate 0.000000%\n",
      "At minibatch 100300, batch loss 0.023062, batch error rate 1.000000%\n",
      "At minibatch 100400, batch loss 0.022192, batch error rate 0.000000%\n",
      "At minibatch 100500, batch loss 0.019190, batch error rate 0.000000%\n",
      "After epoch 201: valid_err_rate: 0.018500% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 100600, batch loss 0.014073, batch error rate 0.000000%\n",
      "At minibatch 100700, batch loss 0.025579, batch error rate 0.000000%\n",
      "At minibatch 100800, batch loss 0.023011, batch error rate 0.000000%\n",
      "At minibatch 100900, batch loss 0.015045, batch error rate 0.000000%\n",
      "At minibatch 101000, batch loss 0.041241, batch error rate 1.000000%\n",
      "After epoch 202: valid_err_rate: 0.018400% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 101100, batch loss 0.010788, batch error rate 0.000000%\n",
      "At minibatch 101200, batch loss 0.025513, batch error rate 1.000000%\n",
      "At minibatch 101300, batch loss 0.015711, batch error rate 0.000000%\n",
      "At minibatch 101400, batch loss 0.032218, batch error rate 1.000000%\n",
      "At minibatch 101500, batch loss 0.025147, batch error rate 0.000000%\n",
      "After epoch 203: valid_err_rate: 0.017500% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 101600, batch loss 0.015752, batch error rate 0.000000%\n",
      "At minibatch 101700, batch loss 0.023710, batch error rate 0.000000%\n",
      "At minibatch 101800, batch loss 0.022949, batch error rate 0.000000%\n",
      "At minibatch 101900, batch loss 0.024913, batch error rate 0.000000%\n",
      "At minibatch 102000, batch loss 0.018426, batch error rate 1.000000%\n",
      "After epoch 204: valid_err_rate: 0.018000% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 102100, batch loss 0.009521, batch error rate 0.000000%\n",
      "At minibatch 102200, batch loss 0.020935, batch error rate 0.000000%\n",
      "At minibatch 102300, batch loss 0.040159, batch error rate 1.000000%\n",
      "At minibatch 102400, batch loss 0.025080, batch error rate 0.000000%\n",
      "At minibatch 102500, batch loss 0.019084, batch error rate 0.000000%\n",
      "After epoch 205: valid_err_rate: 0.018300% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 102600, batch loss 0.009147, batch error rate 0.000000%\n",
      "At minibatch 102700, batch loss 0.025218, batch error rate 0.000000%\n",
      "At minibatch 102800, batch loss 0.016173, batch error rate 0.000000%\n",
      "At minibatch 102900, batch loss 0.014757, batch error rate 0.000000%\n",
      "At minibatch 103000, batch loss 0.038775, batch error rate 2.000000%\n",
      "After epoch 206: valid_err_rate: 0.017200% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 103100, batch loss 0.020189, batch error rate 0.000000%\n",
      "At minibatch 103200, batch loss 0.024250, batch error rate 0.000000%\n",
      "At minibatch 103300, batch loss 0.017348, batch error rate 0.000000%\n",
      "At minibatch 103400, batch loss 0.018700, batch error rate 0.000000%\n",
      "At minibatch 103500, batch loss 0.021241, batch error rate 0.000000%\n",
      "After epoch 207: valid_err_rate: 0.017700% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 103600, batch loss 0.011570, batch error rate 0.000000%\n",
      "At minibatch 103700, batch loss 0.024460, batch error rate 0.000000%\n",
      "At minibatch 103800, batch loss 0.015378, batch error rate 0.000000%\n",
      "At minibatch 103900, batch loss 0.012812, batch error rate 0.000000%\n",
      "At minibatch 104000, batch loss 0.016248, batch error rate 0.000000%\n",
      "After epoch 208: valid_err_rate: 0.017800% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 104100, batch loss 0.037554, batch error rate 1.000000%\n",
      "At minibatch 104200, batch loss 0.024705, batch error rate 0.000000%\n",
      "At minibatch 104300, batch loss 0.033019, batch error rate 1.000000%\n",
      "At minibatch 104400, batch loss 0.019378, batch error rate 0.000000%\n",
      "At minibatch 104500, batch loss 0.017277, batch error rate 0.000000%\n",
      "After epoch 209: valid_err_rate: 0.018100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 104600, batch loss 0.009545, batch error rate 0.000000%\n",
      "At minibatch 104700, batch loss 0.015087, batch error rate 0.000000%\n",
      "At minibatch 104800, batch loss 0.015934, batch error rate 0.000000%\n",
      "At minibatch 104900, batch loss 0.031131, batch error rate 0.000000%\n",
      "At minibatch 105000, batch loss 0.028822, batch error rate 0.000000%\n",
      "After epoch 210: valid_err_rate: 0.018200% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 105100, batch loss 0.024936, batch error rate 0.000000%\n",
      "At minibatch 105200, batch loss 0.014845, batch error rate 0.000000%\n",
      "At minibatch 105300, batch loss 0.023537, batch error rate 0.000000%\n",
      "At minibatch 105400, batch loss 0.011627, batch error rate 0.000000%\n",
      "At minibatch 105500, batch loss 0.033418, batch error rate 1.000000%\n",
      "After epoch 211: valid_err_rate: 0.017800% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 105600, batch loss 0.009700, batch error rate 0.000000%\n",
      "At minibatch 105700, batch loss 0.021927, batch error rate 0.000000%\n",
      "At minibatch 105800, batch loss 0.016738, batch error rate 0.000000%\n",
      "At minibatch 105900, batch loss 0.029191, batch error rate 0.000000%\n",
      "At minibatch 106000, batch loss 0.036499, batch error rate 1.000000%\n",
      "After epoch 212: valid_err_rate: 0.017300% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 106100, batch loss 0.026118, batch error rate 0.000000%\n",
      "At minibatch 106200, batch loss 0.025159, batch error rate 0.000000%\n",
      "At minibatch 106300, batch loss 0.019707, batch error rate 0.000000%\n",
      "At minibatch 106400, batch loss 0.037167, batch error rate 1.000000%\n",
      "At minibatch 106500, batch loss 0.019714, batch error rate 0.000000%\n",
      "After epoch 213: valid_err_rate: 0.018200% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 106600, batch loss 0.026859, batch error rate 0.000000%\n",
      "At minibatch 106700, batch loss 0.009876, batch error rate 0.000000%\n",
      "At minibatch 106800, batch loss 0.021500, batch error rate 1.000000%\n",
      "At minibatch 106900, batch loss 0.016567, batch error rate 0.000000%\n",
      "At minibatch 107000, batch loss 0.010459, batch error rate 0.000000%\n",
      "After epoch 214: valid_err_rate: 0.018200% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 107100, batch loss 0.020420, batch error rate 0.000000%\n",
      "At minibatch 107200, batch loss 0.018343, batch error rate 0.000000%\n",
      "At minibatch 107300, batch loss 0.041209, batch error rate 2.000000%\n",
      "At minibatch 107400, batch loss 0.032158, batch error rate 1.000000%\n",
      "At minibatch 107500, batch loss 0.013933, batch error rate 0.000000%\n",
      "After epoch 215: valid_err_rate: 0.018500% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 107600, batch loss 0.014149, batch error rate 0.000000%\n",
      "At minibatch 107700, batch loss 0.021557, batch error rate 0.000000%\n",
      "At minibatch 107800, batch loss 0.013451, batch error rate 0.000000%\n",
      "At minibatch 107900, batch loss 0.029830, batch error rate 1.000000%\n",
      "At minibatch 108000, batch loss 0.019970, batch error rate 0.000000%\n",
      "After epoch 216: valid_err_rate: 0.018100% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 108100, batch loss 0.026170, batch error rate 0.000000%\n",
      "At minibatch 108200, batch loss 0.016331, batch error rate 0.000000%\n",
      "At minibatch 108300, batch loss 0.023799, batch error rate 0.000000%\n",
      "At minibatch 108400, batch loss 0.013563, batch error rate 0.000000%\n",
      "At minibatch 108500, batch loss 0.011201, batch error rate 0.000000%\n",
      "After epoch 217: valid_err_rate: 0.017400% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 108600, batch loss 0.018568, batch error rate 0.000000%\n",
      "At minibatch 108700, batch loss 0.025701, batch error rate 0.000000%\n",
      "At minibatch 108800, batch loss 0.034768, batch error rate 1.000000%\n",
      "At minibatch 108900, batch loss 0.022012, batch error rate 0.000000%\n",
      "At minibatch 109000, batch loss 0.031506, batch error rate 0.000000%\n",
      "After epoch 218: valid_err_rate: 0.018600% currently going ot do 218 epochs [best: 0.016900%]\n",
      "At minibatch 109100, batch loss 0.027326, batch error rate 0.000000%\n",
      "At minibatch 109200, batch loss 0.033569, batch error rate 0.000000%\n",
      "At minibatch 109300, batch loss 0.015609, batch error rate 0.000000%\n",
      "At minibatch 109400, batch loss 0.016688, batch error rate 0.000000%\n",
      "At minibatch 109500, batch loss 0.014525, batch error rate 0.000000%\n",
      "After epoch 219: valid_err_rate: 0.017700% currently going ot do 218 epochs [best: 0.016900%]\n",
      "Finished with 219 epochs (minibatch 109500), with best valid error rate 0.016900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0187"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27bae41250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_init = IsotropicGaussian(std=0.1, mean=0.0)\n",
    "net = FeedForwardNet([\n",
    "        AffineLayer(784, 800, weight_init = weight_init),\n",
    "        ReLULayer(),\n",
    "        AffineLayer(800, 800, weight_init = weight_init),\n",
    "        ReLULayer(),\n",
    "        AffineLayer(800, 10, weight_init = weight_init),\n",
    "        SoftMaxLayer()\n",
    "    ])\n",
    "SGD(net, mnist_train_stream, mnist_validation_stream, mnist_test_stream,\n",
    "    print_debug = True,\n",
    "    epochs = 3,\n",
    "    regularization_rate = 1e-3,\n",
    "    norm_limiting = 1.5,\n",
    "    alpha_alg = AlphaAlgExp(initial = 5e-2, rate = 0.992),\n",
    "    momentum_alg = MomentumAlg2())\n",
    "\n",
    "compute_error_rate(net, mnist_test_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 3 [2p bonus]\n",
    "\n",
    "Implement norm constraints, i.e. limit the total\n",
    "norm of connections incoming to a neuron. In our case, this\n",
    "corresponds to clipping the norm of *rows* of weight\n",
    "matrices. An easy way of implementing it is to make a gradient\n",
    "step, then look at the norm of rows and scale down those that are\n",
    "over the threshold (this technique is called \"projected gradient descent\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 [2p bonus]\n",
    "\n",
    "Implement a **dropout** layer and try to train a\n",
    "network getting below 1.5% test error rates with dropout (the best\n",
    "result is below 1\\% for dropout!). Details: http://arxiv.org/pdf/1207.0580.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network configuration: \n",
      "W(800, 784), b(800, 1), W(800, 800), b(800, 1), W(10, 800), b(10, 1)\n",
      "At minibatch 100, batch loss 1.917830, batch error rate 50.000000%\n",
      "At minibatch 200, batch loss 1.202583, batch error rate 26.000000%\n",
      "At minibatch 300, batch loss 1.039368, batch error rate 25.000000%\n",
      "At minibatch 400, batch loss 0.857477, batch error rate 20.000000%\n",
      "At minibatch 500, batch loss 0.598408, batch error rate 16.000000%\n",
      "After epoch 1: valid_err_rate: 0.138800% currently going ot do 2000 epochs [best: 0.138800%]\n",
      "At minibatch 600, batch loss 0.714850, batch error rate 19.000000%\n",
      "At minibatch 700, batch loss 0.669361, batch error rate 22.000000%\n",
      "At minibatch 800, batch loss 0.673588, batch error rate 22.000000%\n",
      "At minibatch 900, batch loss 0.573551, batch error rate 14.000000%\n",
      "At minibatch 1000, batch loss 0.685642, batch error rate 16.000000%\n",
      "After epoch 2: valid_err_rate: 0.115200% currently going ot do 2000 epochs [best: 0.115200%]\n",
      "At minibatch 1100, batch loss 0.741196, batch error rate 27.000000%\n",
      "At minibatch 1200, batch loss 0.458552, batch error rate 15.000000%\n",
      "At minibatch 1300, batch loss 0.544606, batch error rate 22.000000%\n",
      "At minibatch 1400, batch loss 0.414401, batch error rate 13.000000%\n",
      "At minibatch 1500, batch loss 0.556470, batch error rate 18.000000%\n",
      "After epoch 3: valid_err_rate: 0.115500% currently going ot do 2000 epochs [best: 0.115200%]\n",
      "At minibatch 1600, batch loss 0.537556, batch error rate 20.000000%\n",
      "At minibatch 1700, batch loss 0.605244, batch error rate 18.000000%\n",
      "At minibatch 1800, batch loss 0.530837, batch error rate 17.000000%\n",
      "At minibatch 1900, batch loss 0.478126, batch error rate 10.000000%\n",
      "At minibatch 2000, batch loss 0.557620, batch error rate 15.000000%\n",
      "After epoch 4: valid_err_rate: 0.109700% currently going ot do 2000 epochs [best: 0.109700%]\n",
      "At minibatch 2100, batch loss 0.628886, batch error rate 19.000000%\n",
      "At minibatch 2200, batch loss 0.591560, batch error rate 18.000000%\n",
      "At minibatch 2300, batch loss 0.753249, batch error rate 23.000000%\n",
      "At minibatch 2400, batch loss 0.394652, batch error rate 10.000000%\n",
      "At minibatch 2500, batch loss 0.618713, batch error rate 19.000000%\n",
      "After epoch 5: valid_err_rate: 0.107300% currently going ot do 2000 epochs [best: 0.107300%]\n",
      "At minibatch 2600, batch loss 0.548524, batch error rate 18.000000%\n",
      "At minibatch 2700, batch loss 0.433066, batch error rate 10.000000%\n",
      "At minibatch 2800, batch loss 0.456560, batch error rate 11.000000%\n",
      "At minibatch 2900, batch loss 0.618380, batch error rate 21.000000%\n",
      "At minibatch 3000, batch loss 0.676085, batch error rate 18.000000%\n",
      "After epoch 6: valid_err_rate: 0.102700% currently going ot do 2000 epochs [best: 0.102700%]\n",
      "At minibatch 3100, batch loss 0.405906, batch error rate 11.000000%\n",
      "At minibatch 3200, batch loss 0.425395, batch error rate 12.000000%\n",
      "At minibatch 3300, batch loss 0.671272, batch error rate 24.000000%\n",
      "At minibatch 3400, batch loss 0.553283, batch error rate 16.000000%\n",
      "At minibatch 3500, batch loss 0.345840, batch error rate 8.000000%\n",
      "After epoch 7: valid_err_rate: 0.103100% currently going ot do 2000 epochs [best: 0.102700%]\n",
      "At minibatch 3600, batch loss 0.594832, batch error rate 20.000000%\n",
      "At minibatch 3700, batch loss 0.543710, batch error rate 19.000000%\n",
      "At minibatch 3800, batch loss 0.452531, batch error rate 10.000000%\n",
      "At minibatch 3900, batch loss 0.418354, batch error rate 12.000000%\n",
      "At minibatch 4000, batch loss 0.633182, batch error rate 21.000000%\n",
      "After epoch 8: valid_err_rate: 0.107800% currently going ot do 2000 epochs [best: 0.102700%]\n",
      "At minibatch 4100, batch loss 0.461028, batch error rate 14.000000%\n",
      "At minibatch 4200, batch loss 0.654197, batch error rate 18.000000%\n",
      "At minibatch 4300, batch loss 0.535590, batch error rate 14.000000%\n",
      "At minibatch 4400, batch loss 0.505700, batch error rate 17.000000%\n",
      "At minibatch 4500, batch loss 0.913591, batch error rate 31.000000%\n",
      "After epoch 9: valid_err_rate: 0.102300% currently going ot do 2000 epochs [best: 0.102300%]\n",
      "At minibatch 4600, batch loss 0.449159, batch error rate 12.000000%\n",
      "At minibatch 4700, batch loss 0.448881, batch error rate 13.000000%\n",
      "At minibatch 4800, batch loss 0.374267, batch error rate 9.000000%\n",
      "At minibatch 4900, batch loss 0.713573, batch error rate 22.000000%\n",
      "At minibatch 5000, batch loss 0.445758, batch error rate 10.000000%\n",
      "After epoch 10: valid_err_rate: 0.098400% currently going ot do 2000 epochs [best: 0.098400%]\n",
      "At minibatch 5100, batch loss 0.437908, batch error rate 12.000000%\n",
      "At minibatch 5200, batch loss 0.534656, batch error rate 10.000000%\n",
      "At minibatch 5300, batch loss 0.417784, batch error rate 8.000000%\n",
      "At minibatch 5400, batch loss 0.453583, batch error rate 12.000000%\n",
      "At minibatch 5500, batch loss 0.408062, batch error rate 11.000000%\n",
      "After epoch 11: valid_err_rate: 0.092400% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 5600, batch loss 0.409650, batch error rate 8.000000%\n",
      "At minibatch 5700, batch loss 0.529401, batch error rate 15.000000%\n",
      "At minibatch 5800, batch loss 0.569224, batch error rate 18.000000%\n",
      "At minibatch 5900, batch loss 0.605709, batch error rate 23.000000%\n",
      "At minibatch 6000, batch loss 0.470848, batch error rate 15.000000%\n",
      "After epoch 12: valid_err_rate: 0.098700% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 6100, batch loss 0.373381, batch error rate 10.000000%\n",
      "At minibatch 6200, batch loss 0.592846, batch error rate 18.000000%\n",
      "At minibatch 6300, batch loss 0.442944, batch error rate 13.000000%\n",
      "At minibatch 6400, batch loss 0.509707, batch error rate 11.000000%\n",
      "At minibatch 6500, batch loss 0.484857, batch error rate 16.000000%\n",
      "After epoch 13: valid_err_rate: 0.097400% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 6600, batch loss 0.542507, batch error rate 14.000000%\n",
      "At minibatch 6700, batch loss 0.544700, batch error rate 10.000000%\n",
      "At minibatch 6800, batch loss 0.488124, batch error rate 17.000000%\n",
      "At minibatch 6900, batch loss 0.494336, batch error rate 15.000000%\n",
      "At minibatch 7000, batch loss 0.470534, batch error rate 12.000000%\n",
      "After epoch 14: valid_err_rate: 0.099000% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 7100, batch loss 0.416145, batch error rate 10.000000%\n",
      "At minibatch 7200, batch loss 0.470610, batch error rate 14.000000%\n",
      "At minibatch 7300, batch loss 0.446054, batch error rate 13.000000%\n",
      "At minibatch 7400, batch loss 0.537304, batch error rate 18.000000%\n",
      "At minibatch 7500, batch loss 0.394683, batch error rate 8.000000%\n",
      "After epoch 15: valid_err_rate: 0.100500% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 7600, batch loss 0.448495, batch error rate 13.000000%\n",
      "At minibatch 7700, batch loss 0.369640, batch error rate 12.000000%\n",
      "At minibatch 7800, batch loss 0.333553, batch error rate 8.000000%\n",
      "At minibatch 7900, batch loss 0.450984, batch error rate 10.000000%\n",
      "At minibatch 8000, batch loss 0.537245, batch error rate 15.000000%\n",
      "After epoch 16: valid_err_rate: 0.098500% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 8100, batch loss 0.454749, batch error rate 9.000000%\n",
      "At minibatch 8200, batch loss 0.348281, batch error rate 10.000000%\n",
      "At minibatch 8300, batch loss 0.612583, batch error rate 20.000000%\n",
      "At minibatch 8400, batch loss 0.457047, batch error rate 10.000000%\n",
      "At minibatch 8500, batch loss 0.475621, batch error rate 14.000000%\n",
      "After epoch 17: valid_err_rate: 0.092800% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 8600, batch loss 0.508806, batch error rate 17.000000%\n",
      "At minibatch 8700, batch loss 0.581721, batch error rate 18.000000%\n",
      "At minibatch 8800, batch loss 0.439410, batch error rate 10.000000%\n",
      "At minibatch 8900, batch loss 0.463645, batch error rate 13.000000%\n",
      "At minibatch 9000, batch loss 0.459535, batch error rate 11.000000%\n",
      "After epoch 18: valid_err_rate: 0.099000% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 9100, batch loss 0.466554, batch error rate 13.000000%\n",
      "At minibatch 9200, batch loss 0.415147, batch error rate 11.000000%\n",
      "At minibatch 9300, batch loss 0.390870, batch error rate 9.000000%\n",
      "At minibatch 9400, batch loss 0.542603, batch error rate 18.000000%\n",
      "At minibatch 9500, batch loss 0.498609, batch error rate 11.000000%\n",
      "After epoch 19: valid_err_rate: 0.094300% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 9600, batch loss 0.612266, batch error rate 15.000000%\n",
      "At minibatch 9700, batch loss 0.352380, batch error rate 9.000000%\n",
      "At minibatch 9800, batch loss 0.460983, batch error rate 16.000000%\n",
      "At minibatch 9900, batch loss 0.477100, batch error rate 11.000000%\n",
      "At minibatch 10000, batch loss 0.388139, batch error rate 12.000000%\n",
      "After epoch 20: valid_err_rate: 0.100500% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 10100, batch loss 0.556283, batch error rate 18.000000%\n",
      "At minibatch 10200, batch loss 0.481322, batch error rate 14.000000%\n",
      "At minibatch 10300, batch loss 0.522922, batch error rate 16.000000%\n",
      "At minibatch 10400, batch loss 0.556858, batch error rate 16.000000%\n",
      "At minibatch 10500, batch loss 0.396205, batch error rate 10.000000%\n",
      "After epoch 21: valid_err_rate: 0.095100% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 10600, batch loss 0.454804, batch error rate 13.000000%\n",
      "At minibatch 10700, batch loss 0.438784, batch error rate 15.000000%\n",
      "At minibatch 10800, batch loss 0.592381, batch error rate 17.000000%\n",
      "At minibatch 10900, batch loss 0.453238, batch error rate 12.000000%\n",
      "At minibatch 11000, batch loss 0.283029, batch error rate 7.000000%\n",
      "After epoch 22: valid_err_rate: 0.094600% currently going ot do 2000 epochs [best: 0.092400%]\n",
      "At minibatch 11100, batch loss 0.615436, batch error rate 16.000000%\n",
      "At minibatch 11200, batch loss 0.443511, batch error rate 11.000000%\n",
      "At minibatch 11300, batch loss 0.491142, batch error rate 15.000000%\n",
      "At minibatch 11400, batch loss 0.612680, batch error rate 14.000000%\n",
      "At minibatch 11500, batch loss 0.366579, batch error rate 10.000000%\n",
      "After epoch 23: valid_err_rate: 0.090300% currently going ot do 2000 epochs [best: 0.090300%]\n",
      "At minibatch 11600, batch loss 0.456575, batch error rate 12.000000%\n",
      "At minibatch 11700, batch loss 0.339788, batch error rate 8.000000%\n",
      "At minibatch 11800, batch loss 0.510044, batch error rate 16.000000%\n",
      "At minibatch 11900, batch loss 0.479735, batch error rate 12.000000%\n",
      "At minibatch 12000, batch loss 0.433448, batch error rate 13.000000%\n",
      "After epoch 24: valid_err_rate: 0.094800% currently going ot do 2000 epochs [best: 0.090300%]\n",
      "At minibatch 12100, batch loss 0.385385, batch error rate 10.000000%\n",
      "At minibatch 12200, batch loss 0.467164, batch error rate 7.000000%\n",
      "At minibatch 12300, batch loss 0.477998, batch error rate 14.000000%\n",
      "At minibatch 12400, batch loss 0.427481, batch error rate 9.000000%\n",
      "At minibatch 12500, batch loss 0.513292, batch error rate 17.000000%\n",
      "After epoch 25: valid_err_rate: 0.093000% currently going ot do 2000 epochs [best: 0.090300%]\n",
      "At minibatch 12600, batch loss 0.581644, batch error rate 17.000000%\n",
      "At minibatch 12700, batch loss 0.506745, batch error rate 14.000000%\n",
      "At minibatch 12800, batch loss 0.518150, batch error rate 13.000000%\n",
      "At minibatch 12900, batch loss 0.342511, batch error rate 7.000000%\n",
      "At minibatch 13000, batch loss 0.485292, batch error rate 12.000000%\n",
      "After epoch 26: valid_err_rate: 0.094600% currently going ot do 2000 epochs [best: 0.090300%]\n",
      "At minibatch 13100, batch loss 0.488034, batch error rate 14.000000%\n",
      "At minibatch 13200, batch loss 0.565742, batch error rate 14.000000%\n",
      "At minibatch 13300, batch loss 0.532461, batch error rate 15.000000%\n",
      "At minibatch 13400, batch loss 0.610139, batch error rate 13.000000%\n",
      "At minibatch 13500, batch loss 0.535466, batch error rate 19.000000%\n",
      "After epoch 27: valid_err_rate: 0.092100% currently going ot do 2000 epochs [best: 0.090300%]\n",
      "At minibatch 13600, batch loss 0.541601, batch error rate 13.000000%\n",
      "At minibatch 13700, batch loss 0.641493, batch error rate 15.000000%\n",
      "At minibatch 13800, batch loss 0.503675, batch error rate 14.000000%\n",
      "At minibatch 13900, batch loss 0.451643, batch error rate 11.000000%\n",
      "At minibatch 14000, batch loss 0.425386, batch error rate 14.000000%\n",
      "After epoch 28: valid_err_rate: 0.091900% currently going ot do 2000 epochs [best: 0.090300%]\n",
      "At minibatch 14100, batch loss 0.487654, batch error rate 14.000000%\n",
      "At minibatch 14200, batch loss 0.462921, batch error rate 12.000000%\n",
      "At minibatch 14300, batch loss 0.394410, batch error rate 10.000000%\n",
      "At minibatch 14400, batch loss 0.397126, batch error rate 11.000000%\n",
      "At minibatch 14500, batch loss 0.389817, batch error rate 8.000000%\n",
      "After epoch 29: valid_err_rate: 0.089600% currently going ot do 2000 epochs [best: 0.089600%]\n",
      "At minibatch 14600, batch loss 0.460818, batch error rate 10.000000%\n",
      "At minibatch 14700, batch loss 0.376397, batch error rate 11.000000%\n",
      "At minibatch 14800, batch loss 0.496622, batch error rate 12.000000%\n",
      "At minibatch 14900, batch loss 0.433850, batch error rate 13.000000%\n",
      "At minibatch 15000, batch loss 0.503605, batch error rate 13.000000%\n",
      "After epoch 30: valid_err_rate: 0.089600% currently going ot do 2000 epochs [best: 0.089600%]\n",
      "At minibatch 15100, batch loss 0.476172, batch error rate 16.000000%\n",
      "At minibatch 15200, batch loss 0.624611, batch error rate 20.000000%\n",
      "At minibatch 15300, batch loss 0.516511, batch error rate 17.000000%\n",
      "At minibatch 15400, batch loss 0.388236, batch error rate 8.000000%\n",
      "At minibatch 15500, batch loss 0.361392, batch error rate 11.000000%\n",
      "After epoch 31: valid_err_rate: 0.089800% currently going ot do 2000 epochs [best: 0.089600%]\n",
      "At minibatch 15600, batch loss 0.555755, batch error rate 15.000000%\n",
      "At minibatch 15700, batch loss 0.513148, batch error rate 12.000000%\n",
      "At minibatch 15800, batch loss 0.487446, batch error rate 14.000000%\n",
      "At minibatch 15900, batch loss 0.604789, batch error rate 19.000000%\n",
      "At minibatch 16000, batch loss 0.437825, batch error rate 11.000000%\n",
      "After epoch 32: valid_err_rate: 0.092100% currently going ot do 2000 epochs [best: 0.089600%]\n",
      "At minibatch 16100, batch loss 0.399695, batch error rate 10.000000%\n",
      "At minibatch 16200, batch loss 0.422592, batch error rate 12.000000%\n",
      "At minibatch 16300, batch loss 0.429489, batch error rate 14.000000%\n",
      "At minibatch 16400, batch loss 0.547767, batch error rate 13.000000%\n",
      "At minibatch 16500, batch loss 0.470310, batch error rate 13.000000%\n",
      "After epoch 33: valid_err_rate: 0.087700% currently going ot do 2000 epochs [best: 0.087700%]\n",
      "At minibatch 16600, batch loss 0.405605, batch error rate 10.000000%\n",
      "At minibatch 16700, batch loss 0.424024, batch error rate 11.000000%\n",
      "At minibatch 16800, batch loss 0.439634, batch error rate 13.000000%\n",
      "At minibatch 16900, batch loss 0.348512, batch error rate 9.000000%\n",
      "At minibatch 17000, batch loss 0.570900, batch error rate 13.000000%\n",
      "After epoch 34: valid_err_rate: 0.091900% currently going ot do 2000 epochs [best: 0.087700%]\n",
      "At minibatch 17100, batch loss 0.366448, batch error rate 8.000000%\n",
      "At minibatch 17200, batch loss 0.511571, batch error rate 14.000000%\n",
      "At minibatch 17300, batch loss 0.558792, batch error rate 19.000000%\n",
      "At minibatch 17400, batch loss 0.380669, batch error rate 11.000000%\n",
      "At minibatch 17500, batch loss 0.513303, batch error rate 15.000000%\n",
      "After epoch 35: valid_err_rate: 0.087700% currently going ot do 2000 epochs [best: 0.087700%]\n",
      "At minibatch 17600, batch loss 0.521434, batch error rate 12.000000%\n",
      "At minibatch 17700, batch loss 0.484106, batch error rate 11.000000%\n",
      "At minibatch 17800, batch loss 0.511387, batch error rate 16.000000%\n",
      "At minibatch 17900, batch loss 0.302537, batch error rate 7.000000%\n",
      "At minibatch 18000, batch loss 0.527950, batch error rate 15.000000%\n",
      "After epoch 36: valid_err_rate: 0.093200% currently going ot do 2000 epochs [best: 0.087700%]\n",
      "At minibatch 18100, batch loss 0.391478, batch error rate 10.000000%\n",
      "At minibatch 18200, batch loss 0.484713, batch error rate 12.000000%\n",
      "At minibatch 18300, batch loss 0.486207, batch error rate 14.000000%\n",
      "At minibatch 18400, batch loss 0.483879, batch error rate 13.000000%\n",
      "At minibatch 18500, batch loss 0.467426, batch error rate 14.000000%\n",
      "After epoch 37: valid_err_rate: 0.087300% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 18600, batch loss 0.434304, batch error rate 13.000000%\n",
      "At minibatch 18700, batch loss 0.543581, batch error rate 12.000000%\n",
      "At minibatch 18800, batch loss 0.438904, batch error rate 13.000000%\n",
      "At minibatch 18900, batch loss 0.572982, batch error rate 15.000000%\n",
      "At minibatch 19000, batch loss 0.372879, batch error rate 7.000000%\n",
      "After epoch 38: valid_err_rate: 0.088800% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 19100, batch loss 0.370531, batch error rate 10.000000%\n",
      "At minibatch 19200, batch loss 0.377900, batch error rate 10.000000%\n",
      "At minibatch 19300, batch loss 0.430054, batch error rate 14.000000%\n",
      "At minibatch 19400, batch loss 0.393739, batch error rate 11.000000%\n",
      "At minibatch 19500, batch loss 0.377090, batch error rate 11.000000%\n",
      "After epoch 39: valid_err_rate: 0.092000% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 19600, batch loss 0.388260, batch error rate 10.000000%\n",
      "At minibatch 19700, batch loss 0.437881, batch error rate 11.000000%\n",
      "At minibatch 19800, batch loss 0.517569, batch error rate 15.000000%\n",
      "At minibatch 19900, batch loss 0.378231, batch error rate 10.000000%\n",
      "At minibatch 20000, batch loss 0.464726, batch error rate 11.000000%\n",
      "After epoch 40: valid_err_rate: 0.090600% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 20100, batch loss 0.562426, batch error rate 16.000000%\n",
      "At minibatch 20200, batch loss 0.467454, batch error rate 12.000000%\n",
      "At minibatch 20300, batch loss 0.425427, batch error rate 10.000000%\n",
      "At minibatch 20400, batch loss 0.506321, batch error rate 15.000000%\n",
      "At minibatch 20500, batch loss 0.490363, batch error rate 16.000000%\n",
      "After epoch 41: valid_err_rate: 0.092100% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 20600, batch loss 0.491110, batch error rate 9.000000%\n",
      "At minibatch 20700, batch loss 0.433299, batch error rate 10.000000%\n",
      "At minibatch 20800, batch loss 0.435280, batch error rate 13.000000%\n",
      "At minibatch 20900, batch loss 0.420059, batch error rate 10.000000%\n",
      "At minibatch 21000, batch loss 0.477189, batch error rate 14.000000%\n",
      "After epoch 42: valid_err_rate: 0.088400% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 21100, batch loss 0.575691, batch error rate 16.000000%\n",
      "At minibatch 21200, batch loss 0.406686, batch error rate 12.000000%\n",
      "At minibatch 21300, batch loss 0.456229, batch error rate 13.000000%\n",
      "At minibatch 21400, batch loss 0.533415, batch error rate 13.000000%\n",
      "At minibatch 21500, batch loss 0.491509, batch error rate 11.000000%\n",
      "After epoch 43: valid_err_rate: 0.089500% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 21600, batch loss 0.467472, batch error rate 9.000000%\n",
      "At minibatch 21700, batch loss 0.521415, batch error rate 13.000000%\n",
      "At minibatch 21800, batch loss 0.402143, batch error rate 11.000000%\n",
      "At minibatch 21900, batch loss 0.399912, batch error rate 9.000000%\n",
      "At minibatch 22000, batch loss 0.436617, batch error rate 12.000000%\n",
      "After epoch 44: valid_err_rate: 0.091300% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 22100, batch loss 0.413336, batch error rate 9.000000%\n",
      "At minibatch 22200, batch loss 0.343628, batch error rate 10.000000%\n",
      "At minibatch 22300, batch loss 0.519114, batch error rate 16.000000%\n",
      "At minibatch 22400, batch loss 0.396661, batch error rate 10.000000%\n",
      "At minibatch 22500, batch loss 0.555512, batch error rate 16.000000%\n",
      "After epoch 45: valid_err_rate: 0.089000% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 22600, batch loss 0.414504, batch error rate 11.000000%\n",
      "At minibatch 22700, batch loss 0.478244, batch error rate 11.000000%\n",
      "At minibatch 22800, batch loss 0.518381, batch error rate 14.000000%\n",
      "At minibatch 22900, batch loss 0.446704, batch error rate 13.000000%\n",
      "At minibatch 23000, batch loss 0.410070, batch error rate 16.000000%\n",
      "After epoch 46: valid_err_rate: 0.091400% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 23100, batch loss 0.479133, batch error rate 11.000000%\n",
      "At minibatch 23200, batch loss 0.387187, batch error rate 12.000000%\n",
      "At minibatch 23300, batch loss 0.402504, batch error rate 12.000000%\n",
      "At minibatch 23400, batch loss 0.440616, batch error rate 12.000000%\n",
      "At minibatch 23500, batch loss 0.512195, batch error rate 15.000000%\n",
      "After epoch 47: valid_err_rate: 0.089600% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 23600, batch loss 0.561937, batch error rate 16.000000%\n",
      "At minibatch 23700, batch loss 0.423303, batch error rate 13.000000%\n",
      "At minibatch 23800, batch loss 0.531967, batch error rate 17.000000%\n",
      "At minibatch 23900, batch loss 0.433360, batch error rate 11.000000%\n",
      "At minibatch 24000, batch loss 0.407566, batch error rate 10.000000%\n",
      "After epoch 48: valid_err_rate: 0.094200% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 24100, batch loss 0.466574, batch error rate 14.000000%\n",
      "At minibatch 24200, batch loss 0.426731, batch error rate 12.000000%\n",
      "At minibatch 24300, batch loss 0.436881, batch error rate 10.000000%\n",
      "At minibatch 24400, batch loss 0.625606, batch error rate 20.000000%\n",
      "At minibatch 24500, batch loss 0.466811, batch error rate 13.000000%\n",
      "After epoch 49: valid_err_rate: 0.090100% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 24600, batch loss 0.394268, batch error rate 12.000000%\n",
      "At minibatch 24700, batch loss 0.372377, batch error rate 11.000000%\n",
      "At minibatch 24800, batch loss 0.474241, batch error rate 14.000000%\n",
      "At minibatch 24900, batch loss 0.500595, batch error rate 11.000000%\n",
      "At minibatch 25000, batch loss 0.448367, batch error rate 8.000000%\n",
      "After epoch 50: valid_err_rate: 0.093600% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 25100, batch loss 0.625835, batch error rate 20.000000%\n",
      "At minibatch 25200, batch loss 0.426602, batch error rate 9.000000%\n",
      "At minibatch 25300, batch loss 0.480373, batch error rate 14.000000%\n",
      "At minibatch 25400, batch loss 0.412379, batch error rate 11.000000%\n",
      "At minibatch 25500, batch loss 0.374957, batch error rate 10.000000%\n",
      "After epoch 51: valid_err_rate: 0.089700% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 25600, batch loss 0.389733, batch error rate 12.000000%\n",
      "At minibatch 25700, batch loss 0.471698, batch error rate 9.000000%\n",
      "At minibatch 25800, batch loss 0.506278, batch error rate 16.000000%\n",
      "At minibatch 25900, batch loss 0.446646, batch error rate 13.000000%\n",
      "At minibatch 26000, batch loss 0.602960, batch error rate 22.000000%\n",
      "After epoch 52: valid_err_rate: 0.087400% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 26100, batch loss 0.406839, batch error rate 13.000000%\n",
      "At minibatch 26200, batch loss 0.423105, batch error rate 15.000000%\n",
      "At minibatch 26300, batch loss 0.442818, batch error rate 12.000000%\n",
      "At minibatch 26400, batch loss 0.360984, batch error rate 9.000000%\n",
      "At minibatch 26500, batch loss 0.482603, batch error rate 17.000000%\n",
      "After epoch 53: valid_err_rate: 0.089100% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 26600, batch loss 0.504355, batch error rate 15.000000%\n",
      "At minibatch 26700, batch loss 0.401389, batch error rate 10.000000%\n",
      "At minibatch 26800, batch loss 0.348238, batch error rate 8.000000%\n",
      "At minibatch 26900, batch loss 0.461610, batch error rate 9.000000%\n",
      "At minibatch 27000, batch loss 0.541203, batch error rate 15.000000%\n",
      "After epoch 54: valid_err_rate: 0.088800% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 27100, batch loss 0.402902, batch error rate 9.000000%\n",
      "At minibatch 27200, batch loss 0.467391, batch error rate 11.000000%\n",
      "At minibatch 27300, batch loss 0.376034, batch error rate 9.000000%\n",
      "At minibatch 27400, batch loss 0.501964, batch error rate 15.000000%\n",
      "At minibatch 27500, batch loss 0.492148, batch error rate 14.000000%\n",
      "After epoch 55: valid_err_rate: 0.090200% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 27600, batch loss 0.480911, batch error rate 10.000000%\n",
      "At minibatch 27700, batch loss 0.472377, batch error rate 12.000000%\n",
      "At minibatch 27800, batch loss 0.475375, batch error rate 14.000000%\n",
      "At minibatch 27900, batch loss 0.448342, batch error rate 9.000000%\n",
      "At minibatch 28000, batch loss 0.545687, batch error rate 12.000000%\n",
      "After epoch 56: valid_err_rate: 0.089900% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 28100, batch loss 0.454992, batch error rate 9.000000%\n",
      "At minibatch 28200, batch loss 0.392678, batch error rate 9.000000%\n",
      "At minibatch 28300, batch loss 0.511684, batch error rate 12.000000%\n",
      "At minibatch 28400, batch loss 0.431383, batch error rate 8.000000%\n",
      "At minibatch 28500, batch loss 0.433612, batch error rate 14.000000%\n",
      "After epoch 57: valid_err_rate: 0.089100% currently going ot do 2000 epochs [best: 0.087300%]\n",
      "At minibatch 28600, batch loss 0.452247, batch error rate 8.000000%\n",
      "At minibatch 28700, batch loss 0.429050, batch error rate 9.000000%\n",
      "At minibatch 28800, batch loss 0.442811, batch error rate 14.000000%\n",
      "At minibatch 28900, batch loss 0.519687, batch error rate 15.000000%\n",
      "At minibatch 29000, batch loss 0.535598, batch error rate 12.000000%\n",
      "After epoch 58: valid_err_rate: 0.085800% currently going ot do 2000 epochs [best: 0.085800%]\n",
      "At minibatch 29100, batch loss 0.511157, batch error rate 13.000000%\n",
      "At minibatch 29200, batch loss 0.458165, batch error rate 14.000000%\n",
      "At minibatch 29300, batch loss 0.469862, batch error rate 12.000000%\n",
      "At minibatch 29400, batch loss 0.542323, batch error rate 13.000000%\n",
      "At minibatch 29500, batch loss 0.451669, batch error rate 10.000000%\n",
      "After epoch 59: valid_err_rate: 0.095600% currently going ot do 2000 epochs [best: 0.085800%]\n",
      "At minibatch 29600, batch loss 0.456558, batch error rate 10.000000%\n",
      "At minibatch 29700, batch loss 0.478837, batch error rate 13.000000%\n",
      "At minibatch 29800, batch loss 0.547642, batch error rate 10.000000%\n",
      "At minibatch 29900, batch loss 0.388055, batch error rate 11.000000%\n",
      "At minibatch 30000, batch loss 0.513209, batch error rate 14.000000%\n",
      "After epoch 60: valid_err_rate: 0.086200% currently going ot do 2000 epochs [best: 0.085800%]\n",
      "At minibatch 30100, batch loss 0.425946, batch error rate 13.000000%\n",
      "At minibatch 30200, batch loss 0.282789, batch error rate 5.000000%\n",
      "At minibatch 30300, batch loss 0.589288, batch error rate 20.000000%\n",
      "At minibatch 30400, batch loss 0.541915, batch error rate 17.000000%\n",
      "At minibatch 30500, batch loss 0.469995, batch error rate 12.000000%\n",
      "After epoch 61: valid_err_rate: 0.084000% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 30600, batch loss 0.380217, batch error rate 9.000000%\n",
      "At minibatch 30700, batch loss 0.543308, batch error rate 15.000000%\n",
      "At minibatch 30800, batch loss 0.384601, batch error rate 9.000000%\n",
      "At minibatch 30900, batch loss 0.401457, batch error rate 8.000000%\n",
      "At minibatch 31000, batch loss 0.370827, batch error rate 8.000000%\n",
      "After epoch 62: valid_err_rate: 0.087300% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 31100, batch loss 0.654415, batch error rate 20.000000%\n",
      "At minibatch 31200, batch loss 0.518198, batch error rate 14.000000%\n",
      "At minibatch 31300, batch loss 0.532417, batch error rate 15.000000%\n",
      "At minibatch 31400, batch loss 0.322671, batch error rate 4.000000%\n",
      "At minibatch 31500, batch loss 0.419608, batch error rate 13.000000%\n",
      "After epoch 63: valid_err_rate: 0.087100% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 31600, batch loss 0.389675, batch error rate 13.000000%\n",
      "At minibatch 31700, batch loss 0.346345, batch error rate 11.000000%\n",
      "At minibatch 31800, batch loss 0.548844, batch error rate 13.000000%\n",
      "At minibatch 31900, batch loss 0.386356, batch error rate 8.000000%\n",
      "At minibatch 32000, batch loss 0.465058, batch error rate 13.000000%\n",
      "After epoch 64: valid_err_rate: 0.087100% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 32100, batch loss 0.471832, batch error rate 12.000000%\n",
      "At minibatch 32200, batch loss 0.364717, batch error rate 12.000000%\n",
      "At minibatch 32300, batch loss 0.571398, batch error rate 13.000000%\n",
      "At minibatch 32400, batch loss 0.338977, batch error rate 10.000000%\n",
      "At minibatch 32500, batch loss 0.372351, batch error rate 10.000000%\n",
      "After epoch 65: valid_err_rate: 0.085800% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 32600, batch loss 0.434652, batch error rate 12.000000%\n",
      "At minibatch 32700, batch loss 0.506308, batch error rate 11.000000%\n",
      "At minibatch 32800, batch loss 0.619182, batch error rate 19.000000%\n",
      "At minibatch 32900, batch loss 0.450103, batch error rate 11.000000%\n",
      "At minibatch 33000, batch loss 0.343326, batch error rate 8.000000%\n",
      "After epoch 66: valid_err_rate: 0.087900% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 33100, batch loss 0.539674, batch error rate 14.000000%\n",
      "At minibatch 33200, batch loss 0.412915, batch error rate 13.000000%\n",
      "At minibatch 33300, batch loss 0.495602, batch error rate 16.000000%\n",
      "At minibatch 33400, batch loss 0.466153, batch error rate 12.000000%\n",
      "At minibatch 33500, batch loss 0.351441, batch error rate 8.000000%\n",
      "After epoch 67: valid_err_rate: 0.088900% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 33600, batch loss 0.421506, batch error rate 13.000000%\n",
      "At minibatch 33700, batch loss 0.443346, batch error rate 12.000000%\n",
      "At minibatch 33800, batch loss 0.535613, batch error rate 17.000000%\n",
      "At minibatch 33900, batch loss 0.432593, batch error rate 14.000000%\n",
      "At minibatch 34000, batch loss 0.382174, batch error rate 10.000000%\n",
      "After epoch 68: valid_err_rate: 0.085500% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 34100, batch loss 0.390152, batch error rate 8.000000%\n",
      "At minibatch 34200, batch loss 0.410322, batch error rate 10.000000%\n",
      "At minibatch 34300, batch loss 0.531134, batch error rate 16.000000%\n",
      "At minibatch 34400, batch loss 0.485116, batch error rate 17.000000%\n",
      "At minibatch 34500, batch loss 0.342126, batch error rate 8.000000%\n",
      "After epoch 69: valid_err_rate: 0.087600% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 34600, batch loss 0.498600, batch error rate 16.000000%\n",
      "At minibatch 34700, batch loss 0.477103, batch error rate 19.000000%\n",
      "At minibatch 34800, batch loss 0.532660, batch error rate 14.000000%\n",
      "At minibatch 34900, batch loss 0.350573, batch error rate 7.000000%\n",
      "At minibatch 35000, batch loss 0.421670, batch error rate 8.000000%\n",
      "After epoch 70: valid_err_rate: 0.086300% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 35100, batch loss 0.458884, batch error rate 11.000000%\n",
      "At minibatch 35200, batch loss 0.436694, batch error rate 12.000000%\n",
      "At minibatch 35300, batch loss 0.454398, batch error rate 13.000000%\n",
      "At minibatch 35400, batch loss 0.390878, batch error rate 10.000000%\n",
      "At minibatch 35500, batch loss 0.506263, batch error rate 14.000000%\n",
      "After epoch 71: valid_err_rate: 0.090100% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 35600, batch loss 0.524416, batch error rate 10.000000%\n",
      "At minibatch 35700, batch loss 0.429226, batch error rate 13.000000%\n",
      "At minibatch 35800, batch loss 0.502066, batch error rate 7.000000%\n",
      "At minibatch 35900, batch loss 0.434776, batch error rate 13.000000%\n",
      "At minibatch 36000, batch loss 0.344553, batch error rate 10.000000%\n",
      "After epoch 72: valid_err_rate: 0.086600% currently going ot do 2000 epochs [best: 0.084000%]\n",
      "At minibatch 36100, batch loss 0.445432, batch error rate 13.000000%\n",
      "At minibatch 36200, batch loss 0.508375, batch error rate 14.000000%\n",
      "At minibatch 36300, batch loss 0.363704, batch error rate 7.000000%\n",
      "At minibatch 36400, batch loss 0.432671, batch error rate 9.000000%\n",
      "At minibatch 36500, batch loss 0.317960, batch error rate 6.000000%\n",
      "After epoch 73: valid_err_rate: 0.082000% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 36600, batch loss 0.423803, batch error rate 11.000000%\n",
      "At minibatch 36700, batch loss 0.371960, batch error rate 8.000000%\n",
      "At minibatch 36800, batch loss 0.329520, batch error rate 7.000000%\n",
      "At minibatch 36900, batch loss 0.554462, batch error rate 15.000000%\n",
      "At minibatch 37000, batch loss 0.467367, batch error rate 14.000000%\n",
      "After epoch 74: valid_err_rate: 0.093000% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 37100, batch loss 0.691743, batch error rate 18.000000%\n",
      "At minibatch 37200, batch loss 0.404515, batch error rate 7.000000%\n",
      "At minibatch 37300, batch loss 0.350983, batch error rate 4.000000%\n",
      "At minibatch 37400, batch loss 0.260903, batch error rate 5.000000%\n",
      "At minibatch 37500, batch loss 0.443702, batch error rate 14.000000%\n",
      "After epoch 75: valid_err_rate: 0.082700% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 37600, batch loss 0.399563, batch error rate 13.000000%\n",
      "At minibatch 37700, batch loss 0.423791, batch error rate 10.000000%\n",
      "At minibatch 37800, batch loss 0.419703, batch error rate 13.000000%\n",
      "At minibatch 37900, batch loss 0.519337, batch error rate 15.000000%\n",
      "At minibatch 38000, batch loss 0.523372, batch error rate 17.000000%\n",
      "After epoch 76: valid_err_rate: 0.086900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 38100, batch loss 0.502259, batch error rate 14.000000%\n",
      "At minibatch 38200, batch loss 0.591144, batch error rate 15.000000%\n",
      "At minibatch 38300, batch loss 0.403684, batch error rate 12.000000%\n",
      "At minibatch 38400, batch loss 0.286703, batch error rate 4.000000%\n",
      "At minibatch 38500, batch loss 0.369361, batch error rate 12.000000%\n",
      "After epoch 77: valid_err_rate: 0.085200% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 38600, batch loss 0.443455, batch error rate 14.000000%\n",
      "At minibatch 38700, batch loss 0.641019, batch error rate 15.000000%\n",
      "At minibatch 38800, batch loss 0.475684, batch error rate 19.000000%\n",
      "At minibatch 38900, batch loss 0.625315, batch error rate 19.000000%\n",
      "At minibatch 39000, batch loss 0.521701, batch error rate 11.000000%\n",
      "After epoch 78: valid_err_rate: 0.086800% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 39100, batch loss 0.542020, batch error rate 16.000000%\n",
      "At minibatch 39200, batch loss 0.424645, batch error rate 11.000000%\n",
      "At minibatch 39300, batch loss 0.411525, batch error rate 11.000000%\n",
      "At minibatch 39400, batch loss 0.550206, batch error rate 16.000000%\n",
      "At minibatch 39500, batch loss 0.407622, batch error rate 9.000000%\n",
      "After epoch 79: valid_err_rate: 0.090500% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 39600, batch loss 0.520271, batch error rate 12.000000%\n",
      "At minibatch 39700, batch loss 0.349598, batch error rate 9.000000%\n",
      "At minibatch 39800, batch loss 0.443993, batch error rate 13.000000%\n",
      "At minibatch 39900, batch loss 0.489539, batch error rate 15.000000%\n",
      "At minibatch 40000, batch loss 0.426802, batch error rate 15.000000%\n",
      "After epoch 80: valid_err_rate: 0.086600% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 40100, batch loss 0.487247, batch error rate 14.000000%\n",
      "At minibatch 40200, batch loss 0.528871, batch error rate 13.000000%\n",
      "At minibatch 40300, batch loss 0.421121, batch error rate 14.000000%\n",
      "At minibatch 40400, batch loss 0.483470, batch error rate 12.000000%\n",
      "At minibatch 40500, batch loss 0.495480, batch error rate 13.000000%\n",
      "After epoch 81: valid_err_rate: 0.084300% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 40600, batch loss 0.366920, batch error rate 12.000000%\n",
      "At minibatch 40700, batch loss 0.359476, batch error rate 10.000000%\n",
      "At minibatch 40800, batch loss 0.396285, batch error rate 7.000000%\n",
      "At minibatch 40900, batch loss 0.483514, batch error rate 14.000000%\n",
      "At minibatch 41000, batch loss 0.361718, batch error rate 8.000000%\n",
      "After epoch 82: valid_err_rate: 0.087900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 41100, batch loss 0.410009, batch error rate 14.000000%\n",
      "At minibatch 41200, batch loss 0.373507, batch error rate 11.000000%\n",
      "At minibatch 41300, batch loss 0.365657, batch error rate 11.000000%\n",
      "At minibatch 41400, batch loss 0.513219, batch error rate 15.000000%\n",
      "At minibatch 41500, batch loss 0.494435, batch error rate 15.000000%\n",
      "After epoch 83: valid_err_rate: 0.086100% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 41600, batch loss 0.494882, batch error rate 17.000000%\n",
      "At minibatch 41700, batch loss 0.502123, batch error rate 14.000000%\n",
      "At minibatch 41800, batch loss 0.486207, batch error rate 15.000000%\n",
      "At minibatch 41900, batch loss 0.436970, batch error rate 11.000000%\n",
      "At minibatch 42000, batch loss 0.367098, batch error rate 8.000000%\n",
      "After epoch 84: valid_err_rate: 0.088700% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 42100, batch loss 0.536487, batch error rate 12.000000%\n",
      "At minibatch 42200, batch loss 0.260938, batch error rate 3.000000%\n",
      "At minibatch 42300, batch loss 0.516863, batch error rate 10.000000%\n",
      "At minibatch 42400, batch loss 0.421662, batch error rate 10.000000%\n",
      "At minibatch 42500, batch loss 0.507363, batch error rate 14.000000%\n",
      "After epoch 85: valid_err_rate: 0.087300% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 42600, batch loss 0.414809, batch error rate 7.000000%\n",
      "At minibatch 42700, batch loss 0.379082, batch error rate 12.000000%\n",
      "At minibatch 42800, batch loss 0.595069, batch error rate 18.000000%\n",
      "At minibatch 42900, batch loss 0.485388, batch error rate 13.000000%\n",
      "At minibatch 43000, batch loss 0.437093, batch error rate 12.000000%\n",
      "After epoch 86: valid_err_rate: 0.089400% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 43100, batch loss 0.364051, batch error rate 9.000000%\n",
      "At minibatch 43200, batch loss 0.449351, batch error rate 13.000000%\n",
      "At minibatch 43300, batch loss 0.322560, batch error rate 8.000000%\n",
      "At minibatch 43400, batch loss 0.415155, batch error rate 11.000000%\n",
      "At minibatch 43500, batch loss 0.501846, batch error rate 15.000000%\n",
      "After epoch 87: valid_err_rate: 0.085000% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 43600, batch loss 0.563322, batch error rate 16.000000%\n",
      "At minibatch 43700, batch loss 0.463834, batch error rate 12.000000%\n",
      "At minibatch 43800, batch loss 0.444060, batch error rate 12.000000%\n",
      "At minibatch 43900, batch loss 0.592399, batch error rate 19.000000%\n",
      "At minibatch 44000, batch loss 0.362826, batch error rate 9.000000%\n",
      "After epoch 88: valid_err_rate: 0.088500% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 44100, batch loss 0.361952, batch error rate 6.000000%\n",
      "At minibatch 44200, batch loss 0.489399, batch error rate 11.000000%\n",
      "At minibatch 44300, batch loss 0.436320, batch error rate 9.000000%\n",
      "At minibatch 44400, batch loss 0.485060, batch error rate 14.000000%\n",
      "At minibatch 44500, batch loss 0.456838, batch error rate 13.000000%\n",
      "After epoch 89: valid_err_rate: 0.085400% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 44600, batch loss 0.324660, batch error rate 7.000000%\n",
      "At minibatch 44700, batch loss 0.360857, batch error rate 9.000000%\n",
      "At minibatch 44800, batch loss 0.431005, batch error rate 16.000000%\n",
      "At minibatch 44900, batch loss 0.450920, batch error rate 15.000000%\n",
      "At minibatch 45000, batch loss 0.414226, batch error rate 9.000000%\n",
      "After epoch 90: valid_err_rate: 0.083500% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 45100, batch loss 0.369660, batch error rate 10.000000%\n",
      "At minibatch 45200, batch loss 0.543961, batch error rate 8.000000%\n",
      "At minibatch 45300, batch loss 0.435801, batch error rate 10.000000%\n",
      "At minibatch 45400, batch loss 0.542837, batch error rate 15.000000%\n",
      "At minibatch 45500, batch loss 0.354730, batch error rate 4.000000%\n",
      "After epoch 91: valid_err_rate: 0.089400% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 45600, batch loss 0.351057, batch error rate 6.000000%\n",
      "At minibatch 45700, batch loss 0.491646, batch error rate 10.000000%\n",
      "At minibatch 45800, batch loss 0.485966, batch error rate 14.000000%\n",
      "At minibatch 45900, batch loss 0.302816, batch error rate 9.000000%\n",
      "At minibatch 46000, batch loss 0.508918, batch error rate 14.000000%\n",
      "After epoch 92: valid_err_rate: 0.089200% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 46100, batch loss 0.577632, batch error rate 17.000000%\n",
      "At minibatch 46200, batch loss 0.471060, batch error rate 12.000000%\n",
      "At minibatch 46300, batch loss 0.472376, batch error rate 12.000000%\n",
      "At minibatch 46400, batch loss 0.412294, batch error rate 10.000000%\n",
      "At minibatch 46500, batch loss 0.345684, batch error rate 8.000000%\n",
      "After epoch 93: valid_err_rate: 0.085000% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 46600, batch loss 0.521961, batch error rate 14.000000%\n",
      "At minibatch 46700, batch loss 0.485527, batch error rate 11.000000%\n",
      "At minibatch 46800, batch loss 0.478175, batch error rate 12.000000%\n",
      "At minibatch 46900, batch loss 0.555806, batch error rate 17.000000%\n",
      "At minibatch 47000, batch loss 0.321945, batch error rate 10.000000%\n",
      "After epoch 94: valid_err_rate: 0.086300% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 47100, batch loss 0.420391, batch error rate 12.000000%\n",
      "At minibatch 47200, batch loss 0.513277, batch error rate 13.000000%\n",
      "At minibatch 47300, batch loss 0.541564, batch error rate 18.000000%\n",
      "At minibatch 47400, batch loss 0.568403, batch error rate 13.000000%\n",
      "At minibatch 47500, batch loss 0.479354, batch error rate 19.000000%\n",
      "After epoch 95: valid_err_rate: 0.088900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 47600, batch loss 0.367539, batch error rate 6.000000%\n",
      "At minibatch 47700, batch loss 0.443610, batch error rate 10.000000%\n",
      "At minibatch 47800, batch loss 0.494703, batch error rate 10.000000%\n",
      "At minibatch 47900, batch loss 0.454712, batch error rate 12.000000%\n",
      "At minibatch 48000, batch loss 0.420551, batch error rate 9.000000%\n",
      "After epoch 96: valid_err_rate: 0.085000% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 48100, batch loss 0.476984, batch error rate 10.000000%\n",
      "At minibatch 48200, batch loss 0.413331, batch error rate 13.000000%\n",
      "At minibatch 48300, batch loss 0.479640, batch error rate 12.000000%\n",
      "At minibatch 48400, batch loss 0.330293, batch error rate 10.000000%\n",
      "At minibatch 48500, batch loss 0.462705, batch error rate 13.000000%\n",
      "After epoch 97: valid_err_rate: 0.087000% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 48600, batch loss 0.632307, batch error rate 19.000000%\n",
      "At minibatch 48700, batch loss 0.484921, batch error rate 13.000000%\n",
      "At minibatch 48800, batch loss 0.571516, batch error rate 18.000000%\n",
      "At minibatch 48900, batch loss 0.442649, batch error rate 9.000000%\n",
      "At minibatch 49000, batch loss 0.504183, batch error rate 13.000000%\n",
      "After epoch 98: valid_err_rate: 0.084400% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 49100, batch loss 0.317926, batch error rate 7.000000%\n",
      "At minibatch 49200, batch loss 0.433155, batch error rate 12.000000%\n",
      "At minibatch 49300, batch loss 0.508601, batch error rate 12.000000%\n",
      "At minibatch 49400, batch loss 0.339909, batch error rate 8.000000%\n",
      "At minibatch 49500, batch loss 0.412717, batch error rate 11.000000%\n",
      "After epoch 99: valid_err_rate: 0.088200% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 49600, batch loss 0.278596, batch error rate 9.000000%\n",
      "At minibatch 49700, batch loss 0.487900, batch error rate 12.000000%\n",
      "At minibatch 49800, batch loss 0.420768, batch error rate 15.000000%\n",
      "At minibatch 49900, batch loss 0.452899, batch error rate 10.000000%\n",
      "At minibatch 50000, batch loss 0.350000, batch error rate 8.000000%\n",
      "After epoch 100: valid_err_rate: 0.088300% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 50100, batch loss 0.544046, batch error rate 17.000000%\n",
      "At minibatch 50200, batch loss 0.415099, batch error rate 11.000000%\n",
      "At minibatch 50300, batch loss 0.461381, batch error rate 16.000000%\n",
      "At minibatch 50400, batch loss 0.309675, batch error rate 9.000000%\n",
      "At minibatch 50500, batch loss 0.439318, batch error rate 12.000000%\n",
      "After epoch 101: valid_err_rate: 0.087000% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 50600, batch loss 0.375756, batch error rate 13.000000%\n",
      "At minibatch 50700, batch loss 0.365949, batch error rate 6.000000%\n",
      "At minibatch 50800, batch loss 0.513077, batch error rate 15.000000%\n",
      "At minibatch 50900, batch loss 0.525537, batch error rate 13.000000%\n",
      "At minibatch 51000, batch loss 0.474302, batch error rate 13.000000%\n",
      "After epoch 102: valid_err_rate: 0.086300% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 51100, batch loss 0.386057, batch error rate 13.000000%\n",
      "At minibatch 51200, batch loss 0.417983, batch error rate 10.000000%\n",
      "At minibatch 51300, batch loss 0.436626, batch error rate 15.000000%\n",
      "At minibatch 51400, batch loss 0.380296, batch error rate 8.000000%\n",
      "At minibatch 51500, batch loss 0.412721, batch error rate 9.000000%\n",
      "After epoch 103: valid_err_rate: 0.085100% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 51600, batch loss 0.475852, batch error rate 14.000000%\n",
      "At minibatch 51700, batch loss 0.394848, batch error rate 9.000000%\n",
      "At minibatch 51800, batch loss 0.415315, batch error rate 14.000000%\n",
      "At minibatch 51900, batch loss 0.458222, batch error rate 11.000000%\n",
      "At minibatch 52000, batch loss 0.531519, batch error rate 12.000000%\n",
      "After epoch 104: valid_err_rate: 0.088100% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 52100, batch loss 0.563332, batch error rate 12.000000%\n",
      "At minibatch 52200, batch loss 0.475232, batch error rate 13.000000%\n",
      "At minibatch 52300, batch loss 0.440249, batch error rate 12.000000%\n",
      "At minibatch 52400, batch loss 0.433986, batch error rate 10.000000%\n",
      "At minibatch 52500, batch loss 0.423894, batch error rate 8.000000%\n",
      "After epoch 105: valid_err_rate: 0.085200% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 52600, batch loss 0.351201, batch error rate 7.000000%\n",
      "At minibatch 52700, batch loss 0.408864, batch error rate 9.000000%\n",
      "At minibatch 52800, batch loss 0.515555, batch error rate 19.000000%\n",
      "At minibatch 52900, batch loss 0.470701, batch error rate 10.000000%\n",
      "At minibatch 53000, batch loss 0.397005, batch error rate 10.000000%\n",
      "After epoch 106: valid_err_rate: 0.083300% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 53100, batch loss 0.512666, batch error rate 13.000000%\n",
      "At minibatch 53200, batch loss 0.442310, batch error rate 11.000000%\n",
      "At minibatch 53300, batch loss 0.426700, batch error rate 12.000000%\n",
      "At minibatch 53400, batch loss 0.490276, batch error rate 13.000000%\n",
      "At minibatch 53500, batch loss 0.348629, batch error rate 4.000000%\n",
      "After epoch 107: valid_err_rate: 0.086300% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 53600, batch loss 0.418474, batch error rate 13.000000%\n",
      "At minibatch 53700, batch loss 0.474381, batch error rate 12.000000%\n",
      "At minibatch 53800, batch loss 0.500198, batch error rate 11.000000%\n",
      "At minibatch 53900, batch loss 0.402802, batch error rate 13.000000%\n",
      "At minibatch 54000, batch loss 0.497317, batch error rate 16.000000%\n",
      "After epoch 108: valid_err_rate: 0.087900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 54100, batch loss 0.395565, batch error rate 10.000000%\n",
      "At minibatch 54200, batch loss 0.494651, batch error rate 14.000000%\n",
      "At minibatch 54300, batch loss 0.319328, batch error rate 7.000000%\n",
      "At minibatch 54400, batch loss 0.269913, batch error rate 5.000000%\n",
      "At minibatch 54500, batch loss 0.427008, batch error rate 11.000000%\n",
      "After epoch 109: valid_err_rate: 0.082700% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 54600, batch loss 0.591660, batch error rate 16.000000%\n",
      "At minibatch 54700, batch loss 0.341560, batch error rate 10.000000%\n",
      "At minibatch 54800, batch loss 0.388688, batch error rate 10.000000%\n",
      "At minibatch 54900, batch loss 0.421420, batch error rate 14.000000%\n",
      "At minibatch 55000, batch loss 0.379632, batch error rate 10.000000%\n",
      "After epoch 110: valid_err_rate: 0.085100% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 55100, batch loss 0.412019, batch error rate 9.000000%\n",
      "At minibatch 55200, batch loss 0.382130, batch error rate 7.000000%\n",
      "At minibatch 55300, batch loss 0.572031, batch error rate 16.000000%\n",
      "At minibatch 55400, batch loss 0.481949, batch error rate 13.000000%\n",
      "At minibatch 55500, batch loss 0.463874, batch error rate 10.000000%\n",
      "After epoch 111: valid_err_rate: 0.086100% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 55600, batch loss 0.420854, batch error rate 15.000000%\n",
      "At minibatch 55700, batch loss 0.430350, batch error rate 11.000000%\n",
      "At minibatch 55800, batch loss 0.463057, batch error rate 7.000000%\n",
      "At minibatch 55900, batch loss 0.487668, batch error rate 13.000000%\n",
      "At minibatch 56000, batch loss 0.520935, batch error rate 13.000000%\n",
      "After epoch 112: valid_err_rate: 0.087200% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 56100, batch loss 0.389696, batch error rate 8.000000%\n",
      "At minibatch 56200, batch loss 0.434093, batch error rate 12.000000%\n",
      "At minibatch 56300, batch loss 0.443798, batch error rate 10.000000%\n",
      "At minibatch 56400, batch loss 0.436521, batch error rate 10.000000%\n",
      "At minibatch 56500, batch loss 0.482864, batch error rate 11.000000%\n",
      "After epoch 113: valid_err_rate: 0.087300% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 56600, batch loss 0.445484, batch error rate 10.000000%\n",
      "At minibatch 56700, batch loss 0.452739, batch error rate 10.000000%\n",
      "At minibatch 56800, batch loss 0.349615, batch error rate 4.000000%\n",
      "At minibatch 56900, batch loss 0.446704, batch error rate 12.000000%\n",
      "At minibatch 57000, batch loss 0.389508, batch error rate 9.000000%\n",
      "After epoch 114: valid_err_rate: 0.087600% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 57100, batch loss 0.356657, batch error rate 12.000000%\n",
      "At minibatch 57200, batch loss 0.479990, batch error rate 16.000000%\n",
      "At minibatch 57300, batch loss 0.487256, batch error rate 14.000000%\n",
      "At minibatch 57400, batch loss 0.438944, batch error rate 15.000000%\n",
      "At minibatch 57500, batch loss 0.558084, batch error rate 15.000000%\n",
      "After epoch 115: valid_err_rate: 0.085600% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 57600, batch loss 0.620192, batch error rate 19.000000%\n",
      "At minibatch 57700, batch loss 0.385707, batch error rate 11.000000%\n",
      "At minibatch 57800, batch loss 0.424817, batch error rate 14.000000%\n",
      "At minibatch 57900, batch loss 0.480794, batch error rate 18.000000%\n",
      "At minibatch 58000, batch loss 0.413302, batch error rate 9.000000%\n",
      "After epoch 116: valid_err_rate: 0.083900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 58100, batch loss 0.454798, batch error rate 11.000000%\n",
      "At minibatch 58200, batch loss 0.420794, batch error rate 8.000000%\n",
      "At minibatch 58300, batch loss 0.426417, batch error rate 10.000000%\n",
      "At minibatch 58400, batch loss 0.404203, batch error rate 9.000000%\n",
      "At minibatch 58500, batch loss 0.391385, batch error rate 9.000000%\n",
      "After epoch 117: valid_err_rate: 0.085900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 58600, batch loss 0.469869, batch error rate 13.000000%\n",
      "At minibatch 58700, batch loss 0.491135, batch error rate 13.000000%\n",
      "At minibatch 58800, batch loss 0.319530, batch error rate 7.000000%\n",
      "At minibatch 58900, batch loss 0.573214, batch error rate 12.000000%\n",
      "At minibatch 59000, batch loss 0.390934, batch error rate 9.000000%\n",
      "After epoch 118: valid_err_rate: 0.089000% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 59100, batch loss 0.416510, batch error rate 8.000000%\n",
      "At minibatch 59200, batch loss 0.415583, batch error rate 12.000000%\n",
      "At minibatch 59300, batch loss 0.370531, batch error rate 11.000000%\n",
      "At minibatch 59400, batch loss 0.387161, batch error rate 14.000000%\n",
      "At minibatch 59500, batch loss 0.491868, batch error rate 14.000000%\n",
      "After epoch 119: valid_err_rate: 0.086900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 59600, batch loss 0.519896, batch error rate 16.000000%\n",
      "At minibatch 59700, batch loss 0.632871, batch error rate 23.000000%\n",
      "At minibatch 59800, batch loss 0.605200, batch error rate 19.000000%\n",
      "At minibatch 59900, batch loss 0.479897, batch error rate 15.000000%\n",
      "At minibatch 60000, batch loss 0.524223, batch error rate 10.000000%\n",
      "After epoch 120: valid_err_rate: 0.087900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 60100, batch loss 0.482446, batch error rate 15.000000%\n",
      "At minibatch 60200, batch loss 0.581110, batch error rate 17.000000%\n",
      "At minibatch 60300, batch loss 0.430746, batch error rate 11.000000%\n",
      "At minibatch 60400, batch loss 0.395344, batch error rate 11.000000%\n",
      "At minibatch 60500, batch loss 0.427409, batch error rate 12.000000%\n",
      "After epoch 121: valid_err_rate: 0.086600% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 60600, batch loss 0.423192, batch error rate 13.000000%\n",
      "At minibatch 60700, batch loss 0.281937, batch error rate 6.000000%\n",
      "At minibatch 60800, batch loss 0.534058, batch error rate 14.000000%\n",
      "At minibatch 60900, batch loss 0.516039, batch error rate 17.000000%\n",
      "At minibatch 61000, batch loss 0.478940, batch error rate 13.000000%\n",
      "After epoch 122: valid_err_rate: 0.085400% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 61100, batch loss 0.467862, batch error rate 14.000000%\n",
      "At minibatch 61200, batch loss 0.486975, batch error rate 9.000000%\n",
      "At minibatch 61300, batch loss 0.268277, batch error rate 8.000000%\n",
      "At minibatch 61400, batch loss 0.412170, batch error rate 10.000000%\n",
      "At minibatch 61500, batch loss 0.378629, batch error rate 13.000000%\n",
      "After epoch 123: valid_err_rate: 0.089000% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 61600, batch loss 0.428568, batch error rate 10.000000%\n",
      "At minibatch 61700, batch loss 0.415812, batch error rate 16.000000%\n",
      "At minibatch 61800, batch loss 0.411455, batch error rate 9.000000%\n",
      "At minibatch 61900, batch loss 0.372935, batch error rate 11.000000%\n",
      "At minibatch 62000, batch loss 0.412654, batch error rate 7.000000%\n",
      "After epoch 124: valid_err_rate: 0.090100% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 62100, batch loss 0.259536, batch error rate 4.000000%\n",
      "At minibatch 62200, batch loss 0.445526, batch error rate 9.000000%\n",
      "At minibatch 62300, batch loss 0.424748, batch error rate 9.000000%\n",
      "At minibatch 62400, batch loss 0.468660, batch error rate 11.000000%\n",
      "At minibatch 62500, batch loss 0.465579, batch error rate 15.000000%\n",
      "After epoch 125: valid_err_rate: 0.083700% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 62600, batch loss 0.356127, batch error rate 9.000000%\n",
      "At minibatch 62700, batch loss 0.372542, batch error rate 9.000000%\n",
      "At minibatch 62800, batch loss 0.493921, batch error rate 18.000000%\n",
      "At minibatch 62900, batch loss 0.385815, batch error rate 10.000000%\n",
      "At minibatch 63000, batch loss 0.325534, batch error rate 8.000000%\n",
      "After epoch 126: valid_err_rate: 0.086400% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 63100, batch loss 0.299040, batch error rate 9.000000%\n",
      "At minibatch 63200, batch loss 0.452894, batch error rate 11.000000%\n",
      "At minibatch 63300, batch loss 0.365017, batch error rate 11.000000%\n",
      "At minibatch 63400, batch loss 0.528559, batch error rate 11.000000%\n",
      "At minibatch 63500, batch loss 0.548536, batch error rate 14.000000%\n",
      "After epoch 127: valid_err_rate: 0.087600% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 63600, batch loss 0.552547, batch error rate 14.000000%\n",
      "At minibatch 63700, batch loss 0.481298, batch error rate 11.000000%\n",
      "At minibatch 63800, batch loss 0.471816, batch error rate 12.000000%\n",
      "At minibatch 63900, batch loss 0.408195, batch error rate 9.000000%\n",
      "At minibatch 64000, batch loss 0.393320, batch error rate 12.000000%\n",
      "After epoch 128: valid_err_rate: 0.082800% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 64100, batch loss 0.435094, batch error rate 10.000000%\n",
      "At minibatch 64200, batch loss 0.618089, batch error rate 18.000000%\n",
      "At minibatch 64300, batch loss 0.478736, batch error rate 13.000000%\n",
      "At minibatch 64400, batch loss 0.519365, batch error rate 16.000000%\n",
      "At minibatch 64500, batch loss 0.399016, batch error rate 8.000000%\n",
      "After epoch 129: valid_err_rate: 0.085400% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 64600, batch loss 0.381783, batch error rate 9.000000%\n",
      "At minibatch 64700, batch loss 0.411048, batch error rate 9.000000%\n",
      "At minibatch 64800, batch loss 0.453164, batch error rate 13.000000%\n",
      "At minibatch 64900, batch loss 0.403219, batch error rate 9.000000%\n",
      "At minibatch 65000, batch loss 0.480832, batch error rate 16.000000%\n",
      "After epoch 130: valid_err_rate: 0.085200% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 65100, batch loss 0.393425, batch error rate 10.000000%\n",
      "At minibatch 65200, batch loss 0.493405, batch error rate 15.000000%\n",
      "At minibatch 65300, batch loss 0.434901, batch error rate 12.000000%\n",
      "At minibatch 65400, batch loss 0.475396, batch error rate 11.000000%\n",
      "At minibatch 65500, batch loss 0.461698, batch error rate 13.000000%\n",
      "After epoch 131: valid_err_rate: 0.083200% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 65600, batch loss 0.361687, batch error rate 9.000000%\n",
      "At minibatch 65700, batch loss 0.387541, batch error rate 9.000000%\n",
      "At minibatch 65800, batch loss 0.369898, batch error rate 11.000000%\n",
      "At minibatch 65900, batch loss 0.517142, batch error rate 12.000000%\n",
      "At minibatch 66000, batch loss 0.532140, batch error rate 15.000000%\n",
      "After epoch 132: valid_err_rate: 0.088100% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 66100, batch loss 0.672042, batch error rate 18.000000%\n",
      "At minibatch 66200, batch loss 0.482871, batch error rate 14.000000%\n",
      "At minibatch 66300, batch loss 0.360955, batch error rate 10.000000%\n",
      "At minibatch 66400, batch loss 0.272212, batch error rate 8.000000%\n",
      "At minibatch 66500, batch loss 0.455100, batch error rate 13.000000%\n",
      "After epoch 133: valid_err_rate: 0.087900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 66600, batch loss 0.402927, batch error rate 10.000000%\n",
      "At minibatch 66700, batch loss 0.313487, batch error rate 9.000000%\n",
      "At minibatch 66800, batch loss 0.348779, batch error rate 8.000000%\n",
      "At minibatch 66900, batch loss 0.426678, batch error rate 11.000000%\n",
      "At minibatch 67000, batch loss 0.371441, batch error rate 9.000000%\n",
      "After epoch 134: valid_err_rate: 0.085900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 67100, batch loss 0.676294, batch error rate 17.000000%\n",
      "At minibatch 67200, batch loss 0.422182, batch error rate 6.000000%\n",
      "At minibatch 67300, batch loss 0.484695, batch error rate 9.000000%\n",
      "At minibatch 67400, batch loss 0.381370, batch error rate 10.000000%\n",
      "At minibatch 67500, batch loss 0.373253, batch error rate 9.000000%\n",
      "After epoch 135: valid_err_rate: 0.085600% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 67600, batch loss 0.419530, batch error rate 9.000000%\n",
      "At minibatch 67700, batch loss 0.523120, batch error rate 15.000000%\n",
      "At minibatch 67800, batch loss 0.512379, batch error rate 18.000000%\n",
      "At minibatch 67900, batch loss 0.507792, batch error rate 15.000000%\n",
      "At minibatch 68000, batch loss 0.464873, batch error rate 12.000000%\n",
      "After epoch 136: valid_err_rate: 0.085100% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 68100, batch loss 0.455023, batch error rate 11.000000%\n",
      "At minibatch 68200, batch loss 0.543344, batch error rate 15.000000%\n",
      "At minibatch 68300, batch loss 0.409373, batch error rate 11.000000%\n",
      "At minibatch 68400, batch loss 0.427251, batch error rate 11.000000%\n",
      "At minibatch 68500, batch loss 0.516851, batch error rate 16.000000%\n",
      "After epoch 137: valid_err_rate: 0.088200% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 68600, batch loss 0.586737, batch error rate 19.000000%\n",
      "At minibatch 68700, batch loss 0.476645, batch error rate 12.000000%\n",
      "At minibatch 68800, batch loss 0.372126, batch error rate 8.000000%\n",
      "At minibatch 68900, batch loss 0.414464, batch error rate 12.000000%\n",
      "At minibatch 69000, batch loss 0.453997, batch error rate 11.000000%\n",
      "After epoch 138: valid_err_rate: 0.084600% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 69100, batch loss 0.439753, batch error rate 16.000000%\n",
      "At minibatch 69200, batch loss 0.471323, batch error rate 11.000000%\n",
      "At minibatch 69300, batch loss 0.406515, batch error rate 11.000000%\n",
      "At minibatch 69400, batch loss 0.512725, batch error rate 11.000000%\n",
      "At minibatch 69500, batch loss 0.516354, batch error rate 13.000000%\n",
      "After epoch 139: valid_err_rate: 0.090000% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 69600, batch loss 0.448735, batch error rate 9.000000%\n",
      "At minibatch 69700, batch loss 0.407992, batch error rate 9.000000%\n",
      "At minibatch 69800, batch loss 0.416675, batch error rate 12.000000%\n",
      "At minibatch 69900, batch loss 0.454991, batch error rate 14.000000%\n",
      "At minibatch 70000, batch loss 0.359967, batch error rate 9.000000%\n",
      "After epoch 140: valid_err_rate: 0.086900% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 70100, batch loss 0.376759, batch error rate 10.000000%\n",
      "At minibatch 70200, batch loss 0.562260, batch error rate 14.000000%\n",
      "At minibatch 70300, batch loss 0.463788, batch error rate 11.000000%\n",
      "At minibatch 70400, batch loss 0.418928, batch error rate 10.000000%\n",
      "At minibatch 70500, batch loss 0.483005, batch error rate 12.000000%\n",
      "After epoch 141: valid_err_rate: 0.084500% currently going ot do 2000 epochs [best: 0.082000%]\n",
      "At minibatch 70600, batch loss 0.456334, batch error rate 9.000000%\n",
      "At minibatch 70700, batch loss 0.444619, batch error rate 12.000000%\n",
      "At minibatch 70800, batch loss 0.343151, batch error rate 11.000000%\n",
      "At minibatch 70900, batch loss 0.546853, batch error rate 18.000000%\n",
      "At minibatch 71000, batch loss 0.469886, batch error rate 15.000000%\n",
      "After epoch 142: valid_err_rate: 0.081900% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 71100, batch loss 0.442174, batch error rate 7.000000%\n",
      "At minibatch 71200, batch loss 0.355343, batch error rate 11.000000%\n",
      "At minibatch 71300, batch loss 0.330419, batch error rate 11.000000%\n",
      "At minibatch 71400, batch loss 0.487585, batch error rate 15.000000%\n",
      "At minibatch 71500, batch loss 0.494314, batch error rate 14.000000%\n",
      "After epoch 143: valid_err_rate: 0.085000% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 71600, batch loss 0.362511, batch error rate 9.000000%\n",
      "At minibatch 71700, batch loss 0.284716, batch error rate 5.000000%\n",
      "At minibatch 71800, batch loss 0.381943, batch error rate 10.000000%\n",
      "At minibatch 71900, batch loss 0.506691, batch error rate 16.000000%\n",
      "At minibatch 72000, batch loss 0.478452, batch error rate 13.000000%\n",
      "After epoch 144: valid_err_rate: 0.084500% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 72100, batch loss 0.367370, batch error rate 8.000000%\n",
      "At minibatch 72200, batch loss 0.356037, batch error rate 9.000000%\n",
      "At minibatch 72300, batch loss 0.468428, batch error rate 13.000000%\n",
      "At minibatch 72400, batch loss 0.504495, batch error rate 12.000000%\n",
      "At minibatch 72500, batch loss 0.492557, batch error rate 14.000000%\n",
      "After epoch 145: valid_err_rate: 0.083500% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 72600, batch loss 0.640903, batch error rate 18.000000%\n",
      "At minibatch 72700, batch loss 0.443670, batch error rate 11.000000%\n",
      "At minibatch 72800, batch loss 0.403064, batch error rate 11.000000%\n",
      "At minibatch 72900, batch loss 0.344995, batch error rate 7.000000%\n",
      "At minibatch 73000, batch loss 0.550606, batch error rate 12.000000%\n",
      "After epoch 146: valid_err_rate: 0.085400% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 73100, batch loss 0.374596, batch error rate 8.000000%\n",
      "At minibatch 73200, batch loss 0.418323, batch error rate 11.000000%\n",
      "At minibatch 73300, batch loss 0.358862, batch error rate 10.000000%\n",
      "At minibatch 73400, batch loss 0.338523, batch error rate 9.000000%\n",
      "At minibatch 73500, batch loss 0.462096, batch error rate 13.000000%\n",
      "After epoch 147: valid_err_rate: 0.083800% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 73600, batch loss 0.420486, batch error rate 13.000000%\n",
      "At minibatch 73700, batch loss 0.421413, batch error rate 9.000000%\n",
      "At minibatch 73800, batch loss 0.547428, batch error rate 11.000000%\n",
      "At minibatch 73900, batch loss 0.466624, batch error rate 9.000000%\n",
      "At minibatch 74000, batch loss 0.458184, batch error rate 11.000000%\n",
      "After epoch 148: valid_err_rate: 0.089600% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 74100, batch loss 0.449300, batch error rate 11.000000%\n",
      "At minibatch 74200, batch loss 0.323738, batch error rate 8.000000%\n",
      "At minibatch 74300, batch loss 0.390069, batch error rate 8.000000%\n",
      "At minibatch 74400, batch loss 0.419716, batch error rate 9.000000%\n",
      "At minibatch 74500, batch loss 0.418509, batch error rate 12.000000%\n",
      "After epoch 149: valid_err_rate: 0.086000% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 74600, batch loss 0.399122, batch error rate 11.000000%\n",
      "At minibatch 74700, batch loss 0.402165, batch error rate 9.000000%\n",
      "At minibatch 74800, batch loss 0.463122, batch error rate 12.000000%\n",
      "At minibatch 74900, batch loss 0.448138, batch error rate 10.000000%\n",
      "At minibatch 75000, batch loss 0.488201, batch error rate 16.000000%\n",
      "After epoch 150: valid_err_rate: 0.086000% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 75100, batch loss 0.476215, batch error rate 15.000000%\n",
      "At minibatch 75200, batch loss 0.383023, batch error rate 9.000000%\n",
      "At minibatch 75300, batch loss 0.452369, batch error rate 7.000000%\n",
      "At minibatch 75400, batch loss 0.400952, batch error rate 8.000000%\n",
      "At minibatch 75500, batch loss 0.502296, batch error rate 14.000000%\n",
      "After epoch 151: valid_err_rate: 0.086900% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 75600, batch loss 0.352655, batch error rate 12.000000%\n",
      "At minibatch 75700, batch loss 0.273706, batch error rate 5.000000%\n",
      "At minibatch 75800, batch loss 0.369683, batch error rate 12.000000%\n",
      "At minibatch 75900, batch loss 0.385187, batch error rate 10.000000%\n",
      "At minibatch 76000, batch loss 0.299160, batch error rate 3.000000%\n",
      "After epoch 152: valid_err_rate: 0.084600% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 76100, batch loss 0.440272, batch error rate 8.000000%\n",
      "At minibatch 76200, batch loss 0.402158, batch error rate 8.000000%\n",
      "At minibatch 76300, batch loss 0.558600, batch error rate 15.000000%\n",
      "At minibatch 76400, batch loss 0.406932, batch error rate 10.000000%\n",
      "At minibatch 76500, batch loss 0.373432, batch error rate 7.000000%\n",
      "After epoch 153: valid_err_rate: 0.084000% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 76600, batch loss 0.367785, batch error rate 10.000000%\n",
      "At minibatch 76700, batch loss 0.346075, batch error rate 8.000000%\n",
      "At minibatch 76800, batch loss 0.579713, batch error rate 14.000000%\n",
      "At minibatch 76900, batch loss 0.318129, batch error rate 7.000000%\n",
      "At minibatch 77000, batch loss 0.470290, batch error rate 11.000000%\n",
      "After epoch 154: valid_err_rate: 0.088400% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 77100, batch loss 0.456928, batch error rate 10.000000%\n",
      "At minibatch 77200, batch loss 0.420960, batch error rate 8.000000%\n",
      "At minibatch 77300, batch loss 0.459342, batch error rate 10.000000%\n",
      "At minibatch 77400, batch loss 0.307980, batch error rate 8.000000%\n",
      "At minibatch 77500, batch loss 0.474885, batch error rate 13.000000%\n",
      "After epoch 155: valid_err_rate: 0.087700% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 77600, batch loss 0.448261, batch error rate 15.000000%\n",
      "At minibatch 77700, batch loss 0.371571, batch error rate 10.000000%\n",
      "At minibatch 77800, batch loss 0.437760, batch error rate 12.000000%\n",
      "At minibatch 77900, batch loss 0.405290, batch error rate 7.000000%\n",
      "At minibatch 78000, batch loss 0.357505, batch error rate 8.000000%\n",
      "After epoch 156: valid_err_rate: 0.082100% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 78100, batch loss 0.318222, batch error rate 9.000000%\n",
      "At minibatch 78200, batch loss 0.350202, batch error rate 10.000000%\n",
      "At minibatch 78300, batch loss 0.452728, batch error rate 16.000000%\n",
      "At minibatch 78400, batch loss 0.407377, batch error rate 10.000000%\n",
      "At minibatch 78500, batch loss 0.429050, batch error rate 12.000000%\n",
      "After epoch 157: valid_err_rate: 0.087800% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 78600, batch loss 0.316643, batch error rate 5.000000%\n",
      "At minibatch 78700, batch loss 0.467351, batch error rate 13.000000%\n",
      "At minibatch 78800, batch loss 0.496296, batch error rate 12.000000%\n",
      "At minibatch 78900, batch loss 0.335482, batch error rate 6.000000%\n",
      "At minibatch 79000, batch loss 0.506081, batch error rate 15.000000%\n",
      "After epoch 158: valid_err_rate: 0.083800% currently going ot do 2000 epochs [best: 0.081900%]\n",
      "At minibatch 79100, batch loss 0.470415, batch error rate 13.000000%\n",
      "At minibatch 79200, batch loss 0.484539, batch error rate 15.000000%\n",
      "At minibatch 79300, batch loss 0.308157, batch error rate 6.000000%\n",
      "At minibatch 79400, batch loss 0.419198, batch error rate 10.000000%\n",
      "At minibatch 79500, batch loss 0.437685, batch error rate 14.000000%\n",
      "After epoch 159: valid_err_rate: 0.081300% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 79600, batch loss 0.372599, batch error rate 9.000000%\n",
      "At minibatch 79700, batch loss 0.588497, batch error rate 17.000000%\n",
      "At minibatch 79800, batch loss 0.465788, batch error rate 15.000000%\n",
      "At minibatch 79900, batch loss 0.513244, batch error rate 14.000000%\n",
      "At minibatch 80000, batch loss 0.569158, batch error rate 13.000000%\n",
      "After epoch 160: valid_err_rate: 0.083200% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 80100, batch loss 0.422466, batch error rate 9.000000%\n",
      "At minibatch 80200, batch loss 0.469938, batch error rate 9.000000%\n",
      "At minibatch 80300, batch loss 0.488180, batch error rate 13.000000%\n",
      "At minibatch 80400, batch loss 0.406117, batch error rate 12.000000%\n",
      "At minibatch 80500, batch loss 0.409769, batch error rate 9.000000%\n",
      "After epoch 161: valid_err_rate: 0.084900% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 80600, batch loss 0.373681, batch error rate 8.000000%\n",
      "At minibatch 80700, batch loss 0.401617, batch error rate 9.000000%\n",
      "At minibatch 80800, batch loss 0.331792, batch error rate 6.000000%\n",
      "At minibatch 80900, batch loss 0.511696, batch error rate 16.000000%\n",
      "At minibatch 81000, batch loss 0.454162, batch error rate 10.000000%\n",
      "After epoch 162: valid_err_rate: 0.084900% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 81100, batch loss 0.488841, batch error rate 17.000000%\n",
      "At minibatch 81200, batch loss 0.312290, batch error rate 9.000000%\n",
      "At minibatch 81300, batch loss 0.401957, batch error rate 12.000000%\n",
      "At minibatch 81400, batch loss 0.328077, batch error rate 7.000000%\n",
      "At minibatch 81500, batch loss 0.331498, batch error rate 10.000000%\n",
      "After epoch 163: valid_err_rate: 0.086700% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 81600, batch loss 0.316716, batch error rate 9.000000%\n",
      "At minibatch 81700, batch loss 0.501776, batch error rate 16.000000%\n",
      "At minibatch 81800, batch loss 0.455710, batch error rate 14.000000%\n",
      "At minibatch 81900, batch loss 0.289176, batch error rate 8.000000%\n",
      "At minibatch 82000, batch loss 0.480057, batch error rate 14.000000%\n",
      "After epoch 164: valid_err_rate: 0.083700% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 82100, batch loss 0.541548, batch error rate 16.000000%\n",
      "At minibatch 82200, batch loss 0.487619, batch error rate 13.000000%\n",
      "At minibatch 82300, batch loss 0.426015, batch error rate 8.000000%\n",
      "At minibatch 82400, batch loss 0.360161, batch error rate 8.000000%\n",
      "At minibatch 82500, batch loss 0.441085, batch error rate 14.000000%\n",
      "After epoch 165: valid_err_rate: 0.082600% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 82600, batch loss 0.345006, batch error rate 11.000000%\n",
      "At minibatch 82700, batch loss 0.328794, batch error rate 8.000000%\n",
      "At minibatch 82800, batch loss 0.487980, batch error rate 13.000000%\n",
      "At minibatch 82900, batch loss 0.452445, batch error rate 12.000000%\n",
      "At minibatch 83000, batch loss 0.374934, batch error rate 12.000000%\n",
      "After epoch 166: valid_err_rate: 0.087700% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 83100, batch loss 0.584390, batch error rate 14.000000%\n",
      "At minibatch 83200, batch loss 0.469422, batch error rate 16.000000%\n",
      "At minibatch 83300, batch loss 0.424971, batch error rate 12.000000%\n",
      "At minibatch 83400, batch loss 0.500565, batch error rate 16.000000%\n",
      "At minibatch 83500, batch loss 0.343814, batch error rate 9.000000%\n",
      "After epoch 167: valid_err_rate: 0.083600% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 83600, batch loss 0.486841, batch error rate 14.000000%\n",
      "At minibatch 83700, batch loss 0.442643, batch error rate 16.000000%\n",
      "At minibatch 83800, batch loss 0.537616, batch error rate 17.000000%\n",
      "At minibatch 83900, batch loss 0.388064, batch error rate 11.000000%\n",
      "At minibatch 84000, batch loss 0.425529, batch error rate 13.000000%\n",
      "After epoch 168: valid_err_rate: 0.084300% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 84100, batch loss 0.449859, batch error rate 13.000000%\n",
      "At minibatch 84200, batch loss 0.390151, batch error rate 10.000000%\n",
      "At minibatch 84300, batch loss 0.503629, batch error rate 11.000000%\n",
      "At minibatch 84400, batch loss 0.369489, batch error rate 5.000000%\n",
      "At minibatch 84500, batch loss 0.358097, batch error rate 6.000000%\n",
      "After epoch 169: valid_err_rate: 0.085800% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 84600, batch loss 0.404303, batch error rate 16.000000%\n",
      "At minibatch 84700, batch loss 0.460944, batch error rate 15.000000%\n",
      "At minibatch 84800, batch loss 0.425193, batch error rate 11.000000%\n",
      "At minibatch 84900, batch loss 0.458002, batch error rate 9.000000%\n",
      "At minibatch 85000, batch loss 0.341940, batch error rate 4.000000%\n",
      "After epoch 170: valid_err_rate: 0.086500% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 85100, batch loss 0.444363, batch error rate 13.000000%\n",
      "At minibatch 85200, batch loss 0.425045, batch error rate 10.000000%\n",
      "At minibatch 85300, batch loss 0.316962, batch error rate 6.000000%\n",
      "At minibatch 85400, batch loss 0.432525, batch error rate 12.000000%\n",
      "At minibatch 85500, batch loss 0.434796, batch error rate 11.000000%\n",
      "After epoch 171: valid_err_rate: 0.087300% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 85600, batch loss 0.431049, batch error rate 10.000000%\n",
      "At minibatch 85700, batch loss 0.636151, batch error rate 21.000000%\n",
      "At minibatch 85800, batch loss 0.469199, batch error rate 13.000000%\n",
      "At minibatch 85900, batch loss 0.424737, batch error rate 7.000000%\n",
      "At minibatch 86000, batch loss 0.368513, batch error rate 8.000000%\n",
      "After epoch 172: valid_err_rate: 0.085600% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 86100, batch loss 0.566867, batch error rate 18.000000%\n",
      "At minibatch 86200, batch loss 0.469844, batch error rate 14.000000%\n",
      "At minibatch 86300, batch loss 0.380720, batch error rate 11.000000%\n",
      "At minibatch 86400, batch loss 0.341273, batch error rate 7.000000%\n",
      "At minibatch 86500, batch loss 0.478179, batch error rate 14.000000%\n",
      "After epoch 173: valid_err_rate: 0.085600% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 86600, batch loss 0.483076, batch error rate 13.000000%\n",
      "At minibatch 86700, batch loss 0.377161, batch error rate 9.000000%\n",
      "At minibatch 86800, batch loss 0.531580, batch error rate 15.000000%\n",
      "At minibatch 86900, batch loss 0.366797, batch error rate 13.000000%\n",
      "At minibatch 87000, batch loss 0.534248, batch error rate 17.000000%\n",
      "After epoch 174: valid_err_rate: 0.085500% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 87100, batch loss 0.397276, batch error rate 9.000000%\n",
      "At minibatch 87200, batch loss 0.368784, batch error rate 6.000000%\n",
      "At minibatch 87300, batch loss 0.405626, batch error rate 7.000000%\n",
      "At minibatch 87400, batch loss 0.457572, batch error rate 7.000000%\n",
      "At minibatch 87500, batch loss 0.356215, batch error rate 6.000000%\n",
      "After epoch 175: valid_err_rate: 0.083300% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 87600, batch loss 0.385351, batch error rate 9.000000%\n",
      "At minibatch 87700, batch loss 0.480721, batch error rate 13.000000%\n",
      "At minibatch 87800, batch loss 0.384291, batch error rate 9.000000%\n",
      "At minibatch 87900, batch loss 0.279782, batch error rate 4.000000%\n",
      "At minibatch 88000, batch loss 0.306117, batch error rate 7.000000%\n",
      "After epoch 176: valid_err_rate: 0.088100% currently going ot do 2000 epochs [best: 0.081300%]\n",
      "At minibatch 88100, batch loss 0.406282, batch error rate 12.000000%\n",
      "Setting network parameters from after epoch 159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0887"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27b6d478d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_init = IsotropicGaussian(std=0.05, mean=0.0)\n",
    "net = FeedForwardNet([\n",
    "        InputDropoutLayer(dropout = 0.8),\n",
    "        AffineLayer(784, 800, weight_init = weight_init),\n",
    "        ReLULayer(dropout = 0.5),\n",
    "        AffineLayer(800, 800, weight_init = weight_init, dropout = 0.5),\n",
    "        ReLULayer(dropout = 0.5),\n",
    "        AffineLayer(800, 10, weight_init = weight_init, dropout = 0.5),\n",
    "        SoftMaxLayer()\n",
    "    ])\n",
    "SGD(net, mnist_train_stream, mnist_validation_stream, mnist_test_stream,\n",
    "    print_debug = True,\n",
    "    epochs = 2000,\n",
    "    regularization_rate = 10e-3,\n",
    "    norm_limiting = 1.3,\n",
    "    alpha_alg = AlphaAlgExp(initial = 5e-2, rate = 0.992),\n",
    "    momentum_alg = MomentumAlg2())\n",
    "\n",
    "net3 = net\n",
    "\n",
    "compute_error_rate(net, mnist_test_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.AffineLayer object at 0x7f27baeedad0>\n",
      "shapes\n",
      "(800,)\n",
      "(800, 784)\n",
      "(800,)\n",
      "(0, 784)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "# print np.sqrt(15)\n",
    "# # for p in net.parameters:\n",
    "#     #print np.sum(np.sum(p, axis=1) > 3.9)\n",
    "# #     print np.sum(np.linalg.norm(p, axis=1) > 3.9)\n",
    "# #     print np.linalg.norm(p, axis=1).shape\n",
    "\n",
    "# for l in net.layers:\n",
    "#     if l.parameter_names and l.parameter_names[0] == 'W':\n",
    "#         W, b = l.parameters\n",
    "#         r = np.sqrt(np.sum(np.square(W), axis = 1) + np.square(b).ravel())\n",
    "#         print W.shape\n",
    "#         #print (r[r > 1.6]).shape\n",
    "#         #print (np.sum(np.square(W), axis = 1) + np.square(b).ravel()).shape\n",
    "#         W[r > 1.6] /= r[r > 1.6].reshape(-1, 1)\n",
    "#         #print r[r > 1.7]\n",
    "        \n",
    "\n",
    "l = net.layers[1]\n",
    "print l\n",
    "N = l.parameter_names[0]\n",
    "norm_limiting = 1.3\n",
    "P = l.parameters[0]\n",
    "\n",
    "        \n",
    "if N=='W' and norm_limiting:\n",
    "                nrm = np.linalg.norm(P, axis = 1) #.reshape(P.shape[0], 1)\n",
    "                print \"shapes\"\n",
    "                print nrm.shape\n",
    "                print P.shape\n",
    "                print (nrm > norm_limiting).shape\n",
    "                print P[nrm > norm_limiting].shape\n",
    "                print nrm[nrm > norm_limiting].shape\n",
    "                P[nrm > norm_limiting] = P[nrm > norm_limiting] / nrm[nrm > norm_limiting].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5 [3p bonus]\n",
    "\n",
    "Implement convolutional and max-pooling layers and (without dropout) get a test error rate below 1.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6 [1-3p bonus]\n",
    "\n",
    "Implement a data augmentation method (e.g. rotations, noise, crops) that will yield a significant test error rate reduction for your network. Number of bonus points depends on the ingenuity of your solution and error rate gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
