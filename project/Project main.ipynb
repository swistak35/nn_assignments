{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "num_hidden1 = 500 # 1st layer\n",
    "num_hidden2 = 500 # 2nd layer\n",
    "\n",
    "log_dir = \"./log\"\n",
    "\n",
    "max_features = 500 # Tfidf features\n",
    "\n",
    "max_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://noaoctavia.dk/workshops/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/1103922562954315/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://telenorarena.no/upcoming_events/adele-2/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://billetter.dk/legeland-i-nordkraft622016\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/1202077356483230/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/StonedOnLoveUK/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.ulbaekgaard.org/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.reallyusefultheatres.co.uk/events/event/mika-palladium\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/1118362758223380/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:219: UserWarning: \".\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://cwrangel4.wix.com/shoppen#!tastings/tsf9d\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.longitude.ie\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/463994730474205/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/173911806353425/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://eventorsdk.wixsite.com/eventors\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/vjklpjh\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:219: UserWarning: \"..\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.tacohime.net/forums/showthread.php?tid=2103\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/653726201453825/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.leapfrogsystems.com/sites/default/files/atletico_madrid_vs_rostov_live_stream.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.picatic.com/event14775470221047\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/200988387014460/?active_tab=about\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.elorn-hb.fr/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.ballieballerson.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/213805979063561/?active_tab=discussion\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.ticketmaster.dk/event/justin-bieber-special-guests-a-day-at-the-racetrack-billetter/420925\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/562772737246625/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.caminitodelrey.info/es/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/1395421670490182/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/1286156014739222/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/events/266526377101319/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://downloadfestival.es\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/channel/UCanksqaxhueR2gSffbgDCZA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.linkedin.com/pulse/watch-liveama-supercross-detroit-2017-live-s-tream-marco-ronaldo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://autobinarysignalssoftwarereviews.com/infinity-code-review/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/swistak35/apps/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://joshkavirtualreality.blogspot.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "from blt_dataset import CATEGORIES, export_events_data\n",
    "\n",
    "events = export_events_data(\"../datasets/events1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How to represent cyclic input?\n",
    "#   For example, how to represent that 31.12 is close to 01.01? Or we should leave it to NN?\n",
    "# Discretize!\n",
    "# span in days from the beginning of each month\n",
    "# span in hours from daily hour, whether event starts in the morning or notwis\n",
    "# add tfidf from title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_desc_texts = [e['description'] for e in events]\n",
    "raw_title_texts = [e['title'] for e in events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# nltk.download() # needs 'punkt' package\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "# Create TF-IDF of texts\n",
    "tfidf_desc = TfidfVectorizer(tokenizer=tokenizer, stop_words=None, max_features=max_features)\n",
    "sparse_tfidf_desc = tfidf_desc.fit_transform(raw_desc_texts)\n",
    "\n",
    "tfidf_title = TfidfVectorizer(tokenizer=tokenizer, stop_words=None, max_features=max_features)\n",
    "sparse_tfidf_title = tfidf_title.fit_transform(raw_title_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193847.0\n",
      "172139.0\n",
      "82787.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "attrs_bool = np.nan_to_num(np.array([e['attrs_bool'] for e in events], dtype = np.float32))\n",
    "attrs_bool.shape\n",
    "print(np.sum(attrs_bool))\n",
    "\n",
    "attrs_scale01 = np.array([e['attrs_scale01'] for e in events], dtype = np.float32)\n",
    "attrs_scale01 /= np.max(attrs_scale01, axis = 0)\n",
    "attrs_scale01.shape\n",
    "print(np.sum(attrs_scale01))\n",
    "\n",
    "attrs_logscale01 = np.ma.log(np.array([e['attrs_logscale01'] for e in events], dtype = np.float32)).filled(0)\n",
    "attrs_logscale01 /= np.max(attrs_logscale01, axis = 0)\n",
    "attrs_logscale01.shape\n",
    "print(np.sum(attrs_logscale01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107838, 1019)\n",
      "(107838,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1091126.0498753795"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.hstack([\n",
    "    sparse_tfidf_desc.todense(),\n",
    "    sparse_tfidf_title.todense(),\n",
    "    attrs_bool,\n",
    "    attrs_scale01,\n",
    "    attrs_logscale01,\n",
    "])\n",
    "print(features.shape)\n",
    "\n",
    "target = np.array([e['category'] for e in events])\n",
    "print(target.shape)\n",
    "\n",
    "np.sum(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples, num_features = features.shape\n",
    "\n",
    "train_indices = np.random.choice(num_samples, int(0.8*num_samples), replace=False)\n",
    "test_indices = np.array(list(set(range(num_samples)) - set(train_indices)))\n",
    "\n",
    "features_train = features[train_indices]\n",
    "features_test = features[test_indices]\n",
    "\n",
    "target_train = np.array([x for ix, x in enumerate(target) if ix in train_indices])\n",
    "target_test = np.array([x for ix, x in enumerate(target) if ix in test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 500. Train Loss (Test Loss): 2.624 (2.623). Train Acc (Test Acc): 16.000 (15.713)\n",
      "Generation # 1000. Train Loss (Test Loss): 2.615 (2.611). Train Acc (Test Acc): 20.500 (19.376)\n",
      "Generation # 1500. Train Loss (Test Loss): 2.599 (2.598). Train Acc (Test Acc): 22.500 (20.090)\n",
      "Generation # 2000. Train Loss (Test Loss): 2.587 (2.586). Train Acc (Test Acc): 21.000 (20.095)\n",
      "Generation # 2500. Train Loss (Test Loss): 2.568 (2.573). Train Acc (Test Acc): 20.000 (20.044)\n",
      "Generation # 3000. Train Loss (Test Loss): 2.553 (2.561). Train Acc (Test Acc): 20.500 (20.113)\n",
      "Generation # 3500. Train Loss (Test Loss): 2.552 (2.549). Train Acc (Test Acc): 22.000 (20.294)\n",
      "Generation # 4000. Train Loss (Test Loss): 2.537 (2.537). Train Acc (Test Acc): 20.000 (20.498)\n",
      "Generation # 4500. Train Loss (Test Loss): 2.534 (2.525). Train Acc (Test Acc): 20.000 (20.373)\n",
      "Generation # 5000. Train Loss (Test Loss): 2.521 (2.513). Train Acc (Test Acc): 19.000 (20.401)\n",
      "Generation # 5500. Train Loss (Test Loss): 2.495 (2.501). Train Acc (Test Acc): 25.500 (20.415)\n",
      "Generation # 6000. Train Loss (Test Loss): 2.505 (2.489). Train Acc (Test Acc): 14.000 (20.479)\n",
      "Generation # 6500. Train Loss (Test Loss): 2.489 (2.477). Train Acc (Test Acc): 17.000 (20.466)\n",
      "Generation # 7000. Train Loss (Test Loss): 2.450 (2.465). Train Acc (Test Acc): 23.000 (20.637)\n",
      "Generation # 7500. Train Loss (Test Loss): 2.445 (2.453). Train Acc (Test Acc): 20.500 (20.739)\n",
      "Generation # 8000. Train Loss (Test Loss): 2.436 (2.441). Train Acc (Test Acc): 22.000 (20.832)\n",
      "Generation # 8500. Train Loss (Test Loss): 2.430 (2.430). Train Acc (Test Acc): 18.000 (20.911)\n",
      "Generation # 9000. Train Loss (Test Loss): 2.420 (2.419). Train Acc (Test Acc): 16.000 (21.022)\n",
      "Generation # 9500. Train Loss (Test Loss): 2.368 (2.408). Train Acc (Test Acc): 25.000 (21.027)\n",
      "Generation # 10000. Train Loss (Test Loss): 2.450 (2.397). Train Acc (Test Acc): 19.000 (21.152)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()   \n",
    "\n",
    "num_classes = len(CATEGORIES)\n",
    "\n",
    "current_log_dir = os.path.join(log_dir, datetime.now().strftime(\"%Y-%m-%d-%H_%M_%S\"))\n",
    "tf.gfile.MakeDirs(current_log_dir)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x_data = tf.placeholder(shape=[None, num_features], dtype=tf.float32)\n",
    "    y_target = tf.placeholder(tf.int32, shape=(None))\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "    \n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights1 = tf.Variable(\n",
    "            tf.truncated_normal([num_features, num_hidden1],\n",
    "                            stddev=1.0 / math.sqrt(float(num_features))),\n",
    "                            name='weights')\n",
    "        biases1 = tf.Variable(tf.zeros([num_hidden1]),\n",
    "                             name='biases')\n",
    "        hidden_relu1 = tf.nn.relu(tf.matmul(x_data, weights1) + biases1)\n",
    "        hidden1 = tf.nn.dropout(hidden_relu1, keep_prob, name = 'dropout')\n",
    "\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights2 = tf.Variable(\n",
    "            tf.truncated_normal([num_hidden1, num_hidden2],\n",
    "                            stddev=1.0 / math.sqrt(float(num_hidden1))),\n",
    "                            name='weights')\n",
    "        biases2 = tf.Variable(tf.zeros([num_hidden2]),\n",
    "                             name='biases')\n",
    "        hidden_relu2 = tf.nn.relu(tf.matmul(hidden1, weights2) + biases2)\n",
    "        hidden2 = tf.nn.dropout(hidden_relu2, keep_prob, name = 'dropout')\n",
    "\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights_sm = tf.Variable(\n",
    "            tf.truncated_normal([num_hidden2, num_classes],\n",
    "                            stddev=1.0 / math.sqrt(float(num_hidden2))),\n",
    "                            name='weights')\n",
    "        biases_sm = tf.Variable(tf.zeros([num_classes]),\n",
    "                             name='biases')\n",
    "        logits = tf.matmul(hidden2, weights_sm) + biases_sm\n",
    "\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y_target,\n",
    "        logits=logits,\n",
    "        name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "    # optimizer = tf.train.AdamOptimizer(0.00025)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.00025)\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    prediction1 = tf.nn.in_top_k(logits, y_target, 1)\n",
    "    accuracy1 = tf.reduce_mean(tf.cast(prediction1, tf.float32))\n",
    "    tf.summary.scalar('accuracy1', accuracy1)\n",
    "    \n",
    "    prediction2 = tf.nn.in_top_k(logits, y_target, 2)\n",
    "    accuracy2 = tf.reduce_mean(tf.cast(prediction2, tf.float32))\n",
    "    tf.summary.scalar('accuracy2', accuracy2)\n",
    "    \n",
    "    summary = tf.summary.merge_all()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter(current_log_dir + '/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(current_log_dir + '/test')\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        rand_index = np.random.choice(features_train.shape[0], size=batch_size)\n",
    "        rand_x = features_train[rand_index]\n",
    "        rand_y = np.transpose([target_train[rand_index]]).ravel()\n",
    "        feed_dict = {\n",
    "            x_data: rand_x,\n",
    "            y_target: rand_y,\n",
    "            keep_prob: 0.5,\n",
    "        }\n",
    "        \n",
    "        sess.run(train_op, feed_dict=feed_dict)\n",
    "\n",
    "        # Only record loss and accuracy every 100 generations\n",
    "        if (i+1)%100==0:\n",
    "            feed_dict_train = {\n",
    "                x_data: rand_x,\n",
    "                y_target: rand_y,\n",
    "                keep_prob: 1.0,\n",
    "            }\n",
    "\n",
    "            feed_dict_test = {\n",
    "                x_data: features_test,\n",
    "                y_target: np.transpose([target_test]).ravel(),\n",
    "                keep_prob: 1.0,\n",
    "            }\n",
    "\n",
    "            train_loss_temp = sess.run(loss, feed_dict=feed_dict_train)\n",
    "            train_acc_temp = sess.run(accuracy1, feed_dict=feed_dict_train)\n",
    "            train_acc2_temp = sess.run(accuracy2, feed_dict=feed_dict_train)\n",
    "            summary_str = sess.run(summary, feed_dict=feed_dict_train)\n",
    "            train_writer.add_summary(summary_str, i)\n",
    "            train_writer.flush()\n",
    "\n",
    "            test_loss_temp = sess.run(loss, feed_dict=feed_dict_test)\n",
    "            test_acc_temp = sess.run(accuracy1, feed_dict=feed_dict_test)\n",
    "            test_acc2_temp = sess.run(accuracy2, feed_dict=feed_dict_train)\n",
    "            summary_str = sess.run(summary, feed_dict=feed_dict_test)\n",
    "            test_writer.add_summary(summary_str, i)\n",
    "            test_writer.flush()\n",
    "\n",
    "        if (i+1)%500==0:\n",
    "            acc_and_loss = [i+1, train_loss_temp, test_loss_temp, train_acc_temp * 100, test_acc_temp * 100]\n",
    "            acc_and_loss = [np.round(x,3) for x in acc_and_loss]\n",
    "            print('Generation # {}. Train Loss (Test Loss): {:.3f} ({:.3f}). Train Acc (Test Acc): {:.3f} ({:.3f})'.format(*acc_and_loss))\n",
    "            \n",
    "            saver.save(sess, current_log_dir + '/model.ckpt', global_step=i)\n",
    "    \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
